{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72ebefe9-f5e4-4435-8138-1b4a0da1c193",
   "metadata": {},
   "source": [
    "# Software Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb8cc0d-2c4d-4a5f-aeaf-883d851fa27c",
   "metadata": {},
   "source": [
    "## Software Design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c20f861-d69c-4be2-8090-f731cbc38e56",
   "metadata": {},
   "source": [
    "Unlike most InSAR processing software (e.g., StamPS, MintPy) that have designated processing workflow, Moraine only provides a collection of Python functions or commands. The reason is, in real application, there is no perfect workflow that always generate satisfactory deformation result. Especially when the coherence is not good and atmospheric artifact is strong. One needs to try a lot of different methods but they are generally implented in different packages. Even worse, the workflow-based software are encapsulated too much and generally no detailed documentation is provided. It is really frustrating when users need to save intermediate data from one software and prepared them in a designated format and structure required by another software. Sometimes it is necessarry to read a lot of source code to understand what are the output, what are their data structure and what kind of inputs are needed as their typical workflows is not followed. So, instead of providing a standard workflow, Moraine is designed as a collection of functions that implement specific InSAR processing techniques (e.g. calculate the dispersion index, do phase linking) and users are encouraged to make their own workflow that are suitable for their case. We provide the necessary infrastructure and your role is to be innovative! To make it easier, Moraine provides detailed documentation for each function that explain the usage. We also provide the tutorials section that provide some typical workflow for your reference. In case users want to try methods that are not implemented in Moraine, the input and output are well explained in the documentation of every Moraine functions.\n",
    "\n",
    "Although we provide detailed documentation and reference workflow, we still admit this software is not that easy that users only need to run from the first step to the last step. It doesn't mean we don't value user-friendliness, but it shouldnâ€™t come at the expense of flexibility and creativity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb721e29-81ce-46b9-ae87-b7c82fb5cc67",
   "metadata": {},
   "source": [
    "## Software Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9717ab-180e-4ae3-8fde-5edfae1e30ec",
   "metadata": {},
   "source": [
    "Most of the functions in this package provide 2 kind of API, the array-based API and the file-based API. The inputs and output of array-based functions generally are numpy or cupy arrays (Simply, cupy is a package that provides same functions as numpy but runs on GPU), while inputs and outputs of file-based functions are string of path to the array stored in disk. InSAR techniques that can be greatly accelerated with parallel processing are implented in cupy or numba for better performance. The file-based functions are not simple wrapper of the array-based functions. Since Moraine aims at big data processing, most array-based functions may not be used due to the memory limitation. However, the file-based functions support chunkwise processing with the help of [dask](https://www.dask.org/), and mulit-GPU processing is also supported."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cd5d95-9d74-43c0-bef9-dd7de03185c4",
   "metadata": {},
   "source": [
    "To make it simpler, we call the file-based functions CLI (command line interface) (The name is just a convention, we don't provide the commands that can be runned from the terminal.), the array-based API API. The API and CLI functions are arranged in different namespace: `moraine.*` and `moraine.cli.*`. The CLI functions support logging if logger is created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180ea754-8980-42aa-845c-ae3dbf5232d7",
   "metadata": {},
   "source": [
    "## Data format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ed1b26-759b-43e7-8111-1379b6793518",
   "metadata": {},
   "source": [
    "Most of the stored data in this package is in the [zarr](https://zarr.readthedocs.io/en/stable/) format, which is a file storage format for chunked, compressed, N-dimensional arrays. The figure below shows how the structure of zarr data. The reading and writing speed is fast since the data volume is compressed. Before compressing, the data are divided into chunks to be more flexiable for `dask` parallel operation. Generally, the file name is `xxxxxx.zarr`. You will find it is indeed a directory in the file system. But just treat it as a single file in use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc681084-96ca-4427-a9f0-49584fed8511",
   "metadata": {},
   "source": [
    "![imga](./software_architecture/array.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb343e9-5bd0-4602-a8a6-7f096291be46",
   "metadata": {},
   "source": [
    "Note that the sturcture of dask array is similar. Each chunk of a big dask array is just a numpy or cupy array. Independent operations on every chunks are automatically parallelized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bf708f-6153-4c72-bda0-a0dfd5886845",
   "metadata": {},
   "source": [
    "In this software, there are mainly two kind of dataset. One is stack of raster data, another is stack of point cloud data. The raster dataset are divided into chunks both azimuth dimension and range dimension. The point cloud dataset are divided into chunks along the spatial dimension. These two chunksize needs to be determined by the user. The chunksize in high dims are automatically determined. Users don't need to care about it.\n",
    "\n",
    "Chunksize affect the performance of the program. Unproper chunksize slows down the processing speed or even crash the program.\n",
    "Using too small chunksize makes too much inter-process communication and slows down the program.\n",
    "Too big chunksize may crash the program due to mamory limit.\n",
    "For raster data, it is good to make sure range chunksize of the last chunk is same as others.\n",
    "And it is prefered to divide raster data along azimuth direction rather than range direction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274466be-cf08-4d26-8f1b-800adc957dba",
   "metadata": {},
   "source": [
    "## An example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85cd033-61d3-456f-9daa-268f9b3547cf",
   "metadata": {},
   "source": [
    "Here we provide an simple example. The API function `moraine.emi` implemented the `EMI` phase linking method and `moraine.cli.emi` is the file-based API of it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc11ff77-de5d-4396-83ef-2a62fb890c86",
   "metadata": {},
   "source": [
    "Import them first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e87d26-b566-4060-84e5-24f317b2cc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import moraine as mr\n",
    "import moraine.cli as mc\n",
    "from nbdev.showdoc import show_doc # this is just a function to show the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b43e4ce-f31f-4dee-8a51-a94ccee983dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kanglcn/moraine/blob/main/moraine/pl.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### emi\n",
       "\n",
       ">      emi (coh:numpy.ndarray, ref:int=0)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| coh | ndarray |  | complex coherence metrix,dtype cupy.complex |\n",
       "| ref | int | 0 | index of reference image in the phase history output, optional. Default: 0 |\n",
       "| **Returns** | **tuple** |  | **estimated phase history `ph`, dtype complex; quality (minimum eigvalue, dtype float)** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kanglcn/moraine/blob/main/moraine/pl.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### emi\n",
       "\n",
       ">      emi (coh:numpy.ndarray, ref:int=0)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| coh | ndarray |  | complex coherence metrix,dtype cupy.complex |\n",
       "| ref | int | 0 | index of reference image in the phase history output, optional. Default: 0 |\n",
       "| **Returns** | **tuple** |  | **estimated phase history `ph`, dtype complex; quality (minimum eigvalue, dtype float)** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(mr.emi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2d6c82-e64d-4f55-b643-5d22c07f6a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kanglcn/moraine/blob/main/moraine/cli/pl.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### emi\n",
       "\n",
       ">      emi (coh:str, ph:str, emi_quality:str, ref:int=0, chunks:int=None)\n",
       "\n",
       "*Phase linking with EMI estimator.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| coh | str |  | coherence matrix |\n",
       "| ph | str |  | output, wrapped phase |\n",
       "| emi_quality | str |  | output, pixel quality |\n",
       "| ref | int | 0 | reference image for phase |\n",
       "| chunks | int | None | # chunk size of output zarr dataset, optional. Default: same as `coh`. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kanglcn/moraine/blob/main/moraine/cli/pl.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### emi\n",
       "\n",
       ">      emi (coh:str, ph:str, emi_quality:str, ref:int=0, chunks:int=None)\n",
       "\n",
       "*Phase linking with EMI estimator.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| coh | str |  | coherence matrix |\n",
       "| ph | str |  | output, wrapped phase |\n",
       "| emi_quality | str |  | output, pixel quality |\n",
       "| ref | int | 0 | reference image for phase |\n",
       "| chunks | int | None | # chunk size of output zarr dataset, optional. Default: same as `coh`. |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(mc.emi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88542f15-674b-4c33-ad70-596c89aa4425",
   "metadata": {},
   "source": [
    "To apply the `emi` API funtion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54381a9e-a72d-4bad-a2be-94441dcc1be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import numpy as np\n",
    "from moraine.utils_ import is_cuda_available\n",
    "if is_cuda_available():\n",
    "    import cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7e3be5-8c86-47ad-8008-213af5bc78ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "coh_zarr = zarr.open('./software_architecture/ds_can_coh.zarr/','r') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77f3daa-dcb9-4ae2-8a02-8ed31f1327da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<zarr.core.Array (740397, 17, 17) complex64 read-only>,\n",
       " (740397, 17, 17),\n",
       " (200000, 17, 17),\n",
       " dtype('complex64'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coh_zarr,coh_zarr.shape,coh_zarr.chunks,coh_zarr.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688c05bc-d458-40df-ba78-0cbe16861768",
   "metadata": {},
   "source": [
    "It is coherence matrix for 740397 selected DS candidate and there are 17 SAR images.\n",
    "So the coherence matrix for one pixel is 17 $\\times$ 17.\n",
    "The coherence matrix is stored in 4 chunks and each chunks stores data for 200000 DS candidate.\n",
    "(The last chunk only have 140397 DS candidate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee94f4bc-4b06-41b2-80f9-f7f289b5cfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1570400\n",
      "drwxrwxr-x 2 kangl kangl      4096 Sep 28  2023 .\n",
      "drwxrwxr-x 5 kangl kangl      4096 Apr 28 20:27 ..\n",
      "-rw-rw-r-- 1 kangl kangl 434775676 Sep 28  2023 0.0.0\n",
      "-rw-rw-r-- 1 kangl kangl 432578417 Sep 28  2023 1.0.0\n",
      "-rw-rw-r-- 1 kangl kangl 434846911 Sep 28  2023 2.0.0\n",
      "-rw-rw-r-- 1 kangl kangl 305857416 Sep 28  2023 3.0.0\n",
      "-rw-rw-r-- 1 kangl kangl       398 Sep 28  2023 .zarray\n"
     ]
    }
   ],
   "source": [
    "!ls -al ./software_architecture/ds_can_coh.zarr/ #It is a directory indeed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ae3346-1370-49a5-b8de-3c728254e92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coh = coh_zarr[:] # read as numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36e3fee-146f-44b8-a66c-85509d290a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_cuda_available():\n",
    "    coh = cp.asarray(coh) # convert to cupy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc72847c-47d0-4fa5-8302-9bd272afa4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740397, 17, 17)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed44156-81a4-4c40-92a4-2b270113043f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.45 s, sys: 202 ms, total: 1.65 s\n",
      "Wall time: 1.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The processing is really fast!\n",
    "if is_cuda_available():\n",
    "    ph,emi_quality = mr.emi(coh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5081fc8d-66b3-4bab-bf40-205e58f025dc",
   "metadata": {},
   "source": [
    "Now we apply the CLI function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288f2080-08b8-48ae-a795-1a65ddae3503",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = mc.get_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1078b1-9480-4d0c-9a31-368f32838fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-30 22:49:13 - log_args - INFO - running function: emi\n",
      "2024-04-30 22:49:13 - log_args - INFO - fetching args:\n",
      "2024-04-30 22:49:13 - log_args - INFO - coh = './software_architecture/ds_can_coh.zarr/'\n",
      "2024-04-30 22:49:13 - log_args - INFO - ph = './software_architecture/ds_can_ph.zarr'\n",
      "2024-04-30 22:49:13 - log_args - INFO - emi_quality = './software_architecture/ds_can_emi_quality.zarr'\n",
      "2024-04-30 22:49:13 - log_args - INFO - ref = 0\n",
      "2024-04-30 22:49:13 - log_args - INFO - chunks = None\n",
      "2024-04-30 22:49:13 - log_args - INFO - fetching args done.\n",
      "2024-04-30 22:49:13 - zarr_info - INFO - ./software_architecture/ds_can_coh.zarr/ zarray shape: (740397, 17, 17)\n",
      "2024-04-30 22:49:13 - zarr_info - INFO - ./software_architecture/ds_can_coh.zarr/ zarray chunks: (200000, 17, 17)\n",
      "2024-04-30 22:49:13 - zarr_info - INFO - ./software_architecture/ds_can_coh.zarr/ zarray dtype: complex64\n",
      "2024-04-30 22:49:13 - emi - INFO - starting dask CUDA local cluster.\n",
      "2024-04-30 22:49:16 - emi - INFO - dask local CUDA cluster started.\n",
      "2024-04-30 22:49:16 - darr_info - INFO - coh dask array shape: (740397, 17, 17)\n",
      "2024-04-30 22:49:16 - darr_info - INFO - coh dask array chunksize: (200000, 17, 17)\n",
      "2024-04-30 22:49:16 - darr_info - INFO - coh dask array dtype: complex64\n",
      "2024-04-30 22:49:16 - emi - INFO - phase linking with EMI.\n",
      "2024-04-30 22:49:16 - emi - INFO - got ph and emi_quality.\n",
      "2024-04-30 22:49:16 - darr_info - INFO - ph dask array shape: (740397, 17)\n",
      "2024-04-30 22:49:16 - darr_info - INFO - ph dask array chunksize: (200000, 17)\n",
      "2024-04-30 22:49:16 - darr_info - INFO - ph dask array dtype: complex64\n",
      "2024-04-30 22:49:16 - darr_info - INFO - emi_quality dask array shape: (740397,)\n",
      "2024-04-30 22:49:16 - darr_info - INFO - emi_quality dask array chunksize: (200000,)\n",
      "2024-04-30 22:49:16 - darr_info - INFO - emi_quality dask array dtype: float32\n",
      "2024-04-30 22:49:16 - emi - INFO - rechunk ph\n",
      "2024-04-30 22:49:16 - darr_info - INFO - ph dask array shape: (740397, 17)\n",
      "2024-04-30 22:49:16 - darr_info - INFO - ph dask array chunksize: (200000, 17)\n",
      "2024-04-30 22:49:16 - darr_info - INFO - ph dask array dtype: complex64\n",
      "2024-04-30 22:49:16 - emi - INFO - saving ph and emi_quality.\n",
      "2024-04-30 22:49:16 - emi - INFO - computing graph setted. doing all the computing.\n",
      "2024-04-30 22:49:21 - emi - INFO - computing finished.leted |  5.2s\u001b[2K\n",
      "2024-04-30 22:49:22 - emi - INFO - dask cluster closed.\n",
      "CPU times: user 578 ms, sys: 304 ms, total: 883 ms\n",
      "Wall time: 8.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if is_cuda_available():\n",
    "    mc.emi('./software_architecture/ds_can_coh.zarr/',\n",
    "           './software_architecture/ds_can_ph.zarr',\n",
    "           './software_architecture/ds_can_emi_quality.zarr',)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306207af-959c-4576-b814-9351d4e29f9d",
   "metadata": {},
   "source": [
    "The CLI function is slower than the API function since it needs to read and write the data and set up the dask CUDA cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8c6982-9b0f-4653-a85a-c5d6a685488f",
   "metadata": {},
   "source": [
    "The CLI also include functions for simple data manipulation (e.g. array slicing and point clouds merging). As it is very easy to do them for numpy/cupy arrays, these CLI do not have corresponding API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1e4c73-6945-4370-bb71-59b849b5772f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
