{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "238849fa-11ec-4de5-99e4-c4eb367f7913",
   "metadata": {},
   "source": [
    "# pc\n",
    "\n",
    "> Point Cloud data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eed06b-0dd0-4177-8a92-8757961eecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp cli/pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967c14e4-d207-455f-829c-4c3a005838ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6122cdf-94b2-4797-8f04-f12061ed3cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import numpy as np\n",
    "from decorrelation.cli.utils.logging import get_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b686af00-c16a-401d-baf8-2847eda5416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import logging\n",
    "import zarr\n",
    "import numpy as np\n",
    "import numexpr as ne\n",
    "\n",
    "import dask\n",
    "from dask import array as da\n",
    "from dask.distributed import Client, LocalCluster, progress\n",
    "\n",
    "from decorrelation.pc import pc2ras, pc_union, pc_intersect, pc_diff\n",
    "from decorrelation.cli.utils.logging import log_args, de_logger\n",
    "from decorrelation.cli.utils.chunk_size import (get_pc_chunk_size_from_n_pc_chunk, \n",
    "                                                get_pc_chunk_size_from_pc_chunk_size, \n",
    "                                                get_pc_chunk_size_from_n_ras_chunk,\n",
    "                                                get_ras_chunk_size_from_n_pc_chunk)\n",
    "\n",
    "from fastcore.script import call_parse, Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613bab1c-7d42-4f16-8f19-f3679c86beef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@call_parse\n",
    "@log_args\n",
    "@de_logger\n",
    "def de_idx2bool(idx:str, # point cloud index\n",
    "                is_pc:str, # output, output bool array\n",
    "                shape:tuple, # shape of one image (nlines,width)\n",
    "                az_chunk_size:int=None, # output azimuth chunk size, \n",
    "                n_az_chunk:int=None, # # output number of azimuth chunks\n",
    "                r_chunk_size:int=None, # output range chunk size\n",
    "                n_r_chunk:int=None, # output number of range chunks\n",
    "):\n",
    "    '''Convert pc index to bool 2d array'''\n",
    "    logger = logging.getLogger(__name__)\n",
    "    is_pc_path = is_pc\n",
    "\n",
    "    idx_zarr = zarr.open(idx,mode='r')\n",
    "    logger.zarr_info('idx',idx_zarr)\n",
    "    assert idx_zarr.ndim == 2, \"idx dimentation is not 2.\"\n",
    "    logger.info('loading idx into memory.')\n",
    "    idx = zarr.open(idx,mode='r')[:]\n",
    "\n",
    "    logger.info('calculate the bool array')\n",
    "    is_pc = np.zeros(shape,dtype=bool)\n",
    "    is_pc[idx[0],idx[1]] = True\n",
    "\n",
    "    chunks = get_ras_chunk_size_from_n_pc_chunk('idx','ras',idx_zarr.shape[1],idx_zarr.chunks[1],\n",
    "                                               *shape,\n",
    "                                               az_chunk_size=az_chunk_size,\n",
    "                                               n_az_chunk=n_az_chunk,\n",
    "                                               r_chunk_size=r_chunk_size,\n",
    "                                               n_r_chunk=n_r_chunk,\n",
    "                                              )\n",
    "    is_pc_zarr = zarr.open(is_pc_path,'w',shape=shape,dtype=bool,chunks=chunks)\n",
    "    logger.zarr_info('is_pc',is_pc_zarr)\n",
    "    logger.info('write the bool array.')\n",
    "    is_pc_zarr[:] = is_pc\n",
    "    logger.info('write done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010e98a0-a4d3-4922-b743-b1efbe172691",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@call_parse\n",
    "@log_args\n",
    "@de_logger\n",
    "def de_bool2idx(is_pc:str, # input bool array\n",
    "                idx:str, # output, point cloud index\n",
    "                pc_chunk_size:int=None, # output point chunk size\n",
    "                n_pc_chunk:int=None, # output number of chunk\n",
    "):\n",
    "    '''Convert bool 2d array to integer index'''\n",
    "    idx_path = idx\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    is_pc_zarr = zarr.open(is_pc,'r')\n",
    "    logger.zarr_info('is_pc', is_pc_zarr)\n",
    "    logger.info('loading is_pc into memory.')\n",
    "    is_pc = zarr.open(is_pc,mode='r')[:]\n",
    "    \n",
    "    logger.info('calculate the index')\n",
    "    idx = np.stack(np.where(is_pc))\n",
    "\n",
    "    pc_chunk_size = get_pc_chunk_size_from_n_ras_chunk('is_pc','idx',\n",
    "                                                       *is_pc_zarr.shape[:2],\n",
    "                                                       *is_pc_zarr.chunks[:2],\n",
    "                                                       idx.shape[1],\n",
    "                                                       pc_chunk_size=pc_chunk_size, n_pc_chunk=n_pc_chunk)\n",
    "    idx_zarr = zarr.open(idx_path,'w',shape=idx.shape,dtype=bool,chunks=(2,pc_chunk_size))\n",
    "    logger.info('write the idx.')\n",
    "    idx_zarr[:] = idx\n",
    "    logger.info('write done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2d5d0e-48cf-450b-8eb8-91a31cae04a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@log_args\n",
    "@de_logger\n",
    "def de_ras2pc(idx:str, # point cloud index\n",
    "              ras:str|list, # path (in string) or list of path for raster data\n",
    "              pc:str|list, # output, path (in string) or list of path for point cloud data\n",
    "              pc_chunk_size:int=None, # output point chunk size\n",
    "              n_pc_chunk:int=None, # output number of chunk\n",
    "              hd_chunk_size:tuple|list=None, # output high dimension chunk size, tuple or list of tuple, same as input raster data by default\n",
    "):\n",
    "    '''Convert raster data to point cloud data'''\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    idx_zarr = zarr.open(idx,mode='r')\n",
    "    logger.zarr_info(idx,idx_zarr)\n",
    "    assert idx_zarr.ndim == 2, \"idx dimentation is not 2.\"\n",
    "    pc_chunk_size = get_pc_chunk_size_from_pc_chunk_size('idx','pc',\n",
    "                                                         idx_zarr.chunks[1],idx_zarr.shape[1],\n",
    "                                                         pc_chunk_size=pc_chunk_size,n_pc_chunk=n_pc_chunk)\n",
    "\n",
    "    logger.info('loading idx into memory.')\n",
    "    idx = zarr.open(idx,mode='r')[:]\n",
    "    n_pc = idx.shape[1]\n",
    "\n",
    "    if isinstance(ras,str):\n",
    "        assert isinstance(pc,str)\n",
    "        ras_list = [ras]; pc_list = [pc]\n",
    "        if hd_chunk_size is not None:\n",
    "            assert isinstance(hd_chunk_size,tuple)\n",
    "            hd_chunk_size_list = [hd_chunk_size]\n",
    "        else:\n",
    "            hd_chunk_size_list = [None]\n",
    "    else:\n",
    "        assert isinstance(ras,list); assert isinstance(pc,list)\n",
    "        ras_list = ras; pc_list = pc\n",
    "        n_data = len(ras_list)\n",
    "        if hd_chunk_size is not None:\n",
    "            assert isinstance(hd_chunk_size,list)\n",
    "            hd_chunk_size_list = hd_chunk_size\n",
    "        else:\n",
    "            hd_chunk_size_list = [None]*n_data\n",
    "\n",
    "    logger.info('starting dask local cluster.')\n",
    "    with LocalCluster() as cluster, Client(cluster) as client:\n",
    "        logger.info('dask local cluster started.')\n",
    "\n",
    "        _pc_list = ()\n",
    "        for ras_path, pc_path, hd_chunk_size in zip(ras_list,pc_list,hd_chunk_size_list):\n",
    "            logger.info(f'start to slice on {ras_path}')\n",
    "            ras_zarr = zarr.open(ras_path,'r'); logger.zarr_info(ras_path, ras_zarr)\n",
    "            if hd_chunk_size is None:\n",
    "                logger.info(f'hd_chunk_size not setted. Use the one from {ras_path}.')\n",
    "                hd_chunk_size = ras_zarr.chunks[2:]\n",
    "            logger.info(f'hd_chunk_size: {hd_chunk_size}.')\n",
    "\n",
    "            ras = da.from_zarr(ras_path,chunks=(*ras_zarr.chunks[:2],*hd_chunk_size)); logger.darr_info('ras',ras)\n",
    "\n",
    "            with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
    "                pc = ras.reshape(-1,*ras.shape[2:])[np.ravel_multi_index((idx[0],idx[1]),dims=ras.shape[:2])]\n",
    "\n",
    "            logger.darr_info('pc', pc)\n",
    "            logger.info('rechunk pc data:')\n",
    "            pc = pc.rechunk((pc_chunk_size,*pc.chunksize[1:]))\n",
    "            logger.darr_info('pc', pc)\n",
    "            _pc = pc.to_zarr(pc_path,overwrite=True,compute=False)\n",
    "            logger.info(f'saving to {pc_path}.')\n",
    "            _pc_list += (_pc,)\n",
    "\n",
    "        logger.info('computing graph setted. doing all the computing.')\n",
    "        futures = client.persist(_pc_list)\n",
    "        progress(futures,notebook=False)\n",
    "        da.compute(futures)\n",
    "        logger.info('computing finished.')\n",
    "\n",
    "    logger.info('dask cluster closed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad08c7-bb6c-492a-acd2-44ec6e75fb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@call_parse\n",
    "def console_de_ras2pc(idx:str, # point cloud index\n",
    "                      ras:Param(type=str,required=True,nargs='+',help='one or more path for raster data')=None,\n",
    "                      pc:Param(type=str,required=True,nargs='+',help='output, one or more path for point cloud data')=None,\n",
    "                      pc_chunk_size:int=None, # output point chunk size, same as input idx by default\n",
    "                      n_pc_chunk:int=None, # output number of chunk\n",
    "                      hd_chunk_size:Param(type=str,nargs='+',help='''output high dimension chunk size,\n",
    "                      each size should be wrapped in quotation marks and size in each dimension are seperated with \",\",\n",
    "                      same as input raster data by default''')=None,\n",
    "):\n",
    "    '''Convert raster data to point cloud data'''\n",
    "    if hd_chunk_size is not None:\n",
    "        hd_chunk_size_ = []\n",
    "        for size in hd_chunk_size:\n",
    "            if len(size) == 0:\n",
    "                size = ()\n",
    "            else:\n",
    "                size = size.split(',')\n",
    "                size = tuple([int(i) for i in size])\n",
    "            hd_chunk_size_.append(size)\n",
    "    else:\n",
    "        hd_chunk_size_ = None\n",
    "\n",
    "    if len(ras)==1:\n",
    "        ras = ras[0]\n",
    "        pc = pc[0]\n",
    "        if hd_chunk_size_ is not None:\n",
    "            hd_chunk_size_ = hd_chunk_size_[0]\n",
    "\n",
    "    de_ras2pc(idx,ras,pc,pc_chunk_size=pc_chunk_size,n_pc_chunk=n_pc_chunk,hd_chunk_size=hd_chunk_size_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae4f91c-2870-40d7-ab4f-2378ff6d3e95",
   "metadata": {},
   "source": [
    "Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85748a1c-7f01-4264-b6db-8901495b15e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8042246-2acf-44ad-ab50-c2ad2b326fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ras_data1 = np.random.rand(100,100).astype(np.float32)\n",
    "ras_data2 = np.random.rand(100,100,3).astype(np.float32)+1j*np.random.rand(100,100,3).astype(np.float32)\n",
    "\n",
    "idx = np.random.choice(np.arange(100*100,dtype=np.int32),size=1000,replace=False)\n",
    "idx.sort()\n",
    "idx = np.stack(np.unravel_index(idx,shape=(100,100))).astype(np.int32)\n",
    "\n",
    "pc_data1 = ras_data1[idx[0],idx[1]]\n",
    "pc_data2 = ras_data2[idx[0],idx[1]]\n",
    "\n",
    "idx_zarr = zarr.open('pc/idx.zarr','w',shape=idx.shape,dtype=idx.dtype,chunks=(2,200))\n",
    "ras_zarr1 = zarr.open('pc/ras1.zarr','w',shape=ras_data1.shape,dtype=ras_data1.dtype,chunks=(20,100))\n",
    "ras_zarr2 = zarr.open('pc/ras2.zarr','w',shape=ras_data2.shape,dtype=ras_data2.dtype,chunks=(20,100,1))\n",
    "idx_zarr[:] = idx\n",
    "ras_zarr1[:] = ras_data1\n",
    "ras_zarr2[:] = ras_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5b5824-8365-4107-8088-76aad7304f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-05 02:45:19 - logging_args - INFO - running function: de_ras2pc\n",
      "2023-11-05 02:45:19 - logging_args - INFO - fetching args:\n",
      "2023-11-05 02:45:19 - logging_args - INFO - idx = 'pc/idx.zarr'\n",
      "2023-11-05 02:45:19 - logging_args - INFO - ras = 'pc/ras1.zarr'\n",
      "2023-11-05 02:45:19 - logging_args - INFO - pc = 'pc/pc1.zarr'\n",
      "2023-11-05 02:45:19 - logging_args - INFO - pc_chunk_size = None\n",
      "2023-11-05 02:45:19 - logging_args - INFO - n_pc_chunk = None\n",
      "2023-11-05 02:45:19 - logging_args - INFO - hd_chunk_size = None\n",
      "2023-11-05 02:45:19 - logging_args - INFO - fetching args done.\n",
      "2023-11-05 02:45:19 - zarr_info - INFO - pc/idx.zarr zarray shape: (2, 1000)\n",
      "2023-11-05 02:45:19 - zarr_info - INFO - pc/idx.zarr zarray chunks: (2, 200)\n",
      "2023-11-05 02:45:19 - zarr_info - INFO - pc/idx.zarr zarray dtype: int32\n",
      "2023-11-05 02:45:19 - get_pc_chunk_size_from_pc_chunk_size - INFO - automatically determine pc_chunk_size from\n",
      "            pc_chunk_size of idx.\n",
      "2023-11-05 02:45:19 - get_pc_chunk_size_from_pc_chunk_size - INFO - pc_chunk_size for pc: 200\n",
      "2023-11-05 02:45:19 - de_ras2pc - INFO - loading idx into memory.\n",
      "2023-11-05 02:45:19 - de_ras2pc - INFO - starting dask local cluster.\n",
      "2023-11-05 02:45:24 - de_ras2pc - INFO - dask local cluster started.\n",
      "2023-11-05 02:45:24 - de_ras2pc - INFO - start to slice on pc/ras1.zarr\n",
      "2023-11-05 02:45:24 - zarr_info - INFO - pc/ras1.zarr zarray shape: (100, 100)\n",
      "2023-11-05 02:45:24 - zarr_info - INFO - pc/ras1.zarr zarray chunks: (20, 100)\n",
      "2023-11-05 02:45:24 - zarr_info - INFO - pc/ras1.zarr zarray dtype: float32\n",
      "2023-11-05 02:45:24 - de_ras2pc - INFO - hd_chunk_size not setted. Use the one from pc/ras1.zarr.\n",
      "2023-11-05 02:45:24 - de_ras2pc - INFO - hd_chunk_size: ().\n",
      "2023-11-05 02:45:24 - darr_info - INFO - ras dask array shape: (100, 100)\n",
      "2023-11-05 02:45:24 - darr_info - INFO - ras dask array chunksize: (20, 100)\n",
      "2023-11-05 02:45:24 - darr_info - INFO - ras dask array dtype: float32\n",
      "2023-11-05 02:45:24 - darr_info - INFO - pc dask array shape: (1000,)\n",
      "2023-11-05 02:45:24 - darr_info - INFO - pc dask array chunksize: (223,)\n",
      "2023-11-05 02:45:24 - darr_info - INFO - pc dask array dtype: float32\n",
      "2023-11-05 02:45:24 - de_ras2pc - INFO - rechunk pc data:\n",
      "2023-11-05 02:45:24 - darr_info - INFO - pc dask array shape: (1000,)\n",
      "2023-11-05 02:45:24 - darr_info - INFO - pc dask array chunksize: (200,)\n",
      "2023-11-05 02:45:24 - darr_info - INFO - pc dask array dtype: float32\n",
      "2023-11-05 02:45:24 - de_ras2pc - INFO - saving to pc/pc1.zarr.\n",
      "2023-11-05 02:45:24 - de_ras2pc - INFO - computing graph setted. doing all the computing.\n",
      "2023-11-05 02:45:24 - de_ras2pc - INFO - computing finished.|  0.6s\u001b[2K\n",
      "2023-11-05 02:45:25 - de_ras2pc - INFO - dask cluster closed.\n",
      "2023-11-05 02:45:25 - logging_args - INFO - running function: de_ras2pc\n",
      "2023-11-05 02:45:25 - logging_args - INFO - fetching args:\n",
      "2023-11-05 02:45:25 - logging_args - INFO - idx = 'pc/idx.zarr'\n",
      "2023-11-05 02:45:25 - logging_args - INFO - ras = ['pc/ras1.zarr', 'pc/ras2.zarr']\n",
      "2023-11-05 02:45:25 - logging_args - INFO - pc = ['pc/pc1.zarr', 'pc/pc2.zarr']\n",
      "2023-11-05 02:45:25 - logging_args - INFO - pc_chunk_size = None\n",
      "2023-11-05 02:45:25 - logging_args - INFO - n_pc_chunk = None\n",
      "2023-11-05 02:45:25 - logging_args - INFO - hd_chunk_size = [(), (1,)]\n",
      "2023-11-05 02:45:25 - logging_args - INFO - fetching args done.\n",
      "2023-11-05 02:45:25 - zarr_info - INFO - pc/idx.zarr zarray shape: (2, 1000)\n",
      "2023-11-05 02:45:25 - zarr_info - INFO - pc/idx.zarr zarray chunks: (2, 200)\n",
      "2023-11-05 02:45:25 - zarr_info - INFO - pc/idx.zarr zarray dtype: int32\n",
      "2023-11-05 02:45:25 - get_pc_chunk_size_from_pc_chunk_size - INFO - automatically determine pc_chunk_size from\n",
      "            pc_chunk_size of idx.\n",
      "2023-11-05 02:45:25 - get_pc_chunk_size_from_pc_chunk_size - INFO - pc_chunk_size for pc: 200\n",
      "2023-11-05 02:45:25 - de_ras2pc - INFO - loading idx into memory.\n",
      "2023-11-05 02:45:25 - de_ras2pc - INFO - starting dask local cluster.\n",
      "2023-11-05 02:45:29 - de_ras2pc - INFO - dask local cluster started.\n",
      "2023-11-05 02:45:29 - de_ras2pc - INFO - start to slice on pc/ras1.zarr\n",
      "2023-11-05 02:45:29 - zarr_info - INFO - pc/ras1.zarr zarray shape: (100, 100)\n",
      "2023-11-05 02:45:29 - zarr_info - INFO - pc/ras1.zarr zarray chunks: (20, 100)\n",
      "2023-11-05 02:45:29 - zarr_info - INFO - pc/ras1.zarr zarray dtype: float32\n",
      "2023-11-05 02:45:29 - de_ras2pc - INFO - hd_chunk_size: ().\n",
      "2023-11-05 02:45:29 - darr_info - INFO - ras dask array shape: (100, 100)\n",
      "2023-11-05 02:45:29 - darr_info - INFO - ras dask array chunksize: (20, 100)\n",
      "2023-11-05 02:45:29 - darr_info - INFO - ras dask array dtype: float32\n",
      "2023-11-05 02:45:29 - darr_info - INFO - pc dask array shape: (1000,)\n",
      "2023-11-05 02:45:29 - darr_info - INFO - pc dask array chunksize: (223,)\n",
      "2023-11-05 02:45:29 - darr_info - INFO - pc dask array dtype: float32\n",
      "2023-11-05 02:45:29 - de_ras2pc - INFO - rechunk pc data:\n",
      "2023-11-05 02:45:29 - darr_info - INFO - pc dask array shape: (1000,)\n",
      "2023-11-05 02:45:29 - darr_info - INFO - pc dask array chunksize: (200,)\n",
      "2023-11-05 02:45:29 - darr_info - INFO - pc dask array dtype: float32\n",
      "2023-11-05 02:45:29 - de_ras2pc - INFO - saving to pc/pc1.zarr.\n",
      "2023-11-05 02:45:29 - de_ras2pc - INFO - start to slice on pc/ras2.zarr\n",
      "2023-11-05 02:45:29 - zarr_info - INFO - pc/ras2.zarr zarray shape: (100, 100, 3)\n",
      "2023-11-05 02:45:29 - zarr_info - INFO - pc/ras2.zarr zarray chunks: (20, 100, 1)\n",
      "2023-11-05 02:45:29 - zarr_info - INFO - pc/ras2.zarr zarray dtype: complex64\n",
      "2023-11-05 02:45:29 - de_ras2pc - INFO - hd_chunk_size: (1,).\n",
      "2023-11-05 02:45:29 - darr_info - INFO - ras dask array shape: (100, 100, 3)\n",
      "2023-11-05 02:45:29 - darr_info - INFO - ras dask array chunksize: (20, 100, 1)\n",
      "2023-11-05 02:45:29 - darr_info - INFO - ras dask array dtype: complex64\n",
      "2023-11-05 02:45:29 - darr_info - INFO - pc dask array shape: (1000, 3)\n",
      "2023-11-05 02:45:29 - darr_info - INFO - pc dask array chunksize: (223, 1)\n",
      "2023-11-05 02:45:29 - darr_info - INFO - pc dask array dtype: complex64\n",
      "2023-11-05 02:45:29 - de_ras2pc - INFO - rechunk pc data:\n",
      "2023-11-05 02:45:29 - darr_info - INFO - pc dask array shape: (1000, 3)\n",
      "2023-11-05 02:45:29 - darr_info - INFO - pc dask array chunksize: (200, 1)\n",
      "2023-11-05 02:45:29 - darr_info - INFO - pc dask array dtype: complex64\n",
      "2023-11-05 02:45:29 - de_ras2pc - INFO - saving to pc/pc2.zarr.\n",
      "2023-11-05 02:45:29 - de_ras2pc - INFO - computing graph setted. doing all the computing.\n",
      "2023-11-05 02:45:30 - de_ras2pc - INFO - computing finished.|  1.1s\u001b[2K\n",
      "2023-11-05 02:45:30 - de_ras2pc - INFO - dask cluster closed.\n"
     ]
    }
   ],
   "source": [
    "de_ras2pc('pc/idx.zarr','pc/ras1.zarr','pc/pc1.zarr')\n",
    "pc_zarr1 = zarr.open('pc/pc1.zarr','r')\n",
    "np.testing.assert_array_equal(pc_data1,pc_zarr1[:])\n",
    "\n",
    "de_ras2pc('pc/idx.zarr',ras=['pc/ras1.zarr','pc/ras2.zarr'],pc=['pc/pc1.zarr','pc/pc2.zarr'],hd_chunk_size=[(),(1,)])\n",
    "pc_zarr1 = zarr.open('pc/pc1.zarr','r')\n",
    "pc_zarr2 = zarr.open('pc/pc2.zarr','r')\n",
    "np.testing.assert_array_equal(pc_data1,pc_zarr1[:])\n",
    "np.testing.assert_array_equal(pc_data2,pc_zarr2[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbaeef3-786c-49d6-9e6b-d2617383f511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@log_args\n",
    "@de_logger\n",
    "def de_pc2ras(idx:str, # point cloud index\n",
    "              pc:str|list, # path (in string) or list of path for point cloud data\n",
    "              ras:str|list, # output, path (in string) or list of path for raster data\n",
    "              shape:tuple, # shape of one image (nlines,width)\n",
    "              az_chunk_size:int=None, # output azimuth chunk size, \n",
    "              n_az_chunk:int=None, # # output number of azimuth chunks\n",
    "              r_chunk_size:int=None, # output range chunk size\n",
    "              n_r_chunk:int=None, # output number of range chunks\n",
    "):\n",
    "    '''Convert point cloud data to raster data, filled with nan'''\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    idx_zarr = zarr.open(idx,mode='r')\n",
    "    logger.zarr_info('idx', idx_zarr)\n",
    "    assert idx_zarr.ndim == 2, \"idx dimentation is not 2.\"\n",
    "    chunk_size = get_ras_chunk_size_from_n_pc_chunk('idx','ras',\n",
    "                                                    idx_zarr.shape[1],idx_zarr.chunks[1],\n",
    "                                                    *shape,\n",
    "                                                    az_chunk_size=az_chunk_size,n_az_chunk=n_az_chunk,\n",
    "                                                    r_chunk_size=r_chunk_size,n_r_chunk=n_r_chunk\n",
    "                                                    )\n",
    "    logger.info('loading idx into memory.')\n",
    "    idx = zarr.open(idx,mode='r')[:]\n",
    "    n_pc = idx.shape[1]\n",
    "    \n",
    "    if isinstance(pc,str):\n",
    "        assert isinstance(ras,str)\n",
    "        pc_list = [pc]; ras_list = [ras]\n",
    "    else:\n",
    "        assert isinstance(pc,list); assert isinstance(ras,list)\n",
    "        pc_list = pc; ras_list = ras\n",
    "\n",
    "    logger.info('starting dask local cluster.')\n",
    "    with LocalCluster() as cluster, Client(cluster) as client:\n",
    "        logger.info('dask local cluster started.')\n",
    "\n",
    "        _ras_list = ()\n",
    "\n",
    "        for ras_path, pc_path in zip(ras_list,pc_list):\n",
    "            logger.info(f'start to work on {pc_path}')\n",
    "            pc_zarr = zarr.open(pc_path,'r')\n",
    "            logger.zarr_info(pc_path,pc_zarr)\n",
    "\n",
    "            pc = da.from_zarr(pc_path)\n",
    "            logger.darr_info('pc', pc)\n",
    "            ras = da.empty((shape[0]*shape[1],*pc.shape[1:]),chunks = (chunk_size[0]*shape[1],*pc_zarr.chunks[1:]), dtype=pc.dtype)\n",
    "            ras[:] = np.nan\n",
    "            ras[np.ravel_multi_index((idx[0],idx[1]),dims=shape)] = pc\n",
    "            ras = ras.reshape(*shape,*pc.shape[1:])\n",
    "            ras.rechunk((*chunk_size,*pc_zarr.chunks[1:]))\n",
    "            logger.info('create ras dask array')\n",
    "            logger.darr_info('ras', ras)\n",
    "            _ras = ras.to_zarr(ras_path,overwrite=True,compute=False)\n",
    "            _ras_list += (_ras,)\n",
    "\n",
    "        logger.info('computing graph setted. doing all the computing.')\n",
    "        futures = client.persist(_ras_list)\n",
    "        progress(futures,notebook=False)\n",
    "        da.compute(futures)\n",
    "        logger.info('computing finished.')\n",
    "\n",
    "    logger.info('dask cluster closed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f998e06-f4f2-4d2a-816b-c6ca8b5c8492",
   "metadata": {},
   "source": [
    "Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff5e158-5b51-4182-bc09-10481e605d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_data1 = np.random.rand(1000).astype(np.float32)\n",
    "pc_data2 = np.random.rand(1000,3).astype(np.float32)+1j*np.random.rand(1000,3).astype(np.float32)\n",
    "\n",
    "idx = np.random.choice(np.arange(100*100,dtype=np.int32),size=1000,replace=False)\n",
    "idx.sort()\n",
    "idx = np.stack(np.unravel_index(idx,shape=(100,100))).astype(np.int32)\n",
    "\n",
    "ras_data1 = np.zeros((100,100),dtype=np.float32)\n",
    "ras_data2 = np.zeros((100,100,3),dtype=np.complex64)\n",
    "ras_data1[:] = np.nan\n",
    "ras_data2[:] = np.nan\n",
    "\n",
    "ras_data1[idx[0],idx[1]] = pc_data1\n",
    "ras_data2[idx[0],idx[1]] = pc_data2\n",
    "\n",
    "idx_zarr = zarr.open('pc/idx.zarr','w',shape=idx.shape,dtype=idx.dtype,chunks=(2,200))\n",
    "pc_zarr1 = zarr.open('pc/pc1.zarr','w',shape=pc_data1.shape,dtype=pc_data1.dtype,chunks=(200,))\n",
    "pc_zarr2 = zarr.open('pc/pc2.zarr','w',shape=pc_data2.shape,dtype=pc_data2.dtype,chunks=(200,1))\n",
    "idx_zarr[:] = idx\n",
    "pc_zarr1[:] = pc_data1\n",
    "pc_zarr2[:] = pc_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7cb6b1-5a9d-4cde-8c76-0b0fb8bf4d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-05 02:45:32 - logging_args - INFO - running function: de_pc2ras\n",
      "2023-11-05 02:45:32 - logging_args - INFO - fetching args:\n",
      "2023-11-05 02:45:32 - logging_args - INFO - idx = 'pc/idx.zarr'\n",
      "2023-11-05 02:45:32 - logging_args - INFO - pc = 'pc/pc1.zarr'\n",
      "2023-11-05 02:45:32 - logging_args - INFO - ras = 'pc/ras1.zarr'\n",
      "2023-11-05 02:45:32 - logging_args - INFO - shape = (100, 100)\n",
      "2023-11-05 02:45:32 - logging_args - INFO - az_chunk_size = 20\n",
      "2023-11-05 02:45:32 - logging_args - INFO - n_az_chunk = None\n",
      "2023-11-05 02:45:32 - logging_args - INFO - r_chunk_size = None\n",
      "2023-11-05 02:45:32 - logging_args - INFO - n_r_chunk = None\n",
      "2023-11-05 02:45:32 - logging_args - INFO - fetching args done.\n",
      "2023-11-05 02:45:32 - zarr_info - INFO - idx zarray shape: (2, 1000)\n",
      "2023-11-05 02:45:32 - zarr_info - INFO - idx zarray chunks: (2, 200)\n",
      "2023-11-05 02:45:32 - zarr_info - INFO - idx zarray dtype: int32\n",
      "2023-11-05 02:45:32 - get_ras_chunk_size_from_n_pc_chunk - INFO - automatically set r_chunk_size to nlines of ras\n",
      "2023-11-05 02:45:32 - get_ras_chunk_size_from_n_pc_chunk - INFO - got az_chunk_size for ras: 20\n",
      "2023-11-05 02:45:32 - de_pc2ras - INFO - loading idx into memory.\n",
      "2023-11-05 02:45:32 - de_pc2ras - INFO - starting dask local cluster.\n",
      "2023-11-05 02:45:36 - de_pc2ras - INFO - dask local cluster started.\n",
      "2023-11-05 02:45:36 - de_pc2ras - INFO - start to work on pc/pc1.zarr\n",
      "2023-11-05 02:45:36 - zarr_info - INFO - pc/pc1.zarr zarray shape: (1000,)\n",
      "2023-11-05 02:45:36 - zarr_info - INFO - pc/pc1.zarr zarray chunks: (200,)\n",
      "2023-11-05 02:45:36 - zarr_info - INFO - pc/pc1.zarr zarray dtype: float32\n",
      "2023-11-05 02:45:36 - darr_info - INFO - pc dask array shape: (1000,)\n",
      "2023-11-05 02:45:36 - darr_info - INFO - pc dask array chunksize: (200,)\n",
      "2023-11-05 02:45:36 - darr_info - INFO - pc dask array dtype: float32\n",
      "2023-11-05 02:45:36 - de_pc2ras - INFO - create ras dask array\n",
      "2023-11-05 02:45:36 - darr_info - INFO - ras dask array shape: (100, 100)\n",
      "2023-11-05 02:45:36 - darr_info - INFO - ras dask array chunksize: (20, 100)\n",
      "2023-11-05 02:45:36 - darr_info - INFO - ras dask array dtype: float32\n",
      "2023-11-05 02:45:36 - de_pc2ras - INFO - computing graph setted. doing all the computing.\n",
      "2023-11-05 02:45:37 - de_pc2ras - INFO - computing finished.|  0.9s\u001b[2K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 02:45:37,146 - distributed.worker - ERROR - Unexpected exception during heartbeat. Closing worker.\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/kangl/miniforge3/envs/work/lib/python3.10/site-packages/distributed/worker.py\", line 1253, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/users/kangl/miniforge3/envs/work/lib/python3.10/site-packages/distributed/utils_comm.py\", line 454, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/users/kangl/miniforge3/envs/work/lib/python3.10/site-packages/distributed/utils_comm.py\", line 433, in retry\n",
      "    return await coro()\n",
      "  File \"/users/kangl/miniforge3/envs/work/lib/python3.10/site-packages/distributed/core.py\", line 1344, in send_recv_from_rpc\n",
      "    comm = await self.pool.connect(self.addr)\n",
      "  File \"/users/kangl/miniforge3/envs/work/lib/python3.10/site-packages/distributed/core.py\", line 1543, in connect\n",
      "    raise RuntimeError(\"ConnectionPool is closed\")\n",
      "RuntimeError: ConnectionPool is closed\n",
      "2023-11-05 02:45:37,147 - tornado.application - ERROR - Exception in callback <bound method Worker.heartbeat of <Worker 'tcp://127.0.0.1:43929', name: 13, status: closed, stored: 0, running: 0/8, ready: 0, comm: 0, waiting: 0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/kangl/miniforge3/envs/work/lib/python3.10/site-packages/tornado/ioloop.py\", line 921, in _run\n",
      "    await val\n",
      "  File \"/users/kangl/miniforge3/envs/work/lib/python3.10/site-packages/distributed/worker.py\", line 1253, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/users/kangl/miniforge3/envs/work/lib/python3.10/site-packages/distributed/utils_comm.py\", line 454, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/users/kangl/miniforge3/envs/work/lib/python3.10/site-packages/distributed/utils_comm.py\", line 433, in retry\n",
      "    return await coro()\n",
      "  File \"/users/kangl/miniforge3/envs/work/lib/python3.10/site-packages/distributed/core.py\", line 1344, in send_recv_from_rpc\n",
      "    comm = await self.pool.connect(self.addr)\n",
      "  File \"/users/kangl/miniforge3/envs/work/lib/python3.10/site-packages/distributed/core.py\", line 1543, in connect\n",
      "    raise RuntimeError(\"ConnectionPool is closed\")\n",
      "RuntimeError: ConnectionPool is closed\n",
      "2023-11-05 02:45:37,149 - distributed.worker - ERROR - Unexpected exception during heartbeat. Closing worker.\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/kangl/miniforge3/envs/work/lib/python3.10/site-packages/distributed/worker.py\", line 1253, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/users/kangl/miniforge3/envs/work/lib/python3.10/site-packages/distributed/utils_comm.py\", line 454, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/users/kangl/miniforge3/envs/work/lib/python3.10/site-packages/distributed/utils_comm.py\", line 433, in retry\n",
      "    return await coro()\n",
      "  File \"/users/kangl/miniforge3/envs/work/lib/python3.10/site-packages/distributed/core.py\", line 1344, in send_recv_from_rpc\n",
      "    comm = await self.pool.connect(self.addr)\n",
      "  File \"/users/kangl/miniforge3/envs/work/lib/python3.10/site-packages/distributed/core.py\", line 1543, in connect\n",
      "    raise RuntimeError(\"ConnectionPool is closed\")\n",
      "RuntimeError: ConnectionPool is closed\n",
      "2023-11-05 02:45:37,150 - tornado.application - ERROR - Exception in callback <bound method Worker.heartbeat of <Worker 'tcp://127.0.0.1:34629', name: 11, status: closed, stored: 0, running: 0/8, ready: 0, comm: 0, waiting: 0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/kangl/miniforge3/envs/work/lib/python3.10/site-packages/tornado/ioloop.py\", line 921, in _run\n",
      "    await val\n",
      "  File \"/users/kangl/miniforge3/envs/work/lib/python3.10/site-packages/distributed/worker.py\", line 1253, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/users/kangl/miniforge3/envs/work/lib/python3.10/site-packages/distributed/utils_comm.py\", line 454, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/users/kangl/miniforge3/envs/work/lib/python3.10/site-packages/distributed/utils_comm.py\", line 433, in retry\n",
      "    return await coro()\n",
      "  File \"/users/kangl/miniforge3/envs/work/lib/python3.10/site-packages/distributed/core.py\", line 1344, in send_recv_from_rpc\n",
      "    comm = await self.pool.connect(self.addr)\n",
      "  File \"/users/kangl/miniforge3/envs/work/lib/python3.10/site-packages/distributed/core.py\", line 1543, in connect\n",
      "    raise RuntimeError(\"ConnectionPool is closed\")\n",
      "RuntimeError: ConnectionPool is closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-05 02:45:37 - de_pc2ras - INFO - dask cluster closed.\n",
      "2023-11-05 02:45:37 - logging_args - INFO - running function: de_pc2ras\n",
      "2023-11-05 02:45:37 - logging_args - INFO - fetching args:\n",
      "2023-11-05 02:45:37 - logging_args - INFO - idx = 'pc/idx.zarr'\n",
      "2023-11-05 02:45:37 - logging_args - INFO - pc = ['pc/pc1.zarr', 'pc/pc2.zarr']\n",
      "2023-11-05 02:45:37 - logging_args - INFO - ras = ['pc/ras1.zarr', 'pc/ras2.zarr']\n",
      "2023-11-05 02:45:37 - logging_args - INFO - shape = (100, 100)\n",
      "2023-11-05 02:45:37 - logging_args - INFO - az_chunk_size = 20\n",
      "2023-11-05 02:45:37 - logging_args - INFO - n_az_chunk = None\n",
      "2023-11-05 02:45:37 - logging_args - INFO - r_chunk_size = None\n",
      "2023-11-05 02:45:37 - logging_args - INFO - n_r_chunk = None\n",
      "2023-11-05 02:45:37 - logging_args - INFO - fetching args done.\n",
      "2023-11-05 02:45:37 - zarr_info - INFO - idx zarray shape: (2, 1000)\n",
      "2023-11-05 02:45:37 - zarr_info - INFO - idx zarray chunks: (2, 200)\n",
      "2023-11-05 02:45:37 - zarr_info - INFO - idx zarray dtype: int32\n",
      "2023-11-05 02:45:37 - get_ras_chunk_size_from_n_pc_chunk - INFO - automatically set r_chunk_size to nlines of ras\n",
      "2023-11-05 02:45:37 - get_ras_chunk_size_from_n_pc_chunk - INFO - got az_chunk_size for ras: 20\n",
      "2023-11-05 02:45:37 - de_pc2ras - INFO - loading idx into memory.\n",
      "2023-11-05 02:45:37 - de_pc2ras - INFO - starting dask local cluster.\n",
      "2023-11-05 02:45:40 - de_pc2ras - INFO - dask local cluster started.\n",
      "2023-11-05 02:45:40 - de_pc2ras - INFO - start to work on pc/pc1.zarr\n",
      "2023-11-05 02:45:40 - zarr_info - INFO - pc/pc1.zarr zarray shape: (1000,)\n",
      "2023-11-05 02:45:40 - zarr_info - INFO - pc/pc1.zarr zarray chunks: (200,)\n",
      "2023-11-05 02:45:40 - zarr_info - INFO - pc/pc1.zarr zarray dtype: float32\n",
      "2023-11-05 02:45:40 - darr_info - INFO - pc dask array shape: (1000,)\n",
      "2023-11-05 02:45:40 - darr_info - INFO - pc dask array chunksize: (200,)\n",
      "2023-11-05 02:45:40 - darr_info - INFO - pc dask array dtype: float32\n",
      "2023-11-05 02:45:40 - de_pc2ras - INFO - create ras dask array\n",
      "2023-11-05 02:45:40 - darr_info - INFO - ras dask array shape: (100, 100)\n",
      "2023-11-05 02:45:40 - darr_info - INFO - ras dask array chunksize: (20, 100)\n",
      "2023-11-05 02:45:40 - darr_info - INFO - ras dask array dtype: float32\n",
      "2023-11-05 02:45:40 - de_pc2ras - INFO - start to work on pc/pc2.zarr\n",
      "2023-11-05 02:45:40 - zarr_info - INFO - pc/pc2.zarr zarray shape: (1000, 3)\n",
      "2023-11-05 02:45:40 - zarr_info - INFO - pc/pc2.zarr zarray chunks: (200, 1)\n",
      "2023-11-05 02:45:40 - zarr_info - INFO - pc/pc2.zarr zarray dtype: complex64\n",
      "2023-11-05 02:45:40 - darr_info - INFO - pc dask array shape: (1000, 3)\n",
      "2023-11-05 02:45:40 - darr_info - INFO - pc dask array chunksize: (200, 1)\n",
      "2023-11-05 02:45:40 - darr_info - INFO - pc dask array dtype: complex64\n",
      "2023-11-05 02:45:40 - de_pc2ras - INFO - create ras dask array\n",
      "2023-11-05 02:45:40 - darr_info - INFO - ras dask array shape: (100, 100, 3)\n",
      "2023-11-05 02:45:40 - darr_info - INFO - ras dask array chunksize: (20, 100, 1)\n",
      "2023-11-05 02:45:40 - darr_info - INFO - ras dask array dtype: complex64\n",
      "2023-11-05 02:45:40 - de_pc2ras - INFO - computing graph setted. doing all the computing.\n",
      "2023-11-05 02:45:41 - de_pc2ras - INFO - computing finished.|  0.9s\u001b[2K\n",
      "2023-11-05 02:45:42 - de_pc2ras - INFO - dask cluster closed.\n"
     ]
    }
   ],
   "source": [
    "de_pc2ras('pc/idx.zarr','pc/pc1.zarr','pc/ras1.zarr',shape=(100,100),az_chunk_size=20)\n",
    "ras_zarr1 = zarr.open('pc/ras1.zarr','r')\n",
    "np.testing.assert_array_equal(ras_data1,ras_zarr1[:])\n",
    "\n",
    "de_pc2ras('pc/idx.zarr',['pc/pc1.zarr','pc/pc2.zarr'],['pc/ras1.zarr','pc/ras2.zarr'],shape=(100,100),az_chunk_size=20)\n",
    "ras_zarr1 = zarr.open('pc/ras1.zarr','r')\n",
    "ras_zarr2 = zarr.open('pc/ras2.zarr','r')\n",
    "np.testing.assert_array_equal(ras_data1,ras_zarr1[:])\n",
    "np.testing.assert_array_equal(ras_data2,ras_zarr2[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bae521-e1b0-4b4d-82eb-699964597b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@call_parse\n",
    "@log_args\n",
    "@de_logger\n",
    "def de_pc_union(idx1:str, # index of the first point cloud\n",
    "                idx2:str, # index of the second point cloud\n",
    "                idx:str, # output, index of the union point cloud\n",
    "                pc1:str|list=None, # path (in string) or list of path for the first point cloud data\n",
    "                pc2:str|list=None, # path (in string) or list of path for the second point cloud data\n",
    "                pc:str|list=None, #output, path (in string) or list of path for the union point cloud data\n",
    "                pc_chunk_size:int=None, # chunk size in output data,optional\n",
    "                n_pc_chunk:int=None, # number of chunk in output data, optional\n",
    "):\n",
    "    '''Get the union of two point cloud dataset.\n",
    "    For points at their intersection, pc_data1 rather than pc_data2 is copied to the result pc_data.\n",
    "    `pc_chunk_size` and `n_pc_chunk` are used to determine the final pc_chunk_size.\n",
    "    If non of them are provided, the pc_chunk_size is setted as it in idx1.\n",
    "    '''\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    idx1_zarr = zarr.open(idx1,mode='r'); logger.zarr_info(idx1,idx1_zarr)\n",
    "    idx2_zarr = zarr.open(idx2,mode='r'); logger.zarr_info(idx2,idx2_zarr)\n",
    "    logger.info('loading idx1 and idx2 into memory.')\n",
    "    idx1 = idx1_zarr[:]; idx2 = idx2_zarr[:]\n",
    "\n",
    "    logger.info('calculate the union')\n",
    "    idx_path = idx\n",
    "    idx, inv_iidx1, inv_iidx2, iidx2 = pc_union(idx1,idx2)\n",
    "    n_pc = idx.shape[1]\n",
    "    logger.info(f'number of points in the union: {idx.shape[1]}')\n",
    "    pc_chunk_size = get_pc_chunk_size_from_pc_chunk_size('idx1','idx',\n",
    "                                                         idx1_zarr.chunks[1],\n",
    "                                                         n_pc,\n",
    "                                                         pc_chunk_size=pc_chunk_size,n_pc_chunk=n_pc_chunk)\n",
    "    \n",
    "    idx_zarr = zarr.open(idx_path,'w',shape=idx.shape,dtype=idx.dtype,chunks=(2,pc_chunk_size))\n",
    "    logger.info('write union idx')\n",
    "    idx_zarr[:] = idx\n",
    "    logger.info('write done')\n",
    "    logger.zarr_info(idx_path, idx_zarr)\n",
    "    \n",
    "    if pc1 is None:\n",
    "        logger.info('no point cloud data provided, exit.')\n",
    "        return None\n",
    "\n",
    "    if isinstance(pc1,str):\n",
    "        assert isinstance(pc2,str); assert isinstance(pc,str)\n",
    "        pc1_list = [pc1]; pc2_list = [pc2]; pc_list = [pc]\n",
    "    else:\n",
    "        assert isinstance(pc1,list); assert isinstance(pc2,list); assert isinstance(pc,list)\n",
    "        pc1_list = pc1; pc2_list = pc2; pc_list = pc\n",
    "\n",
    "    logger.info('starting dask local cluster.')\n",
    "    with LocalCluster() as cluster, Client(cluster) as client:\n",
    "        logger.info('dask local cluster started.')\n",
    "\n",
    "        _pc_list = ()\n",
    "        for pc1_path, pc2_path, pc_path in zip(pc1_list,pc2_list,pc_list):\n",
    "            pc1_zarr = zarr.open(pc1_path,'r'); pc2_zarr = zarr.open(pc2_path,'r')\n",
    "            logger.zarr_info(pc1_path, pc1_zarr); logger.zarr_info(pc2_path, pc2_zarr);\n",
    "            pc1 = da.from_zarr(pc1_path); pc2 = da.from_zarr(pc2_path)\n",
    "            logger.darr_info('pc1', pc1); logger.darr_info('pc2',pc2)\n",
    "            logger.info('set up union pc data dask array.')\n",
    "            pc = da.empty((n_pc,*pc1.shape[1:]),chunks = (pc_chunk_size,*pc1.chunks[1:]), dtype=pc1.dtype)\n",
    "            logger.darr_info('pc',pc)\n",
    "            pc[inv_iidx1] = pc1\n",
    "            pc[inv_iidx2] = pc2[iidx2]\n",
    "            _pc = pc.to_zarr(pc_path, overwrite=True,compute=False)\n",
    "            _pc_list += (_pc,)\n",
    "\n",
    "        logger.info('computing graph setted. doing all the computing.')\n",
    "        futures = client.persist(_pc_list)\n",
    "        progress(futures,notebook=False)\n",
    "        da.compute(futures)\n",
    "        logger.info('computing finished.')\n",
    "\n",
    "    logger.info('dask cluster closed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16bf1ca-6d42-4265-9fc6-0440e217a807",
   "metadata": {},
   "source": [
    "Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61804e8c-9fd9-4f91-9d2e-75b327b4f11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_data1 = np.random.rand(1000,3).astype(np.float32)+1j*np.random.rand(1000,3).astype(np.float32)\n",
    "pc_data2 = np.random.rand(800,3).astype(np.float32)+1j*np.random.rand(800,3).astype(np.float32)\n",
    "\n",
    "idx1 = np.random.choice(np.arange(100*100,dtype=np.int32),size=1000,replace=False)\n",
    "idx1.sort()\n",
    "idx1 = np.stack(np.unravel_index(idx1,shape=(100,100))).astype(np.int32)\n",
    "\n",
    "idx2 = np.random.choice(np.arange(100*100,dtype=np.int32),size=800,replace=False)\n",
    "idx2.sort()\n",
    "idx2 = np.stack(np.unravel_index(idx2,shape=(100,100))).astype(np.int32)\n",
    "\n",
    "idx, inv_iidx1, inv_iidx2, iidx2 = pc_union(idx1,idx2)\n",
    "\n",
    "pc_data = np.empty((idx.shape[1],*pc_data1.shape[1:]),dtype=pc_data1.dtype)\n",
    "pc_data[inv_iidx1] = pc_data1\n",
    "pc_data[inv_iidx2] = pc_data2[iidx2]\n",
    "\n",
    "idx1_zarr = zarr.open('pc/idx1.zarr','w',shape=idx1.shape,dtype=idx1.dtype,chunks=(2,200))\n",
    "idx2_zarr = zarr.open('pc/idx2.zarr','w',shape=idx2.shape,dtype=idx2.dtype,chunks=(2,200))\n",
    "pc1_zarr = zarr.open('pc/pc1.zarr','w',shape=pc_data1.shape,dtype=pc_data1.dtype,chunks=(200,1))\n",
    "pc2_zarr = zarr.open('pc/pc2.zarr','w',shape=pc_data2.shape,dtype=pc_data2.dtype,chunks=(200,1))\n",
    "idx1_zarr[:] = idx1\n",
    "idx2_zarr[:] = idx2\n",
    "pc1_zarr[:] = pc_data1\n",
    "pc2_zarr[:] = pc_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32ea61e-8437-4fa8-b6ed-844040dc293c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-05 02:45:44 - logging_args - INFO - running function: de_pc_union\n",
      "2023-11-05 02:45:44 - logging_args - INFO - fetching args:\n",
      "2023-11-05 02:45:44 - logging_args - INFO - idx1 = 'pc/idx1.zarr'\n",
      "2023-11-05 02:45:44 - logging_args - INFO - idx2 = 'pc/idx2.zarr'\n",
      "2023-11-05 02:45:44 - logging_args - INFO - idx = 'pc/idx.zarr'\n",
      "2023-11-05 02:45:44 - logging_args - INFO - pc1 = None\n",
      "2023-11-05 02:45:44 - logging_args - INFO - pc2 = None\n",
      "2023-11-05 02:45:44 - logging_args - INFO - pc = None\n",
      "2023-11-05 02:45:44 - logging_args - INFO - pc_chunk_size = None\n",
      "2023-11-05 02:45:44 - logging_args - INFO - n_pc_chunk = None\n",
      "2023-11-05 02:45:44 - logging_args - INFO - fetching args done.\n",
      "2023-11-05 02:45:44 - zarr_info - INFO - pc/idx1.zarr zarray shape: (2, 1000)\n",
      "2023-11-05 02:45:44 - zarr_info - INFO - pc/idx1.zarr zarray chunks: (2, 200)\n",
      "2023-11-05 02:45:44 - zarr_info - INFO - pc/idx1.zarr zarray dtype: int32\n",
      "2023-11-05 02:45:44 - zarr_info - INFO - pc/idx2.zarr zarray shape: (2, 800)\n",
      "2023-11-05 02:45:44 - zarr_info - INFO - pc/idx2.zarr zarray chunks: (2, 200)\n",
      "2023-11-05 02:45:44 - zarr_info - INFO - pc/idx2.zarr zarray dtype: int32\n",
      "2023-11-05 02:45:44 - de_pc_union - INFO - loading idx1 and idx2 into memory.\n",
      "2023-11-05 02:45:44 - de_pc_union - INFO - calculate the union\n",
      "2023-11-05 02:45:44 - de_pc_union - INFO - number of points in the union: 1711\n",
      "2023-11-05 02:45:44 - get_pc_chunk_size_from_pc_chunk_size - INFO - automatically determine pc_chunk_size from\n",
      "            pc_chunk_size of idx1.\n",
      "2023-11-05 02:45:44 - get_pc_chunk_size_from_pc_chunk_size - INFO - pc_chunk_size for idx: 200\n",
      "2023-11-05 02:45:44 - de_pc_union - INFO - write union idx\n",
      "2023-11-05 02:45:44 - de_pc_union - INFO - write done\n",
      "2023-11-05 02:45:44 - zarr_info - INFO - pc/idx.zarr zarray shape: (2, 1711)\n",
      "2023-11-05 02:45:44 - zarr_info - INFO - pc/idx.zarr zarray chunks: (2, 200)\n",
      "2023-11-05 02:45:44 - zarr_info - INFO - pc/idx.zarr zarray dtype: int32\n",
      "2023-11-05 02:45:44 - de_pc_union - INFO - no point cloud data provided, exit.\n",
      "2023-11-05 02:45:44 - logging_args - INFO - running function: de_pc_union\n",
      "2023-11-05 02:45:44 - logging_args - INFO - fetching args:\n",
      "2023-11-05 02:45:44 - logging_args - INFO - idx1 = 'pc/idx1.zarr'\n",
      "2023-11-05 02:45:44 - logging_args - INFO - idx2 = 'pc/idx2.zarr'\n",
      "2023-11-05 02:45:44 - logging_args - INFO - idx = 'pc/idx.zarr'\n",
      "2023-11-05 02:45:44 - logging_args - INFO - pc1 = 'pc/pc1.zarr'\n",
      "2023-11-05 02:45:44 - logging_args - INFO - pc2 = 'pc/pc2.zarr'\n",
      "2023-11-05 02:45:44 - logging_args - INFO - pc = 'pc/pc.zarr'\n",
      "2023-11-05 02:45:44 - logging_args - INFO - pc_chunk_size = None\n",
      "2023-11-05 02:45:44 - logging_args - INFO - n_pc_chunk = None\n",
      "2023-11-05 02:45:44 - logging_args - INFO - fetching args done.\n",
      "2023-11-05 02:45:44 - zarr_info - INFO - pc/idx1.zarr zarray shape: (2, 1000)\n",
      "2023-11-05 02:45:44 - zarr_info - INFO - pc/idx1.zarr zarray chunks: (2, 200)\n",
      "2023-11-05 02:45:44 - zarr_info - INFO - pc/idx1.zarr zarray dtype: int32\n",
      "2023-11-05 02:45:44 - zarr_info - INFO - pc/idx2.zarr zarray shape: (2, 800)\n",
      "2023-11-05 02:45:44 - zarr_info - INFO - pc/idx2.zarr zarray chunks: (2, 200)\n",
      "2023-11-05 02:45:44 - zarr_info - INFO - pc/idx2.zarr zarray dtype: int32\n",
      "2023-11-05 02:45:44 - de_pc_union - INFO - loading idx1 and idx2 into memory.\n",
      "2023-11-05 02:45:44 - de_pc_union - INFO - calculate the union\n",
      "2023-11-05 02:45:44 - de_pc_union - INFO - number of points in the union: 1711\n",
      "2023-11-05 02:45:44 - get_pc_chunk_size_from_pc_chunk_size - INFO - automatically determine pc_chunk_size from\n",
      "            pc_chunk_size of idx1.\n",
      "2023-11-05 02:45:44 - get_pc_chunk_size_from_pc_chunk_size - INFO - pc_chunk_size for idx: 200\n",
      "2023-11-05 02:45:44 - de_pc_union - INFO - write union idx\n",
      "2023-11-05 02:45:45 - de_pc_union - INFO - write done\n",
      "2023-11-05 02:45:45 - zarr_info - INFO - pc/idx.zarr zarray shape: (2, 1711)\n",
      "2023-11-05 02:45:45 - zarr_info - INFO - pc/idx.zarr zarray chunks: (2, 200)\n",
      "2023-11-05 02:45:45 - zarr_info - INFO - pc/idx.zarr zarray dtype: int32\n",
      "2023-11-05 02:45:45 - de_pc_union - INFO - starting dask local cluster.\n",
      "2023-11-05 02:45:48 - de_pc_union - INFO - dask local cluster started.\n",
      "2023-11-05 02:45:48 - zarr_info - INFO - pc/pc1.zarr zarray shape: (1000, 3)\n",
      "2023-11-05 02:45:48 - zarr_info - INFO - pc/pc1.zarr zarray chunks: (200, 1)\n",
      "2023-11-05 02:45:48 - zarr_info - INFO - pc/pc1.zarr zarray dtype: complex64\n",
      "2023-11-05 02:45:48 - zarr_info - INFO - pc/pc2.zarr zarray shape: (800, 3)\n",
      "2023-11-05 02:45:48 - zarr_info - INFO - pc/pc2.zarr zarray chunks: (200, 1)\n",
      "2023-11-05 02:45:48 - zarr_info - INFO - pc/pc2.zarr zarray dtype: complex64\n",
      "2023-11-05 02:45:48 - darr_info - INFO - pc1 dask array shape: (1000, 3)\n",
      "2023-11-05 02:45:48 - darr_info - INFO - pc1 dask array chunksize: (200, 1)\n",
      "2023-11-05 02:45:48 - darr_info - INFO - pc1 dask array dtype: complex64\n",
      "2023-11-05 02:45:48 - darr_info - INFO - pc2 dask array shape: (800, 3)\n",
      "2023-11-05 02:45:48 - darr_info - INFO - pc2 dask array chunksize: (200, 1)\n",
      "2023-11-05 02:45:48 - darr_info - INFO - pc2 dask array dtype: complex64\n",
      "2023-11-05 02:45:48 - de_pc_union - INFO - set up union pc data dask array.\n",
      "2023-11-05 02:45:48 - darr_info - INFO - pc dask array shape: (1711, 3)\n",
      "2023-11-05 02:45:48 - darr_info - INFO - pc dask array chunksize: (200, 1)\n",
      "2023-11-05 02:45:48 - darr_info - INFO - pc dask array dtype: complex64\n",
      "2023-11-05 02:45:48 - de_pc_union - INFO - computing graph setted. doing all the computing.\n",
      "2023-11-05 02:45:49 - de_pc_union - INFO - computing finished. 1.0s\u001b[2K\n",
      "2023-11-05 02:45:49 - de_pc_union - INFO - dask cluster closed.\n"
     ]
    }
   ],
   "source": [
    "de_pc_union('pc/idx1.zarr','pc/idx2.zarr','pc/idx.zarr')\n",
    "de_pc_union('pc/idx1.zarr','pc/idx2.zarr','pc/idx.zarr','pc/pc1.zarr','pc/pc2.zarr','pc/pc.zarr')\n",
    "idx_zarr = zarr.open('pc/idx.zarr','r')\n",
    "pc_zarr = zarr.open('pc/pc.zarr','r')\n",
    "np.testing.assert_array_equal(idx_zarr[:],idx)\n",
    "np.testing.assert_array_equal(pc_zarr[:],pc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e165db47-38a1-4ce9-870f-4d27f79bd848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@call_parse\n",
    "@log_args\n",
    "@de_logger\n",
    "def de_pc_intersect(idx1:str, # index of the first point cloud\n",
    "                    idx2:str, # index of the second point cloud\n",
    "                    idx:str, # output, index of the union point cloud\n",
    "                    pc1:str|list=None, # path (in string) or list of path for the first point cloud data\n",
    "                    pc2:str|list=None, # path (in string) or list of path for the second point cloud data\n",
    "                    pc:str|list=None, #output, path (in string) or list of path for the union point cloud data\n",
    "                    pc_chunk_size:int=None, # chunk size in output data,optional\n",
    "                    n_pc_chunk:int=None, # number of chunk in output data, optional\n",
    "                    prefer_1=True, # save pc1 on intersection to output pc dataset by default `True`. Otherwise, save data from pc2\n",
    "):\n",
    "    '''Get the intersection of two point cloud dataset.\n",
    "    `pc_chunk_size` and `n_pc_chunk` are used to determine the final pc_chunk_size.\n",
    "    If non of them are provided, the n_pc_chunk is set to n_chunk in idx1.\n",
    "    '''\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    idx1_zarr = zarr.open(idx1,mode='r'); logger.zarr_info(idx1,idx1_zarr)\n",
    "    idx2_zarr = zarr.open(idx2,mode='r'); logger.zarr_info(idx2,idx2_zarr)\n",
    "    logger.info('loading idx1 and idx2 into memory.')\n",
    "    idx1 = idx1_zarr[:]; idx2 = idx2_zarr[:]\n",
    "\n",
    "    logger.info('calculate the intersection')\n",
    "    idx_path = idx\n",
    "    idx, iidx1, iidx2 = pc_intersect(idx1,idx2)\n",
    "    n_pc = idx.shape[1]\n",
    "    logger.info(f'number of points in the intersection: {idx.shape[1]}')\n",
    "    pc_chunk_size = get_pc_chunk_size_from_n_pc_chunk('idx1','idx',idx1_zarr.shape[1],idx1_zarr.chunks[1],n_pc,pc_chunk_size=pc_chunk_size,n_pc_chunk=n_pc_chunk)\n",
    "    \n",
    "    idx_zarr = zarr.open(idx_path,'w',shape=idx.shape,dtype=idx.dtype,chunks=(2,pc_chunk_size))\n",
    "    logger.info('write intersect idx')\n",
    "    idx_zarr[:] = idx\n",
    "    logger.info('write done')\n",
    "    logger.zarr_info(idx_path, idx_zarr)\n",
    "\n",
    "    if (pc1 is None) and (pc2 is None):\n",
    "        logger.info('no point cloud data provided, exit.')\n",
    "        return None\n",
    "\n",
    "    if prefer_1:\n",
    "        logger.info('select pc1 as pc_input.')\n",
    "        iidx = iidx1; pc_input = pc1\n",
    "    else:\n",
    "        logger.info('select pc2 as pc_input.')\n",
    "        iidx = iidx2; pc_input = pc2\n",
    "\n",
    "    if isinstance(pc_input,str):\n",
    "        assert isinstance(pc,str)\n",
    "        pc_input_list = [pc_input]; pc_list = [pc]\n",
    "    else:\n",
    "        assert isinstance(pc_input,list); assert isinstance(pc,list)\n",
    "        pc_input_list = pc_input; pc_list = pc\n",
    "\n",
    "    logger.info('starting dask local cluster.')\n",
    "    with LocalCluster() as cluster, Client(cluster) as client:\n",
    "        logger.info('dask local cluster started.')\n",
    "\n",
    "        _pc_list = ()\n",
    "        for pc_input_path, pc_path in zip(pc_input_list,pc_list):\n",
    "            pc_input_zarr = zarr.open(pc_input_path,'r')\n",
    "            logger.zarr_info(pc_input_path,pc_input_zarr)\n",
    "            pc_input = da.from_zarr(pc_input_path)\n",
    "            logger.darr_info('pc_input', pc_input)\n",
    "\n",
    "            logger.info('set up intersect pc data dask array.')\n",
    "            pc = da.empty((n_pc,*pc_input.shape[1:]),chunks = (pc_chunk_size,*pc_input.chunks[1:]), dtype=pc_input.dtype)\n",
    "            logger.darr_info('pc',pc)\n",
    "            pc[:] = pc_input[iidx]\n",
    "            _pc = pc.to_zarr(pc_path, overwrite=True,compute=False)\n",
    "            _pc_list += (_pc,)\n",
    "\n",
    "        logger.info('computing graph setted. doing all the computing.')\n",
    "        futures = client.persist(_pc_list)\n",
    "        progress(futures,notebook=False)\n",
    "        da.compute(futures)\n",
    "        logger.info('computing finished.')\n",
    "    logger.info('dask cluster closed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d15aec-f241-4fcf-96e0-c839994ac04b",
   "metadata": {},
   "source": [
    "Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5e1d41-a087-4bdd-9e17-fa3021fc0045",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_data1 = np.random.rand(1000,3).astype(np.float32)+1j*np.random.rand(1000,3).astype(np.float32)\n",
    "pc_data2 = np.random.rand(800,3).astype(np.float32)+1j*np.random.rand(800,3).astype(np.float32)\n",
    "\n",
    "idx1 = np.random.choice(np.arange(100*100,dtype=np.int32),size=1000,replace=False)\n",
    "idx1.sort()\n",
    "idx1 = np.stack(np.unravel_index(idx1,shape=(100,100))).astype(np.int32)\n",
    "\n",
    "idx2 = np.random.choice(np.arange(100*100,dtype=np.int32),size=800,replace=False)\n",
    "idx2.sort()\n",
    "idx2 = np.stack(np.unravel_index(idx2,shape=(100,100))).astype(np.int32)\n",
    "\n",
    "idx, iidx1, iidx2 = pc_intersect(idx1,idx2)\n",
    "\n",
    "pc_data = np.empty((idx.shape[1],*pc_data1.shape[1:]),dtype=pc_data1.dtype)\n",
    "pc_data[:] = pc_data2[iidx2]\n",
    "\n",
    "idx1_zarr = zarr.open('pc/idx1.zarr','w',shape=idx1.shape,dtype=idx1.dtype,chunks=(2,200))\n",
    "idx2_zarr = zarr.open('pc/idx2.zarr','w',shape=idx2.shape,dtype=idx2.dtype,chunks=(2,200))\n",
    "pc1_zarr = zarr.open('pc/pc1.zarr','w',shape=pc_data1.shape,dtype=pc_data1.dtype,chunks=(200,1))\n",
    "pc2_zarr = zarr.open('pc/pc2.zarr','w',shape=pc_data2.shape,dtype=pc_data2.dtype,chunks=(200,1))\n",
    "idx1_zarr[:] = idx1\n",
    "idx2_zarr[:] = idx2\n",
    "pc1_zarr[:] = pc_data1\n",
    "pc2_zarr[:] = pc_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79624277-e4e9-488f-9785-b41a201db068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-05 02:45:51 - logging_args - INFO - running function: de_pc_intersect\n",
      "2023-11-05 02:45:51 - logging_args - INFO - fetching args:\n",
      "2023-11-05 02:45:51 - logging_args - INFO - idx1 = 'pc/idx1.zarr'\n",
      "2023-11-05 02:45:51 - logging_args - INFO - idx2 = 'pc/idx2.zarr'\n",
      "2023-11-05 02:45:51 - logging_args - INFO - idx = 'pc/idx.zarr'\n",
      "2023-11-05 02:45:51 - logging_args - INFO - pc1 = None\n",
      "2023-11-05 02:45:51 - logging_args - INFO - pc2 = None\n",
      "2023-11-05 02:45:51 - logging_args - INFO - pc = None\n",
      "2023-11-05 02:45:51 - logging_args - INFO - pc_chunk_size = None\n",
      "2023-11-05 02:45:51 - logging_args - INFO - n_pc_chunk = None\n",
      "2023-11-05 02:45:51 - logging_args - INFO - prefer_1 = True\n",
      "2023-11-05 02:45:51 - logging_args - INFO - fetching args done.\n",
      "2023-11-05 02:45:51 - zarr_info - INFO - pc/idx1.zarr zarray shape: (2, 1000)\n",
      "2023-11-05 02:45:51 - zarr_info - INFO - pc/idx1.zarr zarray chunks: (2, 200)\n",
      "2023-11-05 02:45:51 - zarr_info - INFO - pc/idx1.zarr zarray dtype: int32\n",
      "2023-11-05 02:45:51 - zarr_info - INFO - pc/idx2.zarr zarray shape: (2, 800)\n",
      "2023-11-05 02:45:51 - zarr_info - INFO - pc/idx2.zarr zarray chunks: (2, 200)\n",
      "2023-11-05 02:45:51 - zarr_info - INFO - pc/idx2.zarr zarray dtype: int32\n",
      "2023-11-05 02:45:51 - de_pc_intersect - INFO - loading idx1 and idx2 into memory.\n",
      "2023-11-05 02:45:51 - de_pc_intersect - INFO - calculate the intersection\n",
      "2023-11-05 02:45:51 - de_pc_intersect - INFO - number of points in the intersection: 82\n",
      "2023-11-05 02:45:51 - get_pc_chunk_size_from_n_pc_chunk - INFO - automatically determine pc_chunk_size from\n",
      "            n_pc of idx and n_pc_chunk of idx1\n",
      "2023-11-05 02:45:51 - get_pc_chunk_size_from_n_pc_chunk - INFO - pc_chunk_size for idx: 17\n",
      "2023-11-05 02:45:51 - de_pc_intersect - INFO - write intersect idx\n",
      "2023-11-05 02:45:51 - de_pc_intersect - INFO - write done\n",
      "2023-11-05 02:45:51 - zarr_info - INFO - pc/idx.zarr zarray shape: (2, 82)\n",
      "2023-11-05 02:45:51 - zarr_info - INFO - pc/idx.zarr zarray chunks: (2, 17)\n",
      "2023-11-05 02:45:51 - zarr_info - INFO - pc/idx.zarr zarray dtype: int32\n",
      "2023-11-05 02:45:51 - de_pc_intersect - INFO - no point cloud data provided, exit.\n",
      "2023-11-05 02:45:51 - logging_args - INFO - running function: de_pc_intersect\n",
      "2023-11-05 02:45:51 - logging_args - INFO - fetching args:\n",
      "2023-11-05 02:45:51 - logging_args - INFO - idx1 = 'pc/idx1.zarr'\n",
      "2023-11-05 02:45:51 - logging_args - INFO - idx2 = 'pc/idx2.zarr'\n",
      "2023-11-05 02:45:51 - logging_args - INFO - idx = 'pc/idx.zarr'\n",
      "2023-11-05 02:45:51 - logging_args - INFO - pc1 = None\n",
      "2023-11-05 02:45:51 - logging_args - INFO - pc2 = 'pc/pc2.zarr'\n",
      "2023-11-05 02:45:51 - logging_args - INFO - pc = 'pc/pc.zarr'\n",
      "2023-11-05 02:45:51 - logging_args - INFO - pc_chunk_size = None\n",
      "2023-11-05 02:45:51 - logging_args - INFO - n_pc_chunk = None\n",
      "2023-11-05 02:45:51 - logging_args - INFO - prefer_1 = False\n",
      "2023-11-05 02:45:51 - logging_args - INFO - fetching args done.\n",
      "2023-11-05 02:45:51 - zarr_info - INFO - pc/idx1.zarr zarray shape: (2, 1000)\n",
      "2023-11-05 02:45:51 - zarr_info - INFO - pc/idx1.zarr zarray chunks: (2, 200)\n",
      "2023-11-05 02:45:51 - zarr_info - INFO - pc/idx1.zarr zarray dtype: int32\n",
      "2023-11-05 02:45:51 - zarr_info - INFO - pc/idx2.zarr zarray shape: (2, 800)\n",
      "2023-11-05 02:45:51 - zarr_info - INFO - pc/idx2.zarr zarray chunks: (2, 200)\n",
      "2023-11-05 02:45:51 - zarr_info - INFO - pc/idx2.zarr zarray dtype: int32\n",
      "2023-11-05 02:45:51 - de_pc_intersect - INFO - loading idx1 and idx2 into memory.\n",
      "2023-11-05 02:45:51 - de_pc_intersect - INFO - calculate the intersection\n",
      "2023-11-05 02:45:51 - de_pc_intersect - INFO - number of points in the intersection: 82\n",
      "2023-11-05 02:45:51 - get_pc_chunk_size_from_n_pc_chunk - INFO - automatically determine pc_chunk_size from\n",
      "            n_pc of idx and n_pc_chunk of idx1\n",
      "2023-11-05 02:45:51 - get_pc_chunk_size_from_n_pc_chunk - INFO - pc_chunk_size for idx: 17\n",
      "2023-11-05 02:45:51 - de_pc_intersect - INFO - write intersect idx\n",
      "2023-11-05 02:45:51 - de_pc_intersect - INFO - write done\n",
      "2023-11-05 02:45:51 - zarr_info - INFO - pc/idx.zarr zarray shape: (2, 82)\n",
      "2023-11-05 02:45:51 - zarr_info - INFO - pc/idx.zarr zarray chunks: (2, 17)\n",
      "2023-11-05 02:45:51 - zarr_info - INFO - pc/idx.zarr zarray dtype: int32\n",
      "2023-11-05 02:45:51 - de_pc_intersect - INFO - select pc2 as pc_input.\n",
      "2023-11-05 02:45:51 - de_pc_intersect - INFO - starting dask local cluster.\n",
      "2023-11-05 02:45:55 - de_pc_intersect - INFO - dask local cluster started.\n",
      "2023-11-05 02:45:55 - zarr_info - INFO - pc/pc2.zarr zarray shape: (800, 3)\n",
      "2023-11-05 02:45:55 - zarr_info - INFO - pc/pc2.zarr zarray chunks: (200, 1)\n",
      "2023-11-05 02:45:55 - zarr_info - INFO - pc/pc2.zarr zarray dtype: complex64\n",
      "2023-11-05 02:45:55 - darr_info - INFO - pc_input dask array shape: (800, 3)\n",
      "2023-11-05 02:45:55 - darr_info - INFO - pc_input dask array chunksize: (200, 1)\n",
      "2023-11-05 02:45:55 - darr_info - INFO - pc_input dask array dtype: complex64\n",
      "2023-11-05 02:45:55 - de_pc_intersect - INFO - set up intersect pc data dask array.\n",
      "2023-11-05 02:45:55 - darr_info - INFO - pc dask array shape: (82, 3)\n",
      "2023-11-05 02:45:55 - darr_info - INFO - pc dask array chunksize: (17, 1)\n",
      "2023-11-05 02:45:55 - darr_info - INFO - pc dask array dtype: complex64\n",
      "2023-11-05 02:45:55 - de_pc_intersect - INFO - computing graph setted. doing all the computing.\n",
      "2023-11-05 02:45:56 - de_pc_intersect - INFO - computing finished.s\u001b[2K\n",
      "2023-11-05 02:45:57 - de_pc_intersect - INFO - dask cluster closed.\n"
     ]
    }
   ],
   "source": [
    "de_pc_intersect('pc/idx1.zarr','pc/idx2.zarr','pc/idx.zarr')\n",
    "de_pc_intersect('pc/idx1.zarr','pc/idx2.zarr','pc/idx.zarr',pc2='pc/pc2.zarr', pc='pc/pc.zarr',prefer_1=False)\n",
    "idx_zarr = zarr.open('pc/idx.zarr','r')\n",
    "pc_zarr = zarr.open('pc/pc.zarr','r')\n",
    "np.testing.assert_array_equal(idx_zarr[:],idx)\n",
    "np.testing.assert_array_equal(pc_zarr[:],pc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6709657-ac69-48d5-8c89-72a42cc19939",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@call_parse\n",
    "@log_args\n",
    "@de_logger\n",
    "def de_pc_diff(idx1:str, # index of the first point cloud\n",
    "               idx2:str, # index of the second point cloud\n",
    "               idx:str, # output, index of the union point cloud\n",
    "               pc1:str|list=None, # path (in string) or list of path for the first point cloud data\n",
    "               pc:str|list=None, #output, path (in string) or list of path for the union point cloud data\n",
    "               pc_chunk_size:int=None, # chunk size in output data,optional\n",
    "               n_pc_chunk:int=None, # number of chunk in output data, optional\n",
    "              ):\n",
    "    '''Get the point cloud in `idx1` that are not in `idx2`.\n",
    "    `pc_chunk_size` and `n_pc_chunk` are used to determine the final pc_chunk_size.\n",
    "    If non of them are provided, the n_pc_chunk is set to n_chunk in idx1.\n",
    "    '''\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    idx1_zarr = zarr.open(idx1,mode='r'); logger.zarr_info(idx1,idx1_zarr)\n",
    "    idx2_zarr = zarr.open(idx2,mode='r'); logger.zarr_info(idx2,idx2_zarr)\n",
    "    logger.info('loading idx1 and idx2 into memory.')\n",
    "    idx1 = idx1_zarr[:]; idx2 = idx2_zarr[:]\n",
    "\n",
    "    logger.info('calculate the diff.')\n",
    "    idx_path = idx\n",
    "    idx, iidx1 = pc_diff(idx1,idx2)\n",
    "    n_pc = idx.shape[1]\n",
    "    logger.info(f'number of points in the diff: {idx.shape[1]}')\n",
    "    pc_chunk_size = get_pc_chunk_size_from_n_pc_chunk('idx1','idx',idx1_zarr.shape[1],idx1_zarr.chunks[1],n_pc,pc_chunk_size=pc_chunk_size,n_pc_chunk=n_pc_chunk)\n",
    "    \n",
    "    idx_zarr = zarr.open(idx_path,'w',shape=idx.shape,dtype=idx.dtype,chunks=(2,pc_chunk_size))\n",
    "    logger.info('write intersect idx')\n",
    "    idx_zarr[:] = idx\n",
    "    logger.info('write done')\n",
    "    logger.zarr_info(idx_path, idx_zarr)\n",
    "\n",
    "    if pc1 is None:\n",
    "        logger.info('no point cloud data provided, exit.')\n",
    "        return None\n",
    "\n",
    "    if isinstance(pc1,str):\n",
    "        assert isinstance(pc,str)\n",
    "        pc1_list = [pc1]; pc_list = [pc]\n",
    "    else:\n",
    "        assert isinstance(pc1,list); assert isinstance(pc,list)\n",
    "        pc1_list = pc1; pc_list = pc\n",
    "\n",
    "    logger.info('starting dask local cluster.')\n",
    "    with LocalCluster() as cluster, Client(cluster) as client:\n",
    "        logger.info('dask local cluster started.')\n",
    "\n",
    "        _pc_list = ()\n",
    "        for pc1_path, pc_path in zip(pc1_list,pc_list):\n",
    "            pc1_zarr = zarr.open(pc1_path,'r'); logger.zarr_info(pc1_path, pc1_zarr)\n",
    "            pc1 = da.from_zarr(pc1_path); logger.darr_info('pc1', pc1)\n",
    "            logger.info('set up diff pc data dask array.')\n",
    "            pc = da.empty((n_pc,*pc1.shape[1:]),chunks = (pc_chunk_size,*pc1.chunks[1:]), dtype=pc1.dtype)\n",
    "            logger.darr_info('pc',pc)\n",
    "            pc[:] = pc1[iidx1]\n",
    "            _pc = pc.to_zarr(pc_path, overwrite=True,compute=False)\n",
    "            _pc_list += (_pc,)\n",
    "\n",
    "        logger.info('computing graph setted. doing all the computing.')\n",
    "        futures = client.persist(_pc_list)\n",
    "        progress(futures,notebook=False)\n",
    "        da.compute(futures)\n",
    "        logger.info('computing finished.')\n",
    "    logger.info('dask cluster closed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2053e3-a509-4089-87b4-2fd605a23cab",
   "metadata": {},
   "source": [
    "Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e674d6-5b0d-448c-b456-a0bbf1823db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_data1 = np.random.rand(1000,3).astype(np.float32)+1j*np.random.rand(1000,3).astype(np.float32)\n",
    "\n",
    "idx1 = np.random.choice(np.arange(100*100,dtype=np.int32),size=1000,replace=False)\n",
    "idx1.sort()\n",
    "idx1 = np.stack(np.unravel_index(idx1,shape=(100,100))).astype(np.int32)\n",
    "\n",
    "idx2 = np.random.choice(np.arange(100*100,dtype=np.int32),size=800,replace=False)\n",
    "idx2.sort()\n",
    "idx2 = np.stack(np.unravel_index(idx2,shape=(100,100))).astype(np.int32)\n",
    "\n",
    "idx, iidx1 = pc_diff(idx1,idx2)\n",
    "\n",
    "pc_data = np.empty((idx.shape[1],*pc_data1.shape[1:]),dtype=pc_data1.dtype)\n",
    "pc_data[:] = pc_data1[iidx1]\n",
    "\n",
    "idx1_zarr = zarr.open('pc/idx1.zarr','w',shape=idx1.shape,dtype=idx1.dtype,chunks=(2,200))\n",
    "idx2_zarr = zarr.open('pc/idx2.zarr','w',shape=idx2.shape,dtype=idx2.dtype,chunks=(2,200))\n",
    "pc1_zarr = zarr.open('pc/pc1.zarr','w',shape=pc_data1.shape,dtype=pc_data1.dtype,chunks=(200,1))\n",
    "idx1_zarr[:] = idx1\n",
    "idx2_zarr[:] = idx2\n",
    "pc1_zarr[:] = pc_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bc9d97-3e59-4185-978c-e79606560c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-05 02:45:58 - logging_args - INFO - running function: de_pc_diff\n",
      "2023-11-05 02:45:58 - logging_args - INFO - fetching args:\n",
      "2023-11-05 02:45:58 - logging_args - INFO - idx1 = 'pc/idx1.zarr'\n",
      "2023-11-05 02:45:58 - logging_args - INFO - idx2 = 'pc/idx2.zarr'\n",
      "2023-11-05 02:45:58 - logging_args - INFO - idx = 'pc/idx.zarr'\n",
      "2023-11-05 02:45:58 - logging_args - INFO - pc1 = None\n",
      "2023-11-05 02:45:58 - logging_args - INFO - pc = None\n",
      "2023-11-05 02:45:58 - logging_args - INFO - pc_chunk_size = None\n",
      "2023-11-05 02:45:58 - logging_args - INFO - n_pc_chunk = None\n",
      "2023-11-05 02:45:58 - logging_args - INFO - fetching args done.\n",
      "2023-11-05 02:45:58 - zarr_info - INFO - pc/idx1.zarr zarray shape: (2, 1000)\n",
      "2023-11-05 02:45:58 - zarr_info - INFO - pc/idx1.zarr zarray chunks: (2, 200)\n",
      "2023-11-05 02:45:58 - zarr_info - INFO - pc/idx1.zarr zarray dtype: int32\n",
      "2023-11-05 02:45:58 - zarr_info - INFO - pc/idx2.zarr zarray shape: (2, 800)\n",
      "2023-11-05 02:45:58 - zarr_info - INFO - pc/idx2.zarr zarray chunks: (2, 200)\n",
      "2023-11-05 02:45:58 - zarr_info - INFO - pc/idx2.zarr zarray dtype: int32\n",
      "2023-11-05 02:45:58 - de_pc_diff - INFO - loading idx1 and idx2 into memory.\n",
      "2023-11-05 02:45:58 - de_pc_diff - INFO - calculate the diff.\n",
      "2023-11-05 02:45:58 - de_pc_diff - INFO - number of points in the diff: 916\n",
      "2023-11-05 02:45:58 - get_pc_chunk_size_from_n_pc_chunk - INFO - automatically determine pc_chunk_size from\n",
      "            n_pc of idx and n_pc_chunk of idx1\n",
      "2023-11-05 02:45:58 - get_pc_chunk_size_from_n_pc_chunk - INFO - pc_chunk_size for idx: 184\n",
      "2023-11-05 02:45:58 - de_pc_diff - INFO - write intersect idx\n",
      "2023-11-05 02:45:59 - de_pc_diff - INFO - write done\n",
      "2023-11-05 02:45:59 - zarr_info - INFO - pc/idx.zarr zarray shape: (2, 916)\n",
      "2023-11-05 02:45:59 - zarr_info - INFO - pc/idx.zarr zarray chunks: (2, 184)\n",
      "2023-11-05 02:45:59 - zarr_info - INFO - pc/idx.zarr zarray dtype: int32\n",
      "2023-11-05 02:45:59 - de_pc_diff - INFO - no point cloud data provided, exit.\n",
      "2023-11-05 02:45:59 - logging_args - INFO - running function: de_pc_diff\n",
      "2023-11-05 02:45:59 - logging_args - INFO - fetching args:\n",
      "2023-11-05 02:45:59 - logging_args - INFO - idx1 = 'pc/idx1.zarr'\n",
      "2023-11-05 02:45:59 - logging_args - INFO - idx2 = 'pc/idx2.zarr'\n",
      "2023-11-05 02:45:59 - logging_args - INFO - idx = 'pc/idx.zarr'\n",
      "2023-11-05 02:45:59 - logging_args - INFO - pc1 = 'pc/pc1.zarr'\n",
      "2023-11-05 02:45:59 - logging_args - INFO - pc = 'pc/pc.zarr'\n",
      "2023-11-05 02:45:59 - logging_args - INFO - pc_chunk_size = None\n",
      "2023-11-05 02:45:59 - logging_args - INFO - n_pc_chunk = None\n",
      "2023-11-05 02:45:59 - logging_args - INFO - fetching args done.\n",
      "2023-11-05 02:45:59 - zarr_info - INFO - pc/idx1.zarr zarray shape: (2, 1000)\n",
      "2023-11-05 02:45:59 - zarr_info - INFO - pc/idx1.zarr zarray chunks: (2, 200)\n",
      "2023-11-05 02:45:59 - zarr_info - INFO - pc/idx1.zarr zarray dtype: int32\n",
      "2023-11-05 02:45:59 - zarr_info - INFO - pc/idx2.zarr zarray shape: (2, 800)\n",
      "2023-11-05 02:45:59 - zarr_info - INFO - pc/idx2.zarr zarray chunks: (2, 200)\n",
      "2023-11-05 02:45:59 - zarr_info - INFO - pc/idx2.zarr zarray dtype: int32\n",
      "2023-11-05 02:45:59 - de_pc_diff - INFO - loading idx1 and idx2 into memory.\n",
      "2023-11-05 02:45:59 - de_pc_diff - INFO - calculate the diff.\n",
      "2023-11-05 02:45:59 - de_pc_diff - INFO - number of points in the diff: 916\n",
      "2023-11-05 02:45:59 - get_pc_chunk_size_from_n_pc_chunk - INFO - automatically determine pc_chunk_size from\n",
      "            n_pc of idx and n_pc_chunk of idx1\n",
      "2023-11-05 02:45:59 - get_pc_chunk_size_from_n_pc_chunk - INFO - pc_chunk_size for idx: 184\n",
      "2023-11-05 02:45:59 - de_pc_diff - INFO - write intersect idx\n",
      "2023-11-05 02:45:59 - de_pc_diff - INFO - write done\n",
      "2023-11-05 02:45:59 - zarr_info - INFO - pc/idx.zarr zarray shape: (2, 916)\n",
      "2023-11-05 02:45:59 - zarr_info - INFO - pc/idx.zarr zarray chunks: (2, 184)\n",
      "2023-11-05 02:45:59 - zarr_info - INFO - pc/idx.zarr zarray dtype: int32\n",
      "2023-11-05 02:45:59 - de_pc_diff - INFO - starting dask local cluster.\n",
      "2023-11-05 02:46:02 - de_pc_diff - INFO - dask local cluster started.\n",
      "2023-11-05 02:46:02 - zarr_info - INFO - pc/pc1.zarr zarray shape: (1000, 3)\n",
      "2023-11-05 02:46:02 - zarr_info - INFO - pc/pc1.zarr zarray chunks: (200, 1)\n",
      "2023-11-05 02:46:02 - zarr_info - INFO - pc/pc1.zarr zarray dtype: complex64\n",
      "2023-11-05 02:46:02 - darr_info - INFO - pc1 dask array shape: (1000, 3)\n",
      "2023-11-05 02:46:02 - darr_info - INFO - pc1 dask array chunksize: (200, 1)\n",
      "2023-11-05 02:46:02 - darr_info - INFO - pc1 dask array dtype: complex64\n",
      "2023-11-05 02:46:02 - de_pc_diff - INFO - set up diff pc data dask array.\n",
      "2023-11-05 02:46:02 - darr_info - INFO - pc dask array shape: (916, 3)\n",
      "2023-11-05 02:46:02 - darr_info - INFO - pc dask array chunksize: (184, 1)\n",
      "2023-11-05 02:46:02 - darr_info - INFO - pc dask array dtype: complex64\n",
      "2023-11-05 02:46:02 - de_pc_diff - INFO - computing graph setted. doing all the computing.\n",
      "2023-11-05 02:46:03 - de_pc_diff - INFO - computing finished.  1.0s\u001b[2K\n",
      "2023-11-05 02:46:04 - de_pc_diff - INFO - dask cluster closed.\n"
     ]
    }
   ],
   "source": [
    "de_pc_diff('pc/idx1.zarr','pc/idx2.zarr','pc/idx.zarr')\n",
    "de_pc_diff('pc/idx1.zarr','pc/idx2.zarr','pc/idx.zarr',pc1='pc/pc1.zarr', pc='pc/pc.zarr')\n",
    "idx_zarr = zarr.open('pc/idx.zarr','r')\n",
    "pc_zarr = zarr.open('pc/pc.zarr','r')\n",
    "np.testing.assert_array_equal(idx_zarr[:],idx)\n",
    "np.testing.assert_array_equal(pc_zarr[:],pc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041155a0-50f5-41f0-92f0-ae34a609dcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@call_parse\n",
    "@log_args\n",
    "@de_logger\n",
    "def de_pc_logic_ras(ras, # the raster image used for thresholding\n",
    "                    idx, # output, index of selected pixels\n",
    "                    operation:str, # logical operation on input ras\n",
    "                    pc_chunk_size:int=None, # chunk size in output data,optional\n",
    "                    n_pc_chunk:int=None, # number of chunk in output data, optional\n",
    "                   ):\n",
    "    '''generate point cloud index based on logical operation of one raster image.\n",
    "    '''\n",
    "    idx_path = idx\n",
    "    logger = logging.getLogger(__name__)\n",
    "    ras_zarr = zarr.open(ras, mode='r'); logger.zarr_info(ras,ras_zarr)\n",
    "\n",
    "    ras = ras_zarr[:]; logger.info('loading ras into memory.')\n",
    "    is_pc = ne.evaluate(operation,{'ras':ras})\n",
    "    logger.info(f'select pc based on operation: {operation}')\n",
    "    idx = np.stack(np.where(is_pc)).astype(np.int32)\n",
    "    n_pc = idx.shape[1]\n",
    "    logger.info(f'number of selected pixels: {n_pc}.')\n",
    "    pc_chunk_size = get_pc_chunk_size_from_n_ras_chunk('ras','idx',\n",
    "                                                       *ras_zarr.shape[:2],\n",
    "                                                       *ras_zarr.chunks[:2],\n",
    "                                                       n_pc,pc_chunk_size=pc_chunk_size,n_pc_chunk=n_pc_chunk)\n",
    "    idx_zarr = zarr.open(idx_path,'w',dtype=idx.dtype,shape=idx.shape,chunks=(2,pc_chunk_size))\n",
    "    logger.info('writing idx.')\n",
    "    idx_zarr[:] = idx\n",
    "    logger.info('write done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd58d10-4a59-4a2e-84ad-267ea29d24aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ras = np.random.rand(100,100).astype(np.float32)\n",
    "min_thres = 0.1; max_thres=0.5\n",
    "is_pc = (ras>=min_thres) & (ras<=max_thres)\n",
    "idx = np.stack(np.where(is_pc)).astype(np.int32)\n",
    "ras_zarr = zarr.open('pc/ras.zarr','rw',shape=ras.shape,dtype=ras.dtype,chunks=(10,100))\n",
    "ras_zarr[:] = ras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c82334-d804-4eb9-a0af-2f10f3095ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-05 02:46:05 - logging_args - INFO - running function: de_pc_logic_ras\n",
      "2023-11-05 02:46:05 - logging_args - INFO - fetching args:\n",
      "2023-11-05 02:46:05 - logging_args - INFO - ras = 'pc/ras.zarr'\n",
      "2023-11-05 02:46:05 - logging_args - INFO - idx = 'pc/idx.zarr'\n",
      "2023-11-05 02:46:05 - logging_args - INFO - operation = '(ras>=0.1)&(ras<=0.5)'\n",
      "2023-11-05 02:46:05 - logging_args - INFO - pc_chunk_size = None\n",
      "2023-11-05 02:46:05 - logging_args - INFO - n_pc_chunk = None\n",
      "2023-11-05 02:46:05 - logging_args - INFO - fetching args done.\n",
      "2023-11-05 02:46:05 - zarr_info - INFO - pc/ras.zarr zarray shape: (100, 100)\n",
      "2023-11-05 02:46:05 - zarr_info - INFO - pc/ras.zarr zarray chunks: (10, 100)\n",
      "2023-11-05 02:46:05 - zarr_info - INFO - pc/ras.zarr zarray dtype: float32\n",
      "2023-11-05 02:46:05 - de_pc_logic_ras - INFO - loading ras into memory.\n",
      "2023-11-05 02:46:05 - de_pc_logic_ras - INFO - select pc based on operation: (ras>=0.1)&(ras<=0.5)\n",
      "2023-11-05 02:46:05 - de_pc_logic_ras - INFO - number of selected pixels: 3990.\n",
      "2023-11-05 02:46:05 - get_pc_chunk_size_from_n_ras_chunk - INFO - automatically determine pc_chunk_size from\n",
      "            n_pc of idx and n_ras_chunk of ras\n",
      "2023-11-05 02:46:05 - get_pc_chunk_size_from_n_ras_chunk - INFO - n_ras_chunk of ras: 10\n",
      "2023-11-05 02:46:05 - get_pc_chunk_size_from_n_ras_chunk - INFO - pc_chunk_size for idx: 399\n",
      "2023-11-05 02:46:05 - de_pc_logic_ras - INFO - writing idx.\n",
      "2023-11-05 02:46:05 - de_pc_logic_ras - INFO - write done.\n"
     ]
    }
   ],
   "source": [
    "de_pc_logic_ras('pc/ras.zarr','pc/idx.zarr',f'(ras>={min_thres})&(ras<={max_thres})')\n",
    "idx_zarr = zarr.open('pc/idx.zarr','r')\n",
    "np.testing.assert_array_equal(idx_zarr[:],idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59397a9-7a82-4f11-8333-959e64d6b9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@call_parse\n",
    "@log_args\n",
    "@de_logger\n",
    "def de_pc_logic_pc(idx_in:str,# the index of input pc data\n",
    "                   pc_in:str, # the point cloud data used for thresholding\n",
    "                   idx:str, # output, index of selected pixels\n",
    "                   operation:str, # operator\n",
    "                   pc_chunk_size:int=None, # chunk size in output data,optional\n",
    "                   n_pc_chunk:int=None, # number of chunk in output data, optional\n",
    "                   ):\n",
    "    '''generate point cloud index and data based on logical operation one point cloud data.\n",
    "    '''\n",
    "    idx_path = idx\n",
    "    logger = logging.getLogger(__name__)\n",
    "    idx_in_zarr = zarr.open(idx_in,mode='r'); logger.zarr_info(idx_in,idx_in_zarr)\n",
    "    pc_in_zarr = zarr.open(pc_in, mode='r'); logger.zarr_info(pc_in,pc_in_zarr)\n",
    "\n",
    "    idx_in = idx_in_zarr[:]; logger.info('loading idx_in into memory.')\n",
    "    pc_in = pc_in_zarr[:]; logger.info('loading pc_in into memory.')\n",
    "\n",
    "    is_pc = ne.evaluate(operation,{'pc_in':pc_in})\n",
    "    logger.info(f'select pc based on operation: {operation}')\n",
    "    idx = idx_in[:,is_pc]\n",
    "    n_pc = idx.shape[1]\n",
    "    logger.info(f'number of selected pixels: {n_pc}.')\n",
    "    pc_chunk_size = get_pc_chunk_size_from_n_pc_chunk('idx_in','idx',idx_in_zarr.shape[1],idx_in_zarr.chunks[1],n_pc, pc_chunk_size=pc_chunk_size, n_pc_chunk= n_pc_chunk)\n",
    "    idx_zarr = zarr.open(idx_path,'w',dtype=idx.dtype,shape=idx.shape,chunks=(2,pc_chunk_size))\n",
    "    logger.zarr_info('idx', idx_zarr)\n",
    "    logger.info('writing idx.')\n",
    "    idx_zarr[:] = idx\n",
    "    logger.info('write done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0adbca-48c5-402c-98e3-64b2017d4ec7",
   "metadata": {},
   "source": [
    "Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ea19e0-a5bb-4b1a-ac2e-6ebce272da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_in = np.random.rand(1000).astype(np.float32)\n",
    "idx_in = np.random.choice(np.arange(100*100,dtype=np.int32),size=1000,replace=False)\n",
    "idx_in.sort()\n",
    "idx_in = np.stack(np.unravel_index(idx_in,shape=(100,100))).astype(np.int32)\n",
    "\n",
    "min_thres = 0.1; max_thres=0.5\n",
    "is_pc = (pc_in>=min_thres) & (pc_in<=max_thres)\n",
    "idx = idx_in[:,is_pc]\n",
    "pc_in_zarr = zarr.open('pc/pc_in.zarr','w',shape=pc_in.shape,dtype=pc_in.dtype,chunks=(100,))\n",
    "idx_in_zarr = zarr.open('pc/idx_in.zarr','w',shape=idx_in.shape,dtype=idx_in.dtype,chunks=(2,100))\n",
    "pc_in_zarr[:] = pc_in; idx_in_zarr[:] = idx_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cc0848-2892-40b6-8caf-1e2dfaa05e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-05 02:46:06 - logging_args - INFO - running function: de_pc_logic_pc\n",
      "2023-11-05 02:46:06 - logging_args - INFO - fetching args:\n",
      "2023-11-05 02:46:06 - logging_args - INFO - idx_in = 'pc/idx_in.zarr'\n",
      "2023-11-05 02:46:06 - logging_args - INFO - pc_in = 'pc/pc_in.zarr'\n",
      "2023-11-05 02:46:06 - logging_args - INFO - idx = 'pc/idx.zarr'\n",
      "2023-11-05 02:46:06 - logging_args - INFO - operation = '(pc_in>=0.1)&(pc_in<=0.5)'\n",
      "2023-11-05 02:46:06 - logging_args - INFO - pc_chunk_size = None\n",
      "2023-11-05 02:46:06 - logging_args - INFO - n_pc_chunk = None\n",
      "2023-11-05 02:46:06 - logging_args - INFO - fetching args done.\n",
      "2023-11-05 02:46:06 - zarr_info - INFO - pc/idx_in.zarr zarray shape: (2, 1000)\n",
      "2023-11-05 02:46:06 - zarr_info - INFO - pc/idx_in.zarr zarray chunks: (2, 100)\n",
      "2023-11-05 02:46:06 - zarr_info - INFO - pc/idx_in.zarr zarray dtype: int32\n",
      "2023-11-05 02:46:06 - zarr_info - INFO - pc/pc_in.zarr zarray shape: (1000,)\n",
      "2023-11-05 02:46:06 - zarr_info - INFO - pc/pc_in.zarr zarray chunks: (100,)\n",
      "2023-11-05 02:46:06 - zarr_info - INFO - pc/pc_in.zarr zarray dtype: float32\n",
      "2023-11-05 02:46:06 - de_pc_logic_pc - INFO - loading idx_in into memory.\n",
      "2023-11-05 02:46:06 - de_pc_logic_pc - INFO - loading pc_in into memory.\n",
      "2023-11-05 02:46:06 - de_pc_logic_pc - INFO - select pc based on operation: (pc_in>=0.1)&(pc_in<=0.5)\n",
      "2023-11-05 02:46:06 - de_pc_logic_pc - INFO - number of selected pixels: 375.\n",
      "2023-11-05 02:46:06 - get_pc_chunk_size_from_n_pc_chunk - INFO - automatically determine pc_chunk_size from\n",
      "            n_pc of idx and n_pc_chunk of idx_in\n",
      "2023-11-05 02:46:06 - get_pc_chunk_size_from_n_pc_chunk - INFO - pc_chunk_size for idx: 38\n",
      "2023-11-05 02:46:06 - zarr_info - INFO - idx zarray shape: (2, 375)\n",
      "2023-11-05 02:46:06 - zarr_info - INFO - idx zarray chunks: (2, 38)\n",
      "2023-11-05 02:46:06 - zarr_info - INFO - idx zarray dtype: int32\n",
      "2023-11-05 02:46:06 - de_pc_logic_pc - INFO - writing idx.\n",
      "2023-11-05 02:46:06 - de_pc_logic_pc - INFO - write done.\n"
     ]
    }
   ],
   "source": [
    "de_pc_logic_pc('pc/idx_in.zarr','pc/pc_in.zarr','pc/idx.zarr',f'(pc_in>={min_thres})&(pc_in<={max_thres})')\n",
    "idx_zarr = zarr.open('pc/idx.zarr','r')\n",
    "np.testing.assert_array_equal(idx_zarr[:],idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7d0216-326e-43f7-9b8f-0268497f43e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@call_parse\n",
    "@log_args\n",
    "@de_logger\n",
    "def de_pc_select_data(idx_in:str, # index of the input data\n",
    "                      idx:str, # index of the output data\n",
    "                      pc_in:str|list, # path (in string) or list of path for the input point cloud data\n",
    "                      pc:str|list, # output, path (in string) or list of path for the output point cloud data\n",
    "                      pc_chunk_size:int=None, # chunk size in output data,optional\n",
    "                      n_pc_chunk:int=None, # number of chunk in output data, optional\n",
    "                     ):\n",
    "    '''generate point cloud data based on its index and one point cloud data.\n",
    "    The index of generated point cloud data must in the index of the old one.\n",
    "    '''\n",
    "    idx_in_path = idx_in; idx_path = idx\n",
    "    logger = logging.getLogger(__name__)\n",
    "    idx_in_zarr = zarr.open(idx_in_path,mode='r'); logger.zarr_info(idx_in_path,idx_in_zarr)\n",
    "    idx_zarr = zarr.open(idx_path,mode='r'); logger.zarr_info(idx_path,idx_zarr)\n",
    "    logger.info('loading idx_in and idx into memory.')\n",
    "    idx_in = idx_in_zarr[:]; idx = idx_zarr[:]\n",
    "    iidx_in, iidx = pc_intersect(idx_in,idx)[1:]\n",
    "    np.testing.assert_array_equal(iidx,np.arange(iidx.shape[0]),err_msg='idx have points that are not covered by idx_in.')\n",
    "    n_pc = iidx_in.shape[0]\n",
    "    pc_chunk_size = get_pc_chunk_size_from_pc_chunk_size('idx','pc',idx_zarr.chunks[1],n_pc,pc_chunk_size=pc_chunk_size,n_pc_chunk=n_pc_chunk)\n",
    "\n",
    "    if isinstance(pc_in,str):\n",
    "        assert isinstance(pc,str)\n",
    "        pc_in_list = [pc_in]; pc_list = [pc]\n",
    "    else:\n",
    "        assert isinstance(pc_in,list); assert isinstance(pc,list)\n",
    "        pc_in_list = pc_in; pc_list = pc\n",
    "\n",
    "    logger.info('starting dask local cluster.')\n",
    "    with LocalCluster() as cluster, Client(cluster) as client:\n",
    "        logger.info('dask local cluster started.')\n",
    "\n",
    "        _pc_list = ()\n",
    "        for pc_in_path, pc_path in zip(pc_in_list,pc_list):\n",
    "            pc_in_zarr = zarr.open(pc_in_path,'r'); logger.zarr_info(pc_in_path, pc_in_zarr)\n",
    "            pc_in = da.from_zarr(pc_in_path); logger.darr_info('pc_in', pc_in)\n",
    "            logger.info('set up selected pc data dask array.')\n",
    "            pc = da.empty((n_pc,*pc_in.shape[1:]),chunks = (pc_chunk_size,*pc_in.chunks[1:]), dtype=pc_in.dtype)\n",
    "            logger.darr_info('pc',pc)\n",
    "            pc[:] = pc_in[iidx_in]\n",
    "            _pc = pc.to_zarr(pc_path, overwrite=True,compute=False)\n",
    "            _pc_list += (_pc,)\n",
    "\n",
    "        logger.info('computing graph setted. doing all the computing.')\n",
    "        futures = client.persist(_pc_list)\n",
    "        progress(futures,notebook=False)\n",
    "        da.compute(futures)\n",
    "        logger.info('computing finished.')\n",
    "    logger.info('dask cluster closed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62fc920-012d-429d-b385-36b0623bacde",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_in = np.random.rand(1000).astype(np.float32)\n",
    "idx_in = np.random.choice(np.arange(100*100,dtype=np.int32),size=1000,replace=False)\n",
    "idx_in.sort()\n",
    "idx_in = np.stack(np.unravel_index(idx_in,shape=(100,100))).astype(np.int32)\n",
    "\n",
    "iidx_in = np.random.choice(np.arange(1000,dtype=np.int64),size=500,replace=False); iidx_in.sort()\n",
    "idx = idx_in[:,iidx_in]\n",
    "pc = pc_in[iidx_in]\n",
    "\n",
    "pc_in_zarr = zarr.open('pc/pc_in.zarr','w',shape=pc_in.shape,dtype=pc_in.dtype,chunks=(100,))\n",
    "idx_in_zarr = zarr.open('pc/idx_in.zarr','w',shape=idx_in.shape,dtype=idx_in.dtype,chunks=(2,100))\n",
    "idx_zarr = zarr.open('pc/idx.zarr','w',shape=idx.shape,dtype=idx.dtype,chunks=(2,100))\n",
    "pc_in_zarr[:] = pc_in; idx_in_zarr[:] = idx_in; idx_zarr[:] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c08eb9c-851b-4084-95d7-2141f00b02f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-05 02:46:07 - logging_args - INFO - running function: de_pc_select_data\n",
      "2023-11-05 02:46:07 - logging_args - INFO - fetching args:\n",
      "2023-11-05 02:46:07 - logging_args - INFO - idx_in = 'pc/idx_in.zarr'\n",
      "2023-11-05 02:46:07 - logging_args - INFO - idx = 'pc/idx.zarr'\n",
      "2023-11-05 02:46:07 - logging_args - INFO - pc_in = 'pc/pc_in.zarr'\n",
      "2023-11-05 02:46:07 - logging_args - INFO - pc = 'pc/pc.zarr'\n",
      "2023-11-05 02:46:07 - logging_args - INFO - pc_chunk_size = None\n",
      "2023-11-05 02:46:07 - logging_args - INFO - n_pc_chunk = None\n",
      "2023-11-05 02:46:07 - logging_args - INFO - fetching args done.\n",
      "2023-11-05 02:46:07 - zarr_info - INFO - pc/idx_in.zarr zarray shape: (2, 1000)\n",
      "2023-11-05 02:46:07 - zarr_info - INFO - pc/idx_in.zarr zarray chunks: (2, 100)\n",
      "2023-11-05 02:46:07 - zarr_info - INFO - pc/idx_in.zarr zarray dtype: int32\n",
      "2023-11-05 02:46:07 - zarr_info - INFO - pc/idx.zarr zarray shape: (2, 500)\n",
      "2023-11-05 02:46:07 - zarr_info - INFO - pc/idx.zarr zarray chunks: (2, 100)\n",
      "2023-11-05 02:46:07 - zarr_info - INFO - pc/idx.zarr zarray dtype: int32\n",
      "2023-11-05 02:46:07 - de_pc_select_data - INFO - loading idx_in and idx into memory.\n",
      "2023-11-05 02:46:07 - get_pc_chunk_size_from_pc_chunk_size - INFO - automatically determine pc_chunk_size from\n",
      "            pc_chunk_size of idx.\n",
      "2023-11-05 02:46:07 - get_pc_chunk_size_from_pc_chunk_size - INFO - pc_chunk_size for pc: 100\n",
      "2023-11-05 02:46:07 - de_pc_select_data - INFO - starting dask local cluster.\n",
      "2023-11-05 02:46:11 - de_pc_select_data - INFO - dask local cluster started.\n",
      "2023-11-05 02:46:11 - zarr_info - INFO - pc/pc_in.zarr zarray shape: (1000,)\n",
      "2023-11-05 02:46:11 - zarr_info - INFO - pc/pc_in.zarr zarray chunks: (100,)\n",
      "2023-11-05 02:46:11 - zarr_info - INFO - pc/pc_in.zarr zarray dtype: float32\n",
      "2023-11-05 02:46:11 - darr_info - INFO - pc_in dask array shape: (1000,)\n",
      "2023-11-05 02:46:11 - darr_info - INFO - pc_in dask array chunksize: (100,)\n",
      "2023-11-05 02:46:11 - darr_info - INFO - pc_in dask array dtype: float32\n",
      "2023-11-05 02:46:11 - de_pc_select_data - INFO - set up selected pc data dask array.\n",
      "2023-11-05 02:46:11 - darr_info - INFO - pc dask array shape: (500,)\n",
      "2023-11-05 02:46:11 - darr_info - INFO - pc dask array chunksize: (100,)\n",
      "2023-11-05 02:46:11 - darr_info - INFO - pc dask array dtype: float32\n",
      "2023-11-05 02:46:11 - de_pc_select_data - INFO - computing graph setted. doing all the computing.\n",
      "2023-11-05 02:46:12 - de_pc_select_data - INFO - computing finished.[2K\n",
      "2023-11-05 02:46:12 - de_pc_select_data - INFO - dask cluster closed.\n"
     ]
    }
   ],
   "source": [
    "de_pc_select_data('pc/idx_in.zarr','pc/idx.zarr','pc/pc_in.zarr','pc/pc.zarr')\n",
    "pc_zarr = zarr.open('pc/pc.zarr','r')\n",
    "np.testing.assert_array_equal(pc_zarr[:],pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50eda76-1cf8-4fb7-9f5a-df8af874e97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a80c30-b67d-495a-b5f0-ddee13370492",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:work] *",
   "language": "python",
   "name": "conda-env-work-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
