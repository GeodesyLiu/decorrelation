{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "238849fa-11ec-4de5-99e4-c4eb367f7913",
   "metadata": {},
   "source": [
    "# pc\n",
    "\n",
    "> Point Cloud data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eed06b-0dd0-4177-8a92-8757961eecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp cli/pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967c14e4-d207-455f-829c-4c3a005838ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b686af00-c16a-401d-baf8-2847eda5416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import math\n",
    "import zarr\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import dask\n",
    "from dask import array as da\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "from decorrelation.pc import pc2ras, pc_union, pc_intersect, pc_diff\n",
    "from decorrelation.cli.utils.logging import get_logger, log_args\n",
    "from decorrelation.cli.utils.chunk_size import (get_pc_chunk_size_from_n_pc_chunk, \n",
    "                                                get_pc_chunk_size_from_pc_chunk_size, \n",
    "                                                get_pc_chunk_size_from_n_az_chunk,\n",
    "                                                get_az_chunk_size_from_n_pc_chunk)\n",
    "\n",
    "from fastcore.script import call_parse, Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2d5d0e-48cf-450b-8eb8-91a31cae04a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@log_args\n",
    "def de_ras2pc(idx:str, # point cloud index\n",
    "              ras:str|list, # path (in string) or list of path for raster data\n",
    "              pc:str|list, # output, path (in string) or list of path for point cloud data\n",
    "              pc_chunk_size:int=None, # output point chunk size\n",
    "              n_pc_chunk:int=None, # output number of chunk\n",
    "              hd_chunk_size:tuple|list=None, # output high dimension chunk size, tuple or list of tuple, same as input raster data by default\n",
    "              log:str=None, # log file. Default: no log file\n",
    "):\n",
    "    '''Convert raster data to point cloud data'''\n",
    "    logger = get_logger(logfile=log)\n",
    "\n",
    "    idx_zarr = zarr.open(idx,mode='r')\n",
    "    logger.zarr_info(idx,idx_zarr)\n",
    "    assert idx_zarr.ndim == 2, \"idx dimentation is not 2.\"\n",
    "    pc_chunk_size = get_pc_chunk_size_from_pc_chunk_size('idx','pc',idx_zarr.chunks[1],idx_zarr.shape[1],logger,pc_chunk_size=pc_chunk_size,n_pc_chunk=n_pc_chunk)\n",
    "\n",
    "    logger.info('loading idx into memory.')\n",
    "    idx = zarr.open(idx,mode='r')[:]\n",
    "    n_pc = idx.shape[1]\n",
    "\n",
    "    if isinstance(ras,str):\n",
    "        assert isinstance(pc,str)\n",
    "        ras_list = [ras]; pc_list = [pc]\n",
    "        if hd_chunk_size is not None:\n",
    "            assert isinstance(hd_chunk_size,tuple)\n",
    "            hd_chunk_size_list = [hd_chunk_size]\n",
    "        else:\n",
    "            hd_chunk_size_list = [None]\n",
    "    else:\n",
    "        assert isinstance(ras,list); assert isinstance(pc,list)\n",
    "        ras_list = ras; pc_list = pc\n",
    "        n_data = len(ras_list)\n",
    "        if hd_chunk_size is not None:\n",
    "            assert isinstance(hd_chunk_size,list)\n",
    "            hd_chunk_size_list = hd_chunk_size\n",
    "        else:\n",
    "            hd_chunk_size_list = [None]*n_data\n",
    "\n",
    "    logger.info('starting dask local cluster.')\n",
    "    cluster = LocalCluster()\n",
    "    client = Client(cluster)\n",
    "    logger.info('dask local cluster started.')\n",
    "\n",
    "    _pc_list = ()\n",
    "    for ras_path, pc_path, hd_chunk_size in zip(ras_list,pc_list,hd_chunk_size_list):\n",
    "        logger.info(f'start to slice on {ras_path}')\n",
    "        ras_zarr = zarr.open(ras_path,'r'); logger.zarr_info(ras_path, ras_zarr)\n",
    "        if hd_chunk_size is None:\n",
    "            logger.info(f'hd_chunk_size not setted. Use the one from {ras_path}.')\n",
    "            hd_chunk_size = ras_zarr.chunks[2:]\n",
    "        logger.info(f'hd_chunk_size: {hd_chunk_size}.')\n",
    "\n",
    "        ras = da.from_zarr(ras_path,chunks=(*ras_zarr.chunks[:2],*hd_chunk_size)); logger.darr_info('ras',ras)\n",
    "\n",
    "        with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
    "            pc = ras.reshape(-1,*ras.shape[2:])[np.ravel_multi_index((idx[0],idx[1]),dims=ras.shape[:2])]\n",
    "        \n",
    "        logger.darr_info('pc', pc)\n",
    "        logger.info('rechunk pc data:')\n",
    "        pc = pc.rechunk((pc_chunk_size,*pc.chunksize[1:]))\n",
    "        logger.darr_info('pc', pc)\n",
    "        _pc = pc.to_zarr(pc_path,overwrite=True,compute=False)\n",
    "        logger.info(f'saving to {pc_path}.')\n",
    "        _pc_list += (_pc,)\n",
    "    \n",
    "    logger.info('computing graph setted. doing all the computing.')\n",
    "    da.compute(*_pc_list)\n",
    "\n",
    "    logger.info('computing finished.')\n",
    "    cluster.close()\n",
    "    logger.info('dask cluster closed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad08c7-bb6c-492a-acd2-44ec6e75fb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@call_parse\n",
    "def console_de_ras2pc(idx:str, # point cloud index\n",
    "                      ras:Param(type=str,required=True,nargs='+',help='one or more path for raster data')=None,\n",
    "                      pc:Param(type=str,required=True,nargs='+',help='output, one or more path for point cloud data')=None,\n",
    "                      pc_chunk_size:int=None, # output point chunk size, same as input idx by default\n",
    "                      n_pc_chunk:int=None, # output number of chunk\n",
    "                      hd_chunk_size:Param(type=str,nargs='+',help='''output high dimension chunk size,\n",
    "                      each size should be wrapped in quotation marks and size in each dimension are seperated with \",\",\n",
    "                      same as input raster data by default''')=None,\n",
    "                      log:str=None, # log file. Default: no log file\n",
    "):\n",
    "    '''Convert raster data to point cloud data'''\n",
    "    if hd_chunk_size is not None:\n",
    "        hd_chunk_size_ = []\n",
    "        for size in hd_chunk_size:\n",
    "            if len(size) == 0:\n",
    "                size = ()\n",
    "            else:\n",
    "                size = size.split(',')\n",
    "                size = tuple([int(i) for i in size])\n",
    "            hd_chunk_size_.append(size)\n",
    "    else:\n",
    "        hd_chunk_size_ = None\n",
    "\n",
    "    if len(ras)==1:\n",
    "        ras = ras[0]\n",
    "        pc = pc[0]\n",
    "        if hd_chunk_size_ is not None:\n",
    "            hd_chunk_size_ = hd_chunk_size_[0]\n",
    "\n",
    "    de_ras2pc(idx,ras,pc,pc_chunk_size=pc_chunk_size,n_pc_chunk=n_pc_chunk,hd_chunk_size=hd_chunk_size_,log=log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec30940a-4ff1-4f22-a282-da51f8fad493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: de_ras2pc [-h] --ras RAS [RAS ...] --pc PC [PC ...]\n",
      "                 [--pc_chunk_size PC_CHUNK_SIZE] [--n_pc_chunk N_PC_CHUNK]\n",
      "                 [--hd_chunk_size HD_CHUNK_SIZE [HD_CHUNK_SIZE ...]] [--log LOG]\n",
      "                 idx\n",
      "\n",
      "Convert raster data to point cloud data\n",
      "\n",
      "positional arguments:\n",
      "  idx                                   point cloud index\n",
      "\n",
      "options:\n",
      "  -h, --help                            show this help message and exit\n",
      "  --ras RAS [RAS ...]                   one or more path for raster data\n",
      "  --pc PC [PC ...]                      output, one or more path for point cloud\n",
      "                                        data\n",
      "  --pc_chunk_size PC_CHUNK_SIZE         output point chunk size, same as input\n",
      "                                        idx by default\n",
      "  --n_pc_chunk N_PC_CHUNK               output number of chunk\n",
      "  --hd_chunk_size HD_CHUNK_SIZE [HD_CHUNK_SIZE ...]\n",
      "                                        output high dimension chunk size, each\n",
      "                                        size should be wrapped in quotation\n",
      "                                        marks and size in each dimension are\n",
      "                                        seperated with \",\", same as input raster\n",
      "                                        data by default\n",
      "  --log LOG                             log file. Default: no log file\n"
     ]
    }
   ],
   "source": [
    "!de_ras2pc -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae4f91c-2870-40d7-ab4f-2378ff6d3e95",
   "metadata": {},
   "source": [
    "Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8042246-2acf-44ad-ab50-c2ad2b326fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ras_data1 = np.random.rand(100,100).astype(np.float32)\n",
    "ras_data2 = np.random.rand(100,100,3).astype(np.float32)+1j*np.random.rand(100,100,3).astype(np.float32)\n",
    "\n",
    "idx = np.random.choice(np.arange(100*100,dtype=np.int32),size=1000,replace=False)\n",
    "idx.sort()\n",
    "idx = np.stack(np.unravel_index(idx,shape=(100,100))).astype(np.int32)\n",
    "\n",
    "pc_data1 = ras_data1[idx[0],idx[1]]\n",
    "pc_data2 = ras_data2[idx[0],idx[1]]\n",
    "\n",
    "idx_zarr = zarr.open('pc/idx.zarr','w',shape=idx.shape,dtype=idx.dtype,chunks=(2,200))\n",
    "ras_zarr1 = zarr.open('pc/ras1.zarr','w',shape=ras_data1.shape,dtype=ras_data1.dtype,chunks=(20,100))\n",
    "ras_zarr2 = zarr.open('pc/ras2.zarr','w',shape=ras_data2.shape,dtype=ras_data2.dtype,chunks=(20,100,1))\n",
    "idx_zarr[:] = idx\n",
    "ras_zarr1[:] = ras_data1\n",
    "ras_zarr2[:] = ras_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5b5824-8365-4107-8088-76aad7304f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-18 16:59:24 - de_ras2pc - INFO - fetching args:\n",
      "2023-10-18 16:59:24 - de_ras2pc - INFO - idx = 'pc/idx.zarr'\n",
      "2023-10-18 16:59:24 - de_ras2pc - INFO - ras = 'pc/ras1.zarr'\n",
      "2023-10-18 16:59:24 - de_ras2pc - INFO - pc = 'pc/pc1.zarr'\n",
      "2023-10-18 16:59:24 - de_ras2pc - INFO - pc_chunk_size = None\n",
      "2023-10-18 16:59:24 - de_ras2pc - INFO - n_pc_chunk = None\n",
      "2023-10-18 16:59:24 - de_ras2pc - INFO - hd_chunk_size = None\n",
      "2023-10-18 16:59:24 - de_ras2pc - INFO - log = None\n",
      "2023-10-18 16:59:24 - de_ras2pc - INFO - fetching args done.\n",
      "2023-10-18 16:59:24 - de_ras2pc - INFO - pc/idx.zarr zarray shape: (2, 1000)\n",
      "2023-10-18 16:59:24 - de_ras2pc - INFO - pc/idx.zarr zarray chunks: (2, 200)\n",
      "2023-10-18 16:59:24 - de_ras2pc - INFO - pc/idx.zarr zarray dtype: int32\n",
      "2023-10-18 16:59:24 - de_ras2pc - INFO - automatically determine pc_chunk_size from pc_chunk_size of idx.\n",
      "2023-10-18 16:59:24 - de_ras2pc - INFO - pc_chunk_size for pc: 200\n",
      "2023-10-18 16:59:24 - de_ras2pc - INFO - loading idx into memory.\n",
      "2023-10-18 16:59:24 - de_ras2pc - INFO - starting dask local cluster.\n",
      "2023-10-18 16:59:26 - de_ras2pc - INFO - dask local cluster started.\n",
      "2023-10-18 16:59:26 - de_ras2pc - INFO - start to slice on pc/ras1.zarr\n",
      "2023-10-18 16:59:26 - de_ras2pc - INFO - pc/ras1.zarr zarray shape: (100, 100)\n",
      "2023-10-18 16:59:26 - de_ras2pc - INFO - pc/ras1.zarr zarray chunks: (20, 100)\n",
      "2023-10-18 16:59:26 - de_ras2pc - INFO - pc/ras1.zarr zarray dtype: float32\n",
      "2023-10-18 16:59:26 - de_ras2pc - INFO - hd_chunk_size not setted. Use the one from pc/ras1.zarr.\n",
      "2023-10-18 16:59:26 - de_ras2pc - INFO - hd_chunk_size: ().\n",
      "2023-10-18 16:59:26 - de_ras2pc - INFO - ras dask array shape: (100, 100)\n",
      "2023-10-18 16:59:26 - de_ras2pc - INFO - ras dask array chunksize: (20, 100)\n",
      "2023-10-18 16:59:26 - de_ras2pc - INFO - ras dask array dtype: float32\n",
      "2023-10-18 16:59:26 - de_ras2pc - INFO - pc dask array shape: (1000,)\n",
      "2023-10-18 16:59:26 - de_ras2pc - INFO - pc dask array chunksize: (211,)\n",
      "2023-10-18 16:59:26 - de_ras2pc - INFO - pc dask array dtype: float32\n",
      "2023-10-18 16:59:26 - de_ras2pc - INFO - rechunk pc data:\n",
      "2023-10-18 16:59:26 - de_ras2pc - INFO - pc dask array shape: (1000,)\n",
      "2023-10-18 16:59:26 - de_ras2pc - INFO - pc dask array chunksize: (200,)\n",
      "2023-10-18 16:59:26 - de_ras2pc - INFO - pc dask array dtype: float32\n",
      "2023-10-18 16:59:26 - de_ras2pc - INFO - saving to pc/pc1.zarr.\n",
      "2023-10-18 16:59:26 - de_ras2pc - INFO - computing graph setted. doing all the computing.\n",
      "2023-10-18 16:59:27 - de_ras2pc - INFO - computing finished.\n",
      "2023-10-18 16:59:27 - de_ras2pc - INFO - dask cluster closed.\n",
      "2023-10-18 16:59:27 - de_ras2pc - INFO - fetching args:\n",
      "2023-10-18 16:59:27 - de_ras2pc - INFO - idx = 'pc/idx.zarr'\n",
      "2023-10-18 16:59:27 - de_ras2pc - INFO - ras = ['pc/ras1.zarr', 'pc/ras2.zarr']\n",
      "2023-10-18 16:59:27 - de_ras2pc - INFO - pc = ['pc/pc1.zarr', 'pc/pc2.zarr']\n",
      "2023-10-18 16:59:27 - de_ras2pc - INFO - pc_chunk_size = None\n",
      "2023-10-18 16:59:27 - de_ras2pc - INFO - n_pc_chunk = None\n",
      "2023-10-18 16:59:27 - de_ras2pc - INFO - hd_chunk_size = [(), (1,)]\n",
      "2023-10-18 16:59:27 - de_ras2pc - INFO - log = None\n",
      "2023-10-18 16:59:27 - de_ras2pc - INFO - fetching args done.\n",
      "2023-10-18 16:59:27 - de_ras2pc - INFO - pc/idx.zarr zarray shape: (2, 1000)\n",
      "2023-10-18 16:59:27 - de_ras2pc - INFO - pc/idx.zarr zarray chunks: (2, 200)\n",
      "2023-10-18 16:59:27 - de_ras2pc - INFO - pc/idx.zarr zarray dtype: int32\n",
      "2023-10-18 16:59:27 - de_ras2pc - INFO - automatically determine pc_chunk_size from pc_chunk_size of idx.\n",
      "2023-10-18 16:59:27 - de_ras2pc - INFO - pc_chunk_size for pc: 200\n",
      "2023-10-18 16:59:27 - de_ras2pc - INFO - loading idx into memory.\n",
      "2023-10-18 16:59:27 - de_ras2pc - INFO - starting dask local cluster.\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - dask local cluster started.\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - start to slice on pc/ras1.zarr\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - pc/ras1.zarr zarray shape: (100, 100)\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - pc/ras1.zarr zarray chunks: (20, 100)\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - pc/ras1.zarr zarray dtype: float32\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - hd_chunk_size: ().\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - ras dask array shape: (100, 100)\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - ras dask array chunksize: (20, 100)\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - ras dask array dtype: float32\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - pc dask array shape: (1000,)\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - pc dask array chunksize: (211,)\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - pc dask array dtype: float32\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - rechunk pc data:\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - pc dask array shape: (1000,)\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - pc dask array chunksize: (200,)\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - pc dask array dtype: float32\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - saving to pc/pc1.zarr.\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - start to slice on pc/ras2.zarr\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - pc/ras2.zarr zarray shape: (100, 100, 3)\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - pc/ras2.zarr zarray chunks: (20, 100, 1)\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - pc/ras2.zarr zarray dtype: complex64\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - hd_chunk_size: (1,).\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - ras dask array shape: (100, 100, 3)\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - ras dask array chunksize: (20, 100, 1)\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - ras dask array dtype: complex64\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - pc dask array shape: (1000, 3)\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - pc dask array chunksize: (211, 1)\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - pc dask array dtype: complex64\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - rechunk pc data:\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - pc dask array shape: (1000, 3)\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - pc dask array chunksize: (200, 1)\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - pc dask array dtype: complex64\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - saving to pc/pc2.zarr.\n",
      "2023-10-18 16:59:29 - de_ras2pc - INFO - computing graph setted. doing all the computing.\n",
      "2023-10-18 16:59:30 - de_ras2pc - INFO - computing finished.\n",
      "2023-10-18 16:59:30 - de_ras2pc - INFO - dask cluster closed.\n"
     ]
    }
   ],
   "source": [
    "de_ras2pc('pc/idx.zarr','pc/ras1.zarr','pc/pc1.zarr')\n",
    "pc_zarr1 = zarr.open('pc/pc1.zarr','r')\n",
    "np.testing.assert_array_equal(pc_data1,pc_zarr1[:])\n",
    "\n",
    "# !de_ras2pc pc/idx.zarr --ras pc/ras2.zarr --pc pc/pc2.zarr --hd_chunk_size '1'\n",
    "# pc_zarr2 = zarr.open('pc/pc2.zarr','r')\n",
    "# np.testing.assert_array_equal(pc_data2,pc_zarr2[:])\n",
    "\n",
    "de_ras2pc('pc/idx.zarr',ras=['pc/ras1.zarr','pc/ras2.zarr'],pc=['pc/pc1.zarr','pc/pc2.zarr'],hd_chunk_size=[(),(1,)])\n",
    "pc_zarr1 = zarr.open('pc/pc1.zarr','r')\n",
    "pc_zarr2 = zarr.open('pc/pc2.zarr','r')\n",
    "np.testing.assert_array_equal(pc_data1,pc_zarr1[:])\n",
    "np.testing.assert_array_equal(pc_data2,pc_zarr2[:])\n",
    "\n",
    "# !de_ras2pc pc/idx.zarr --ras pc/ras1.zarr pc/ras2.zarr --pc pc/pc1.zarr pc/pc2.zarr --hd_chunk_size '' '1'\n",
    "# pc_zarr1 = zarr.open('pc/pc1.zarr','r')\n",
    "# pc_zarr2 = zarr.open('pc/pc2.zarr','r')\n",
    "# np.testing.assert_array_equal(pc_data1,pc_zarr1[:])\n",
    "# np.testing.assert_array_equal(pc_data2,pc_zarr2[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbaeef3-786c-49d6-9e6b-d2617383f511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@log_args\n",
    "def de_pc2ras(idx:str, # point cloud index\n",
    "              pc:str|list, # path (in string) or list of path for point cloud data\n",
    "              ras:str|list, # output, path (in string) or list of path for raster data\n",
    "              shape:tuple, # shape of one image (nlines,width)\n",
    "              az_chunk_size:int=None, # output azimuth chunk size, \n",
    "              n_az_chunk:int=None, # # output number of azimuth chunks \n",
    "              log:str=None, # log file. Default: no log file\n",
    "):\n",
    "    '''Convert point cloud data to raster data, filled with nan'''\n",
    "    logger = get_logger(logfile=log)\n",
    "\n",
    "    idx_zarr = zarr.open(idx,mode='r')\n",
    "    logger.info('idx dataset shape: '+str(idx_zarr.shape))\n",
    "    logger.info('idx dataset chunks: '+str(idx_zarr.chunks))\n",
    "    assert idx_zarr.ndim == 2, \"idx dimentation is not 2.\"\n",
    "    az_chunk_size = get_az_chunk_size_from_n_pc_chunk('idx','ras',idx_zarr.shape[1],idx_zarr.chunks[1],shape[0],logger=logger,az_chunk_size=az_chunk_size,n_az_chunk=n_az_chunk)\n",
    "\n",
    "    logger.info('loading idx into memory.')\n",
    "    idx = zarr.open(idx,mode='r')[:]\n",
    "    n_pc = idx.shape[1]\n",
    "    \n",
    "    if isinstance(pc,str):\n",
    "        assert isinstance(ras,str)\n",
    "        pc_list = [pc]; ras_list = [ras]\n",
    "    else:\n",
    "        assert isinstance(pc,list); assert isinstance(ras,list)\n",
    "        pc_list = pc; ras_list = ras\n",
    "\n",
    "    logger.info('starting dask local cluster.')\n",
    "    cluster = LocalCluster()\n",
    "    client = Client(cluster)\n",
    "    logger.info('dask local cluster started.')\n",
    "\n",
    "    _ras_list = ()\n",
    "\n",
    "    for ras_path, pc_path in zip(ras_list,pc_list):\n",
    "        logger.info(f'start to work on {pc_path}')\n",
    "        pc_zarr = zarr.open(pc_path,'r')\n",
    "        logger.zarr_info(pc_path,pc_zarr)\n",
    "        \n",
    "        pc = da.from_zarr(pc_path)\n",
    "        logger.darr_info('pc', pc)\n",
    "        ras = da.empty((shape[0]*shape[1],*pc.shape[1:]),chunks = (az_chunk_size*shape[1],*pc_zarr.chunks[1:]), dtype=pc.dtype)\n",
    "        ras[:] = np.nan\n",
    "        ras[np.ravel_multi_index((idx[0],idx[1]),dims=shape)] = pc\n",
    "        ras = ras.reshape(*shape,*pc.shape[1:])\n",
    "        logger.info('create ras dask array')\n",
    "        logger.darr_info('ras', ras)\n",
    "        _ras = ras.to_zarr(ras_path,overwrite=True,compute=False)\n",
    "        _ras_list += (_ras,)\n",
    "\n",
    "    logger.info('computing graph setted. doing all the computing.')\n",
    "    da.compute(*_ras_list)\n",
    "\n",
    "    logger.info('computing finished.')\n",
    "    cluster.close()\n",
    "    logger.info('dask cluster closed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0420061b-1fad-4150-9c6b-e11665e37c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@call_parse\n",
    "def console_de_pc2ras(idx:str, # point cloud index\n",
    "                      pc:Param(type=str,required=True,nargs='+',help='one or more path for point cloud data')=None,\n",
    "                      ras:Param(type=str,required=True,nargs='+',help='output, one or more path for raster data')=None,\n",
    "                      shape:Param(type=str,required=True,help='shape of one image \"nlines,width\"')=None,\n",
    "                      az_chunk_size:int=None, # output azimuth chunk size\n",
    "                      n_az_chunk:int=None, # output number of azimuth chunks \n",
    "                      log:str=None, # log file. Default: no log file\n",
    "):\n",
    "    '''Convert point cloud data to raster data'''\n",
    "    if len(ras)==1:\n",
    "        ras = ras[0]\n",
    "        pc = pc[0]\n",
    "    \n",
    "    shape = shape.split(',')\n",
    "    shape = [int(i) for i in shape]\n",
    "    shape=tuple(shape)\n",
    "\n",
    "    de_pc2ras(idx,pc,ras,shape,az_chunk_size=az_chunk_size,n_az_chunk=n_az_chunk,log=log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b9b586-35bf-41b4-b5b0-7d4a4e70233e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: de_pc2ras [-h] --pc PC [PC ...] --ras RAS [RAS ...] --shape SHAPE\n",
      "                 [--az_chunk_size AZ_CHUNK_SIZE] [--n_az_chunk N_AZ_CHUNK]\n",
      "                 [--log LOG]\n",
      "                 idx\n",
      "\n",
      "Convert point cloud data to raster data\n",
      "\n",
      "positional arguments:\n",
      "  idx                            point cloud index\n",
      "\n",
      "options:\n",
      "  -h, --help                     show this help message and exit\n",
      "  --pc PC [PC ...]               one or more path for point cloud data\n",
      "  --ras RAS [RAS ...]            output, one or more path for raster data\n",
      "  --shape SHAPE                  shape of one image \"nlines,width\"\n",
      "  --az_chunk_size AZ_CHUNK_SIZE  output azimuth chunk size\n",
      "  --n_az_chunk N_AZ_CHUNK        output number of azimuth chunks\n",
      "  --log LOG                      log file. Default: no log file\n"
     ]
    }
   ],
   "source": [
    "!de_pc2ras -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f998e06-f4f2-4d2a-816b-c6ca8b5c8492",
   "metadata": {},
   "source": [
    "Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff5e158-5b51-4182-bc09-10481e605d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_data1 = np.random.rand(1000).astype(np.float32)\n",
    "pc_data2 = np.random.rand(1000,3).astype(np.float32)+1j*np.random.rand(1000,3).astype(np.float32)\n",
    "\n",
    "idx = np.random.choice(np.arange(100*100,dtype=np.int32),size=1000,replace=False)\n",
    "idx.sort()\n",
    "idx = np.stack(np.unravel_index(idx,shape=(100,100))).astype(np.int32)\n",
    "\n",
    "ras_data1 = np.zeros((100,100),dtype=np.float32)\n",
    "ras_data2 = np.zeros((100,100,3),dtype=np.complex64)\n",
    "ras_data1[:] = np.nan\n",
    "ras_data2[:] = np.nan\n",
    "\n",
    "ras_data1[idx[0],idx[1]] = pc_data1\n",
    "ras_data2[idx[0],idx[1]] = pc_data2\n",
    "\n",
    "idx_zarr = zarr.open('pc/idx.zarr','w',shape=idx.shape,dtype=idx.dtype,chunks=(2,200))\n",
    "pc_zarr1 = zarr.open('pc/pc1.zarr','w',shape=pc_data1.shape,dtype=pc_data1.dtype,chunks=(200,))\n",
    "pc_zarr2 = zarr.open('pc/pc2.zarr','w',shape=pc_data2.shape,dtype=pc_data2.dtype,chunks=(200,1))\n",
    "idx_zarr[:] = idx\n",
    "pc_zarr1[:] = pc_data1\n",
    "pc_zarr2[:] = pc_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7cb6b1-5a9d-4cde-8c76-0b0fb8bf4d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-18 16:57:31 - de_pc2ras - INFO - fetching args:\n",
      "2023-10-18 16:57:31 - de_pc2ras - INFO - idx = 'pc/idx.zarr'\n",
      "2023-10-18 16:57:31 - de_pc2ras - INFO - pc = 'pc/pc1.zarr'\n",
      "2023-10-18 16:57:31 - de_pc2ras - INFO - ras = 'pc/ras1.zarr'\n",
      "2023-10-18 16:57:31 - de_pc2ras - INFO - shape = (100, 100)\n",
      "2023-10-18 16:57:31 - de_pc2ras - INFO - az_chunk_size = 20\n",
      "2023-10-18 16:57:31 - de_pc2ras - INFO - n_az_chunk = None\n",
      "2023-10-18 16:57:31 - de_pc2ras - INFO - log = None\n",
      "2023-10-18 16:57:31 - de_pc2ras - INFO - fetching args done.\n",
      "2023-10-18 16:57:31 - de_pc2ras - INFO - idx dataset shape: (2, 1000)\n",
      "2023-10-18 16:57:31 - de_pc2ras - INFO - idx dataset chunks: (2, 200)\n",
      "2023-10-18 16:57:31 - de_pc2ras - INFO - got az_chunk_size for ras: 20\n",
      "2023-10-18 16:57:31 - de_pc2ras - INFO - loading idx into memory.\n",
      "2023-10-18 16:57:31 - de_pc2ras - INFO - starting dask local cluster.\n",
      "2023-10-18 16:57:33 - de_pc2ras - INFO - dask local cluster started.\n",
      "2023-10-18 16:57:33 - de_pc2ras - INFO - start to work on pc/pc1.zarr\n",
      "2023-10-18 16:57:33 - de_pc2ras - INFO - pc/pc1.zarr zarray shape: (1000,)\n",
      "2023-10-18 16:57:33 - de_pc2ras - INFO - pc/pc1.zarr zarray chunks: (200,)\n",
      "2023-10-18 16:57:33 - de_pc2ras - INFO - pc/pc1.zarr zarray dtype: float32\n",
      "2023-10-18 16:57:33 - de_pc2ras - INFO - pc dask array shape: (1000,)\n",
      "2023-10-18 16:57:33 - de_pc2ras - INFO - pc dask array chunksize: (200,)\n",
      "2023-10-18 16:57:33 - de_pc2ras - INFO - pc dask array dtype: float32\n",
      "2023-10-18 16:57:33 - de_pc2ras - INFO - create ras dask array\n",
      "2023-10-18 16:57:33 - de_pc2ras - INFO - ras dask array shape: (100, 100)\n",
      "2023-10-18 16:57:33 - de_pc2ras - INFO - ras dask array chunksize: (20, 100)\n",
      "2023-10-18 16:57:33 - de_pc2ras - INFO - ras dask array dtype: float32\n",
      "2023-10-18 16:57:33 - de_pc2ras - INFO - computing graph setted. doing all the computing.\n",
      "2023-10-18 16:57:34 - de_pc2ras - INFO - computing finished.\n",
      "2023-10-18 16:57:35 - de_pc2ras - INFO - dask cluster closed.\n",
      "2023-10-18 16:57:36 - de_pc2ras - INFO - fetching args:\n",
      "2023-10-18 16:57:36 - de_pc2ras - INFO - idx = 'pc/idx.zarr/'\n",
      "2023-10-18 16:57:36 - de_pc2ras - INFO - pc = 'pc/pc2.zarr/'\n",
      "2023-10-18 16:57:36 - de_pc2ras - INFO - ras = 'pc/ras2.zarr/'\n",
      "2023-10-18 16:57:36 - de_pc2ras - INFO - shape = (100, 100)\n",
      "2023-10-18 16:57:36 - de_pc2ras - INFO - az_chunk_size = 20\n",
      "2023-10-18 16:57:36 - de_pc2ras - INFO - n_az_chunk = None\n",
      "2023-10-18 16:57:36 - de_pc2ras - INFO - log = None\n",
      "2023-10-18 16:57:36 - de_pc2ras - INFO - fetching args done.\n",
      "2023-10-18 16:57:36 - de_pc2ras - INFO - idx dataset shape: (2, 1000)\n",
      "2023-10-18 16:57:36 - de_pc2ras - INFO - idx dataset chunks: (2, 200)\n",
      "2023-10-18 16:57:36 - de_pc2ras - INFO - got az_chunk_size for ras: 20\n",
      "2023-10-18 16:57:36 - de_pc2ras - INFO - loading idx into memory.\n",
      "2023-10-18 16:57:36 - de_pc2ras - INFO - starting dask local cluster.\n",
      "2023-10-18 16:57:39 - de_pc2ras - INFO - dask local cluster started.\n",
      "2023-10-18 16:57:39 - de_pc2ras - INFO - start to work on pc/pc2.zarr/\n",
      "2023-10-18 16:57:39 - de_pc2ras - INFO - pc/pc2.zarr/ zarray shape: (1000, 3)\n",
      "2023-10-18 16:57:39 - de_pc2ras - INFO - pc/pc2.zarr/ zarray chunks: (200, 1)\n",
      "2023-10-18 16:57:39 - de_pc2ras - INFO - pc/pc2.zarr/ zarray dtype: complex64\n",
      "2023-10-18 16:57:39 - de_pc2ras - INFO - pc dask array shape: (1000, 3)\n",
      "2023-10-18 16:57:39 - de_pc2ras - INFO - pc dask array chunksize: (200, 1)\n",
      "2023-10-18 16:57:39 - de_pc2ras - INFO - pc dask array dtype: complex64\n",
      "2023-10-18 16:57:39 - de_pc2ras - INFO - create ras dask array\n",
      "2023-10-18 16:57:39 - de_pc2ras - INFO - ras dask array shape: (100, 100, 3)\n",
      "2023-10-18 16:57:39 - de_pc2ras - INFO - ras dask array chunksize: (20, 100, 1)\n",
      "2023-10-18 16:57:39 - de_pc2ras - INFO - ras dask array dtype: complex64\n",
      "2023-10-18 16:57:39 - de_pc2ras - INFO - computing graph setted. doing all the computing.\n",
      "2023-10-18 16:57:40 - de_pc2ras - INFO - computing finished.\n",
      "2023-10-18 16:57:40 - de_pc2ras - INFO - dask cluster closed.\n",
      "2023-10-18 16:57:41 - de_pc2ras - INFO - fetching args:\n",
      "2023-10-18 16:57:41 - de_pc2ras - INFO - idx = 'pc/idx.zarr'\n",
      "2023-10-18 16:57:41 - de_pc2ras - INFO - pc = ['pc/pc1.zarr', 'pc/pc2.zarr']\n",
      "2023-10-18 16:57:41 - de_pc2ras - INFO - ras = ['pc/ras1.zarr', 'pc/ras2.zarr']\n",
      "2023-10-18 16:57:41 - de_pc2ras - INFO - shape = (100, 100)\n",
      "2023-10-18 16:57:41 - de_pc2ras - INFO - az_chunk_size = 20\n",
      "2023-10-18 16:57:41 - de_pc2ras - INFO - n_az_chunk = None\n",
      "2023-10-18 16:57:41 - de_pc2ras - INFO - log = None\n",
      "2023-10-18 16:57:41 - de_pc2ras - INFO - fetching args done.\n",
      "2023-10-18 16:57:41 - de_pc2ras - INFO - idx dataset shape: (2, 1000)\n",
      "2023-10-18 16:57:41 - de_pc2ras - INFO - idx dataset chunks: (2, 200)\n",
      "2023-10-18 16:57:41 - de_pc2ras - INFO - got az_chunk_size for ras: 20\n",
      "2023-10-18 16:57:41 - de_pc2ras - INFO - loading idx into memory.\n",
      "2023-10-18 16:57:41 - de_pc2ras - INFO - starting dask local cluster.\n",
      "2023-10-18 16:57:43 - de_pc2ras - INFO - dask local cluster started.\n",
      "2023-10-18 16:57:43 - de_pc2ras - INFO - start to work on pc/pc1.zarr\n",
      "2023-10-18 16:57:43 - de_pc2ras - INFO - pc/pc1.zarr zarray shape: (1000,)\n",
      "2023-10-18 16:57:43 - de_pc2ras - INFO - pc/pc1.zarr zarray chunks: (200,)\n",
      "2023-10-18 16:57:43 - de_pc2ras - INFO - pc/pc1.zarr zarray dtype: float32\n",
      "2023-10-18 16:57:43 - de_pc2ras - INFO - pc dask array shape: (1000,)\n",
      "2023-10-18 16:57:43 - de_pc2ras - INFO - pc dask array chunksize: (200,)\n",
      "2023-10-18 16:57:43 - de_pc2ras - INFO - pc dask array dtype: float32\n",
      "2023-10-18 16:57:43 - de_pc2ras - INFO - create ras dask array\n",
      "2023-10-18 16:57:43 - de_pc2ras - INFO - ras dask array shape: (100, 100)\n",
      "2023-10-18 16:57:43 - de_pc2ras - INFO - ras dask array chunksize: (20, 100)\n",
      "2023-10-18 16:57:43 - de_pc2ras - INFO - ras dask array dtype: float32\n",
      "2023-10-18 16:57:43 - de_pc2ras - INFO - start to work on pc/pc2.zarr\n",
      "2023-10-18 16:57:43 - de_pc2ras - INFO - pc/pc2.zarr zarray shape: (1000, 3)\n",
      "2023-10-18 16:57:43 - de_pc2ras - INFO - pc/pc2.zarr zarray chunks: (200, 1)\n",
      "2023-10-18 16:57:43 - de_pc2ras - INFO - pc/pc2.zarr zarray dtype: complex64\n",
      "2023-10-18 16:57:43 - de_pc2ras - INFO - pc dask array shape: (1000, 3)\n",
      "2023-10-18 16:57:43 - de_pc2ras - INFO - pc dask array chunksize: (200, 1)\n",
      "2023-10-18 16:57:43 - de_pc2ras - INFO - pc dask array dtype: complex64\n",
      "2023-10-18 16:57:43 - de_pc2ras - INFO - create ras dask array\n",
      "2023-10-18 16:57:43 - de_pc2ras - INFO - ras dask array shape: (100, 100, 3)\n",
      "2023-10-18 16:57:43 - de_pc2ras - INFO - ras dask array chunksize: (20, 100, 1)\n",
      "2023-10-18 16:57:43 - de_pc2ras - INFO - ras dask array dtype: complex64\n",
      "2023-10-18 16:57:43 - de_pc2ras - INFO - computing graph setted. doing all the computing.\n",
      "2023-10-18 16:57:44 - de_pc2ras - INFO - computing finished.\n",
      "2023-10-18 16:57:44 - de_pc2ras - INFO - dask cluster closed.\n",
      "2023-10-18 16:57:45 - de_pc2ras - INFO - fetching args:\n",
      "2023-10-18 16:57:45 - de_pc2ras - INFO - idx = 'pc/idx.zarr/'\n",
      "2023-10-18 16:57:45 - de_pc2ras - INFO - pc = ['pc/pc1.zarr/', 'pc/pc2.zarr/']\n",
      "2023-10-18 16:57:45 - de_pc2ras - INFO - ras = ['pc/ras1.zarr/', 'pc/ras2.zarr/']\n",
      "2023-10-18 16:57:45 - de_pc2ras - INFO - shape = (100, 100)\n",
      "2023-10-18 16:57:45 - de_pc2ras - INFO - az_chunk_size = 20\n",
      "2023-10-18 16:57:45 - de_pc2ras - INFO - n_az_chunk = None\n",
      "2023-10-18 16:57:45 - de_pc2ras - INFO - log = None\n",
      "2023-10-18 16:57:45 - de_pc2ras - INFO - fetching args done.\n",
      "2023-10-18 16:57:45 - de_pc2ras - INFO - idx dataset shape: (2, 1000)\n",
      "2023-10-18 16:57:45 - de_pc2ras - INFO - idx dataset chunks: (2, 200)\n",
      "2023-10-18 16:57:45 - de_pc2ras - INFO - got az_chunk_size for ras: 20\n",
      "2023-10-18 16:57:45 - de_pc2ras - INFO - loading idx into memory.\n",
      "2023-10-18 16:57:45 - de_pc2ras - INFO - starting dask local cluster.\n",
      "2023-10-18 16:57:48 - de_pc2ras - INFO - dask local cluster started.\n",
      "2023-10-18 16:57:48 - de_pc2ras - INFO - start to work on pc/pc1.zarr/\n",
      "2023-10-18 16:57:48 - de_pc2ras - INFO - pc/pc1.zarr/ zarray shape: (1000,)\n",
      "2023-10-18 16:57:48 - de_pc2ras - INFO - pc/pc1.zarr/ zarray chunks: (200,)\n",
      "2023-10-18 16:57:48 - de_pc2ras - INFO - pc/pc1.zarr/ zarray dtype: float32\n",
      "2023-10-18 16:57:48 - de_pc2ras - INFO - pc dask array shape: (1000,)\n",
      "2023-10-18 16:57:48 - de_pc2ras - INFO - pc dask array chunksize: (200,)\n",
      "2023-10-18 16:57:48 - de_pc2ras - INFO - pc dask array dtype: float32\n",
      "2023-10-18 16:57:48 - de_pc2ras - INFO - create ras dask array\n",
      "2023-10-18 16:57:48 - de_pc2ras - INFO - ras dask array shape: (100, 100)\n",
      "2023-10-18 16:57:48 - de_pc2ras - INFO - ras dask array chunksize: (20, 100)\n",
      "2023-10-18 16:57:48 - de_pc2ras - INFO - ras dask array dtype: float32\n",
      "2023-10-18 16:57:49 - de_pc2ras - INFO - start to work on pc/pc2.zarr/\n",
      "2023-10-18 16:57:49 - de_pc2ras - INFO - pc/pc2.zarr/ zarray shape: (1000, 3)\n",
      "2023-10-18 16:57:49 - de_pc2ras - INFO - pc/pc2.zarr/ zarray chunks: (200, 1)\n",
      "2023-10-18 16:57:49 - de_pc2ras - INFO - pc/pc2.zarr/ zarray dtype: complex64\n",
      "2023-10-18 16:57:49 - de_pc2ras - INFO - pc dask array shape: (1000, 3)\n",
      "2023-10-18 16:57:49 - de_pc2ras - INFO - pc dask array chunksize: (200, 1)\n",
      "2023-10-18 16:57:49 - de_pc2ras - INFO - pc dask array dtype: complex64\n",
      "2023-10-18 16:57:49 - de_pc2ras - INFO - create ras dask array\n",
      "2023-10-18 16:57:49 - de_pc2ras - INFO - ras dask array shape: (100, 100, 3)\n",
      "2023-10-18 16:57:49 - de_pc2ras - INFO - ras dask array chunksize: (20, 100, 1)\n",
      "2023-10-18 16:57:49 - de_pc2ras - INFO - ras dask array dtype: complex64\n",
      "2023-10-18 16:57:49 - de_pc2ras - INFO - computing graph setted. doing all the computing.\n",
      "2023-10-18 16:57:49 - de_pc2ras - INFO - computing finished.\n",
      "2023-10-18 16:57:50 - de_pc2ras - INFO - dask cluster closed.\n"
     ]
    }
   ],
   "source": [
    "de_pc2ras('pc/idx.zarr','pc/pc1.zarr','pc/ras1.zarr',shape=(100,100),az_chunk_size=20)\n",
    "ras_zarr1 = zarr.open('pc/ras1.zarr','r')\n",
    "np.testing.assert_array_equal(ras_data1,ras_zarr1[:])\n",
    "\n",
    "!de_pc2ras pc/idx.zarr/ --pc pc/pc2.zarr/ --ras pc/ras2.zarr/ --shape \"100,100\" --az_chunk_size 20\n",
    "ras_zarr2 = zarr.open('pc/ras2.zarr','r')\n",
    "np.testing.assert_array_equal(ras_data2,ras_zarr2[:])\n",
    "\n",
    "de_pc2ras('pc/idx.zarr',['pc/pc1.zarr','pc/pc2.zarr'],['pc/ras1.zarr','pc/ras2.zarr'],shape=(100,100),az_chunk_size=20)\n",
    "ras_zarr1 = zarr.open('pc/ras1.zarr','r')\n",
    "ras_zarr2 = zarr.open('pc/ras2.zarr','r')\n",
    "np.testing.assert_array_equal(ras_data1,ras_zarr1[:])\n",
    "np.testing.assert_array_equal(ras_data2,ras_zarr2[:])\n",
    "\n",
    "!de_pc2ras pc/idx.zarr/ --pc pc/pc1.zarr/ pc/pc2.zarr/ --ras pc/ras1.zarr/ pc/ras2.zarr/ --shape \"100,100\" --az_chunk_size 20\n",
    "ras_zarr1 = zarr.open('pc/ras1.zarr','r')\n",
    "ras_zarr2 = zarr.open('pc/ras2.zarr','r')\n",
    "np.testing.assert_array_equal(ras_data1,ras_zarr1[:])\n",
    "np.testing.assert_array_equal(ras_data2,ras_zarr2[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bae521-e1b0-4b4d-82eb-699964597b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@call_parse\n",
    "@log_args\n",
    "def de_pc_union(idx1:str, # index of the first point cloud\n",
    "                idx2:str, # index of the second point cloud\n",
    "                idx:str, # output, index of the union point cloud\n",
    "                pc1:str|list=None, # path (in string) or list of path for the first point cloud data\n",
    "                pc2:str|list=None, # path (in string) or list of path for the second point cloud data\n",
    "                pc:str|list=None, #output, path (in string) or list of path for the union point cloud data\n",
    "                pc_chunk_size:int=None, # chunk size in output data,optional\n",
    "                n_pc_chunk:int=None, # number of chunk in output data, optional\n",
    "                log:str=None, # log file. Default: no log file\n",
    "):\n",
    "    '''Get the union of two point cloud dataset.\n",
    "    For points at their intersection, pc_data1 rather than pc_data2 is copied to the result pc_data.\n",
    "    `pc_chunk_size` and `n_pc_chunk` are used to determine the final pc_chunk_size.\n",
    "    If non of them are provided, the n_pc_chunk is set to n_chunk in idx1.\n",
    "    '''\n",
    "    logger = get_logger(logfile=log)\n",
    "\n",
    "    idx1_zarr = zarr.open(idx1,mode='r'); logger.zarr_info(idx1,idx1_zarr)\n",
    "    idx2_zarr = zarr.open(idx2,mode='r'); logger.zarr_info(idx2,idx2_zarr)\n",
    "    logger.info('loading idx1 and idx2 into memory.')\n",
    "    idx1 = idx1_zarr[:]; idx2 = idx2_zarr[:]\n",
    "\n",
    "    logger.info('calculate the union')\n",
    "    idx_path = idx\n",
    "    idx, inv_iidx1, inv_iidx2, iidx2 = pc_union(idx1,idx2)\n",
    "    n_pc = idx.shape[1]\n",
    "    logger.info(f'number of points in the union: {idx.shape[1]}')\n",
    "    pc_chunk_size = get_pc_chunk_size_from_n_pc_chunk('idx1','idx',idx1_zarr.shape[1],idx1_zarr.chunks[1],n_pc,logger,pc_chunk_size=pc_chunk_size,n_pc_chunk=n_pc_chunk)\n",
    "    \n",
    "    idx_zarr = zarr.open(idx_path,'w',shape=idx.shape,dtype=idx.dtype,chunks=(2,pc_chunk_size))\n",
    "    logger.info('write union idx')\n",
    "    idx_zarr[:] = idx\n",
    "    logger.info('write done')\n",
    "    logger.zarr_info(idx_path, idx_zarr)\n",
    "    \n",
    "    if pc1 is None:\n",
    "        logger.info('no point cloud data provided, exit.')\n",
    "        return None\n",
    "\n",
    "    if isinstance(pc1,str):\n",
    "        assert isinstance(pc2,str); assert isinstance(pc,str)\n",
    "        pc1_list = [pc1]; pc2_list = [pc2]; pc_list = [pc]\n",
    "    else:\n",
    "        assert isinstance(pc1,list); assert isinstance(pc2,list); assert isinstance(pc,list)\n",
    "        pc1_list = pc1; pc2_list = pc2; pc_list = pc\n",
    "\n",
    "    logger.info('starting dask local cluster.')\n",
    "    cluster = LocalCluster()\n",
    "    client = Client(cluster)\n",
    "    logger.info('dask local cluster started.')\n",
    "    \n",
    "    _pc_list = ()\n",
    "    for pc1_path, pc2_path, pc_path in zip(pc1_list,pc2_list,pc_list):\n",
    "        pc1_zarr = zarr.open(pc1_path,'r'); pc2_zarr = zarr.open(pc2_path,'r')\n",
    "        logger.zarr_info(pc1_path, pc1_zarr); logger.zarr_info(pc2_path, pc2_zarr);\n",
    "        pc1 = da.from_zarr(pc1_path); pc2 = da.from_zarr(pc2_path)\n",
    "        logger.darr_info('pc1', pc1); logger.darr_info('pc2',pc2)\n",
    "        logger.info('set up union pc data dask array.')\n",
    "        pc = da.empty((n_pc,*pc1.shape[1:]),chunks = (pc_chunk_size,*pc1.chunks[1:]), dtype=pc1.dtype)\n",
    "        logger.darr_info('pc',pc)\n",
    "        pc[inv_iidx1] = pc1\n",
    "        pc[inv_iidx2] = pc2[iidx2]\n",
    "        _pc = pc.to_zarr(pc_path, overwrite=True,compute=False)\n",
    "        _pc_list += (_pc,)\n",
    "\n",
    "    logger.info('computing graph setted. doing all the computing.')\n",
    "    da.compute(*_pc_list)\n",
    "\n",
    "    logger.info('computing finished.')\n",
    "    cluster.close()\n",
    "    logger.info('dask cluster closed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16bf1ca-6d42-4265-9fc6-0440e217a807",
   "metadata": {},
   "source": [
    "Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61804e8c-9fd9-4f91-9d2e-75b327b4f11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_data1 = np.random.rand(1000,3).astype(np.float32)+1j*np.random.rand(1000,3).astype(np.float32)\n",
    "pc_data2 = np.random.rand(800,3).astype(np.float32)+1j*np.random.rand(800,3).astype(np.float32)\n",
    "\n",
    "idx1 = np.random.choice(np.arange(100*100,dtype=np.int32),size=1000,replace=False)\n",
    "idx1.sort()\n",
    "idx1 = np.stack(np.unravel_index(idx1,shape=(100,100))).astype(np.int32)\n",
    "\n",
    "idx2 = np.random.choice(np.arange(100*100,dtype=np.int32),size=800,replace=False)\n",
    "idx2.sort()\n",
    "idx2 = np.stack(np.unravel_index(idx2,shape=(100,100))).astype(np.int32)\n",
    "\n",
    "idx, inv_iidx1, inv_iidx2, iidx2 = pc_union(idx1,idx2)\n",
    "\n",
    "pc_data = np.empty((idx.shape[1],*pc_data1.shape[1:]),dtype=pc_data1.dtype)\n",
    "pc_data[inv_iidx1] = pc_data1\n",
    "pc_data[inv_iidx2] = pc_data2[iidx2]\n",
    "\n",
    "idx1_zarr = zarr.open('pc/idx1.zarr','w',shape=idx1.shape,dtype=idx1.dtype,chunks=(2,200))\n",
    "idx2_zarr = zarr.open('pc/idx2.zarr','w',shape=idx2.shape,dtype=idx2.dtype,chunks=(2,200))\n",
    "pc1_zarr = zarr.open('pc/pc1.zarr','w',shape=pc_data1.shape,dtype=pc_data1.dtype,chunks=(200,1))\n",
    "pc2_zarr = zarr.open('pc/pc2.zarr','w',shape=pc_data2.shape,dtype=pc_data2.dtype,chunks=(200,1))\n",
    "idx1_zarr[:] = idx1\n",
    "idx2_zarr[:] = idx2\n",
    "pc1_zarr[:] = pc_data1\n",
    "pc2_zarr[:] = pc_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32ea61e-8437-4fa8-b6ed-844040dc293c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-18 16:52:14 - de_pc_union - INFO - fetching args:\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - idx1 = 'pc/idx1.zarr'\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - idx2 = 'pc/idx2.zarr'\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - idx = 'pc/idx.zarr'\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - pc1 = None\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - pc2 = None\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - pc = None\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - pc_chunk_size = None\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - n_pc_chunk = None\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - log = None\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - fetching args done.\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - pc/idx1.zarr zarray shape: (2, 1000)\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - pc/idx1.zarr zarray chunks: (2, 200)\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - pc/idx1.zarr zarray dtype: int32\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - pc/idx2.zarr zarray shape: (2, 800)\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - pc/idx2.zarr zarray chunks: (2, 200)\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - pc/idx2.zarr zarray dtype: int32\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - loading idx1 and idx2 into memory.\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - calculate the union\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - number of points in the union: 1718\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - automatically determine pc_chunk_size from n_pc of idx and n_pc_chunk of idx1\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - pc_chunk_size for idx: 344\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - write union idx\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - write done\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - pc/idx.zarr zarray shape: (2, 1718)\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - pc/idx.zarr zarray chunks: (2, 344)\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - pc/idx.zarr zarray dtype: int32\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - no point cloud data provided, exit.\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - fetching args:\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - idx1 = 'pc/idx1.zarr'\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - idx2 = 'pc/idx2.zarr'\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - idx = 'pc/idx.zarr'\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - pc1 = 'pc/pc1.zarr'\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - pc2 = 'pc/pc2.zarr'\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - pc = 'pc/pc.zarr'\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - pc_chunk_size = None\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - n_pc_chunk = None\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - log = None\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - fetching args done.\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - pc/idx1.zarr zarray shape: (2, 1000)\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - pc/idx1.zarr zarray chunks: (2, 200)\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - pc/idx1.zarr zarray dtype: int32\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - pc/idx2.zarr zarray shape: (2, 800)\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - pc/idx2.zarr zarray chunks: (2, 200)\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - pc/idx2.zarr zarray dtype: int32\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - loading idx1 and idx2 into memory.\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - calculate the union\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - number of points in the union: 1718\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - automatically determine pc_chunk_size from n_pc of idx and n_pc_chunk of idx1\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - pc_chunk_size for idx: 344\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - write union idx\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - write done\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - pc/idx.zarr zarray shape: (2, 1718)\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - pc/idx.zarr zarray chunks: (2, 344)\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - pc/idx.zarr zarray dtype: int32\n",
      "2023-10-18 16:52:14 - de_pc_union - INFO - starting dask local cluster.\n",
      "2023-10-18 16:52:16 - de_pc_union - INFO - dask local cluster started.\n",
      "2023-10-18 16:52:16 - de_pc_union - INFO - pc/pc1.zarr zarray shape: (1000, 3)\n",
      "2023-10-18 16:52:16 - de_pc_union - INFO - pc/pc1.zarr zarray chunks: (200, 1)\n",
      "2023-10-18 16:52:16 - de_pc_union - INFO - pc/pc1.zarr zarray dtype: complex64\n",
      "2023-10-18 16:52:16 - de_pc_union - INFO - pc/pc2.zarr zarray shape: (800, 3)\n",
      "2023-10-18 16:52:16 - de_pc_union - INFO - pc/pc2.zarr zarray chunks: (200, 1)\n",
      "2023-10-18 16:52:16 - de_pc_union - INFO - pc/pc2.zarr zarray dtype: complex64\n",
      "2023-10-18 16:52:16 - de_pc_union - INFO - pc1 dask array shape: (1000, 3)\n",
      "2023-10-18 16:52:16 - de_pc_union - INFO - pc1 dask array chunksize: (200, 1)\n",
      "2023-10-18 16:52:16 - de_pc_union - INFO - pc1 dask array dtype: complex64\n",
      "2023-10-18 16:52:16 - de_pc_union - INFO - pc2 dask array shape: (800, 3)\n",
      "2023-10-18 16:52:16 - de_pc_union - INFO - pc2 dask array chunksize: (200, 1)\n",
      "2023-10-18 16:52:16 - de_pc_union - INFO - pc2 dask array dtype: complex64\n",
      "2023-10-18 16:52:16 - de_pc_union - INFO - set up union pc data dask array.\n",
      "2023-10-18 16:52:16 - de_pc_union - INFO - pc dask array shape: (1718, 3)\n",
      "2023-10-18 16:52:16 - de_pc_union - INFO - pc dask array chunksize: (344, 1)\n",
      "2023-10-18 16:52:16 - de_pc_union - INFO - pc dask array dtype: complex64\n",
      "2023-10-18 16:52:16 - de_pc_union - INFO - computing graph setted. doing all the computing.\n",
      "2023-10-18 16:52:18 - de_pc_union - INFO - computing finished.\n",
      "2023-10-18 16:52:18 - de_pc_union - INFO - dask cluster closed.\n"
     ]
    }
   ],
   "source": [
    "de_pc_union('pc/idx1.zarr','pc/idx2.zarr','pc/idx.zarr')\n",
    "de_pc_union('pc/idx1.zarr','pc/idx2.zarr','pc/idx.zarr','pc/pc1.zarr','pc/pc2.zarr','pc/pc.zarr')\n",
    "idx_zarr = zarr.open('pc/idx.zarr','r')\n",
    "pc_zarr = zarr.open('pc/pc.zarr','r')\n",
    "np.testing.assert_array_equal(idx_zarr[:],idx)\n",
    "np.testing.assert_array_equal(pc_zarr[:],pc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e165db47-38a1-4ce9-870f-4d27f79bd848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@call_parse\n",
    "@log_args\n",
    "def de_pc_intersect(idx1:str, # index of the first point cloud\n",
    "                    idx2:str, # index of the second point cloud\n",
    "                    idx:str, # output, index of the union point cloud\n",
    "                    pc1:str|list=None, # path (in string) or list of path for the first point cloud data\n",
    "                    pc2:str|list=None, # path (in string) or list of path for the second point cloud data\n",
    "                    pc:str|list=None, #output, path (in string) or list of path for the union point cloud data\n",
    "                    pc_chunk_size:int=None, # chunk size in output data,optional\n",
    "                    n_pc_chunk:int=None, # number of chunk in output data, optional\n",
    "                    prefer_1=True, # save pc1 on intersection to output pc dataset by default `True`. Otherwise, save data from pc2\n",
    "                    log:str=None, # log file. Default: no log file\n",
    "):\n",
    "    '''Get the intersection of two point cloud dataset.\n",
    "    `pc_chunk_size` and `n_pc_chunk` are used to determine the final pc_chunk_size.\n",
    "    If non of them are provided, the n_pc_chunk is set to n_chunk in idx1.\n",
    "    '''\n",
    "    logger = get_logger(logfile=log)\n",
    "\n",
    "    idx1_zarr = zarr.open(idx1,mode='r'); logger.zarr_info(idx1,idx1_zarr)\n",
    "    idx2_zarr = zarr.open(idx2,mode='r'); logger.zarr_info(idx2,idx2_zarr)\n",
    "    logger.info('loading idx1 and idx2 into memory.')\n",
    "    idx1 = idx1_zarr[:]; idx2 = idx2_zarr[:]\n",
    "\n",
    "    logger.info('calculate the intersection')\n",
    "    idx_path = idx\n",
    "    idx, iidx1, iidx2 = pc_intersect(idx1,idx2)\n",
    "    n_pc = idx.shape[1]\n",
    "    logger.info(f'number of points in the intersection: {idx.shape[1]}')\n",
    "    pc_chunk_size = get_pc_chunk_size_from_n_pc_chunk('idx1','idx',idx1_zarr.shape[1],idx1_zarr.chunks[1],n_pc,logger,pc_chunk_size=pc_chunk_size,n_pc_chunk=n_pc_chunk)\n",
    "    \n",
    "    idx_zarr = zarr.open(idx_path,'w',shape=idx.shape,dtype=idx.dtype,chunks=(2,pc_chunk_size))\n",
    "    logger.info('write intersect idx')\n",
    "    idx_zarr[:] = idx\n",
    "    logger.info('write done')\n",
    "    logger.zarr_info(idx_path, idx_zarr)\n",
    "\n",
    "    if (pc1 is None) and (pc2 is None):\n",
    "        logger.info('no point cloud data provided, exit.')\n",
    "        return None\n",
    "\n",
    "    if prefer_1:\n",
    "        logger.info('select pc1 as pc_input.')\n",
    "        iidx = iidx1; pc_input = pc1\n",
    "    else:\n",
    "        logger.info('select pc2 as pc_input.')\n",
    "        iidx = iidx2; pc_input = pc2\n",
    "\n",
    "    if isinstance(pc_input,str):\n",
    "        assert isinstance(pc,str)\n",
    "        pc_input_list = [pc_input]; pc_list = [pc]\n",
    "    else:\n",
    "        assert isinstance(pc_input,list); assert isinstance(pc,list)\n",
    "        pc_input_list = pc_input; pc_list = pc\n",
    "\n",
    "    logger.info('starting dask local cluster.')\n",
    "    cluster = LocalCluster(); client = Client(cluster)\n",
    "    logger.info('dask local cluster started.')\n",
    "    \n",
    "    _pc_list = ()\n",
    "    for pc_input_path, pc_path in zip(pc_input_list,pc_list):\n",
    "        pc_input_zarr = zarr.open(pc_input_path,'r')\n",
    "        logger.zarr_info(pc_input_path,pc_input_zarr)\n",
    "        pc_input = da.from_zarr(pc_input_path)\n",
    "        logger.darr_info('pc_input', pc_input)\n",
    "\n",
    "        logger.info('set up intersect pc data dask array.')\n",
    "        pc = da.empty((n_pc,*pc_input.shape[1:]),chunks = (pc_chunk_size,*pc_input.chunks[1:]), dtype=pc_input.dtype)\n",
    "        logger.darr_info('pc',pc)\n",
    "        pc[:] = pc_input[iidx]\n",
    "        _pc = pc.to_zarr(pc_path, overwrite=True,compute=False)\n",
    "        _pc_list += (_pc,)\n",
    "\n",
    "    logger.info('computing graph setted. doing all the computing.')\n",
    "    da.compute(*_pc_list)\n",
    "\n",
    "    logger.info('computing finished.')\n",
    "    cluster.close()\n",
    "    logger.info('dask cluster closed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d15aec-f241-4fcf-96e0-c839994ac04b",
   "metadata": {},
   "source": [
    "Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5e1d41-a087-4bdd-9e17-fa3021fc0045",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_data1 = np.random.rand(1000,3).astype(np.float32)+1j*np.random.rand(1000,3).astype(np.float32)\n",
    "pc_data2 = np.random.rand(800,3).astype(np.float32)+1j*np.random.rand(800,3).astype(np.float32)\n",
    "\n",
    "idx1 = np.random.choice(np.arange(100*100,dtype=np.int32),size=1000,replace=False)\n",
    "idx1.sort()\n",
    "idx1 = np.stack(np.unravel_index(idx1,shape=(100,100))).astype(np.int32)\n",
    "\n",
    "idx2 = np.random.choice(np.arange(100*100,dtype=np.int32),size=800,replace=False)\n",
    "idx2.sort()\n",
    "idx2 = np.stack(np.unravel_index(idx2,shape=(100,100))).astype(np.int32)\n",
    "\n",
    "idx, iidx1, iidx2 = pc_intersect(idx1,idx2)\n",
    "\n",
    "pc_data = np.empty((idx.shape[1],*pc_data1.shape[1:]),dtype=pc_data1.dtype)\n",
    "pc_data[:] = pc_data2[iidx2]\n",
    "\n",
    "idx1_zarr = zarr.open('pc/idx1.zarr','w',shape=idx1.shape,dtype=idx1.dtype,chunks=(2,200))\n",
    "idx2_zarr = zarr.open('pc/idx2.zarr','w',shape=idx2.shape,dtype=idx2.dtype,chunks=(2,200))\n",
    "pc1_zarr = zarr.open('pc/pc1.zarr','w',shape=pc_data1.shape,dtype=pc_data1.dtype,chunks=(200,1))\n",
    "pc2_zarr = zarr.open('pc/pc2.zarr','w',shape=pc_data2.shape,dtype=pc_data2.dtype,chunks=(200,1))\n",
    "idx1_zarr[:] = idx1\n",
    "idx2_zarr[:] = idx2\n",
    "pc1_zarr[:] = pc_data1\n",
    "pc2_zarr[:] = pc_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79624277-e4e9-488f-9785-b41a201db068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - fetching args:\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - idx1 = 'pc/idx1.zarr'\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - idx2 = 'pc/idx2.zarr'\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - idx = 'pc/idx.zarr'\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - pc1 = None\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - pc2 = None\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - pc = None\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - pc_chunk_size = None\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - n_pc_chunk = None\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - prefer_1 = True\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - log = None\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - fetching args done.\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - pc/idx1.zarr zarray shape: (2, 1000)\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - pc/idx1.zarr zarray chunks: (2, 200)\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - pc/idx1.zarr zarray dtype: int32\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - pc/idx2.zarr zarray shape: (2, 800)\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - pc/idx2.zarr zarray chunks: (2, 200)\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - pc/idx2.zarr zarray dtype: int32\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - loading idx1 and idx2 into memory.\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - calculate the intersection\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - number of points in the intersection: 81\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - automatically determine pc_chunk_size from n_pc of idx and n_pc_chunk of idx1\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - pc_chunk_size for idx: 17\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - write intersect idx\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - write done\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - pc/idx.zarr zarray shape: (2, 81)\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - pc/idx.zarr zarray chunks: (2, 17)\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - pc/idx.zarr zarray dtype: int32\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - no point cloud data provided, exit.\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - fetching args:\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - idx1 = 'pc/idx1.zarr'\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - idx2 = 'pc/idx2.zarr'\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - idx = 'pc/idx.zarr'\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - pc1 = None\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - pc2 = 'pc/pc2.zarr'\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - pc = 'pc/pc.zarr'\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - pc_chunk_size = None\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - n_pc_chunk = None\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - prefer_1 = False\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - log = None\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - fetching args done.\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - pc/idx1.zarr zarray shape: (2, 1000)\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - pc/idx1.zarr zarray chunks: (2, 200)\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - pc/idx1.zarr zarray dtype: int32\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - pc/idx2.zarr zarray shape: (2, 800)\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - pc/idx2.zarr zarray chunks: (2, 200)\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - pc/idx2.zarr zarray dtype: int32\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - loading idx1 and idx2 into memory.\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - calculate the intersection\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - number of points in the intersection: 81\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - automatically determine pc_chunk_size from n_pc of idx and n_pc_chunk of idx1\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - pc_chunk_size for idx: 17\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - write intersect idx\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - write done\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - pc/idx.zarr zarray shape: (2, 81)\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - pc/idx.zarr zarray chunks: (2, 17)\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - pc/idx.zarr zarray dtype: int32\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - select pc2 as pc_input.\n",
      "2023-10-18 16:45:03 - de_pc_intersect - INFO - starting dask local cluster.\n",
      "2023-10-18 16:45:05 - de_pc_intersect - INFO - dask local cluster started.\n",
      "2023-10-18 16:45:05 - de_pc_intersect - INFO - pc/pc2.zarr zarray shape: (800, 3)\n",
      "2023-10-18 16:45:05 - de_pc_intersect - INFO - pc/pc2.zarr zarray chunks: (200, 1)\n",
      "2023-10-18 16:45:05 - de_pc_intersect - INFO - pc/pc2.zarr zarray dtype: complex64\n",
      "2023-10-18 16:45:05 - de_pc_intersect - INFO - pc_input dask array shape: (800, 3)\n",
      "2023-10-18 16:45:05 - de_pc_intersect - INFO - pc_input dask array chunksize: (200, 1)\n",
      "2023-10-18 16:45:05 - de_pc_intersect - INFO - pc_input dask array dtype: complex64\n",
      "2023-10-18 16:45:05 - de_pc_intersect - INFO - set up intersect pc data dask array.\n",
      "2023-10-18 16:45:05 - de_pc_intersect - INFO - pc dask array shape: (81, 3)\n",
      "2023-10-18 16:45:05 - de_pc_intersect - INFO - pc dask array chunksize: (17, 1)\n",
      "2023-10-18 16:45:05 - de_pc_intersect - INFO - pc dask array dtype: complex64\n",
      "2023-10-18 16:45:05 - de_pc_intersect - INFO - computing graph setted. doing all the computing.\n",
      "2023-10-18 16:45:06 - de_pc_intersect - INFO - computing finished.\n",
      "2023-10-18 16:45:06 - de_pc_intersect - INFO - dask cluster closed.\n"
     ]
    }
   ],
   "source": [
    "de_pc_intersect('pc/idx1.zarr','pc/idx2.zarr','pc/idx.zarr')\n",
    "de_pc_intersect('pc/idx1.zarr','pc/idx2.zarr','pc/idx.zarr',pc2='pc/pc2.zarr', pc='pc/pc.zarr',prefer_1=False)\n",
    "idx_zarr = zarr.open('pc/idx.zarr','r')\n",
    "pc_zarr = zarr.open('pc/pc.zarr','r')\n",
    "np.testing.assert_array_equal(idx_zarr[:],idx)\n",
    "np.testing.assert_array_equal(pc_zarr[:],pc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6709657-ac69-48d5-8c89-72a42cc19939",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@call_parse\n",
    "@log_args\n",
    "def de_pc_diff(idx1:str, # index of the first point cloud\n",
    "               idx2:str, # index of the second point cloud\n",
    "               idx:str, # output, index of the union point cloud\n",
    "               pc1:str|list=None, # path (in string) or list of path for the first point cloud data\n",
    "               pc:str|list=None, #output, path (in string) or list of path for the union point cloud data\n",
    "               pc_chunk_size:int=None, # chunk size in output data,optional\n",
    "               n_pc_chunk:int=None, # number of chunk in output data, optional\n",
    "               log:str=None, # log file. Default: no log file\n",
    "              ):\n",
    "    '''Get the point cloud in `idx1` that are not in `idx2`.\n",
    "    `pc_chunk_size` and `n_pc_chunk` are used to determine the final pc_chunk_size.\n",
    "    If non of them are provided, the n_pc_chunk is set to n_chunk in idx1.\n",
    "    '''\n",
    "    logger = get_logger(logfile=log)\n",
    "\n",
    "    idx1_zarr = zarr.open(idx1,mode='r'); logger.zarr_info(idx1,idx1_zarr)\n",
    "    idx2_zarr = zarr.open(idx2,mode='r'); logger.zarr_info(idx2,idx2_zarr)\n",
    "    logger.info('loading idx1 and idx2 into memory.')\n",
    "    idx1 = idx1_zarr[:]; idx2 = idx2_zarr[:]\n",
    "\n",
    "    logger.info('calculate the diff.')\n",
    "    idx_path = idx\n",
    "    idx, iidx1 = pc_diff(idx1,idx2)\n",
    "    n_pc = idx.shape[1]\n",
    "    logger.info(f'number of points in the diff: {idx.shape[1]}')\n",
    "    pc_chunk_size = get_pc_chunk_size_from_n_pc_chunk('idx1','idx',idx1_zarr.shape[1],idx1_zarr.chunks[1],n_pc,logger,pc_chunk_size=pc_chunk_size,n_pc_chunk=n_pc_chunk)\n",
    "    \n",
    "    idx_zarr = zarr.open(idx_path,'w',shape=idx.shape,dtype=idx.dtype,chunks=(2,pc_chunk_size))\n",
    "    logger.info('write intersect idx')\n",
    "    idx_zarr[:] = idx\n",
    "    logger.info('write done')\n",
    "    logger.zarr_info(idx_path, idx_zarr)\n",
    "\n",
    "    if pc1 is None:\n",
    "        logger.info('no point cloud data provided, exit.')\n",
    "        return None\n",
    "\n",
    "    if isinstance(pc1,str):\n",
    "        assert isinstance(pc,str)\n",
    "        pc1_list = [pc1]; pc_list = [pc]\n",
    "    else:\n",
    "        assert isinstance(pc1,list); assert isinstance(pc,list)\n",
    "        pc1_list = pc1; pc_list = pc\n",
    "\n",
    "    logger.info('starting dask local cluster.')\n",
    "    cluster = LocalCluster(); client = Client(cluster)\n",
    "    logger.info('dask local cluster started.')\n",
    "    \n",
    "    _pc_list = ()\n",
    "    for pc1_path, pc_path in zip(pc1_list,pc_list):\n",
    "        pc1_zarr = zarr.open(pc1_path,'r'); logger.zarr_info(pc1_path, pc1_zarr)\n",
    "        pc1 = da.from_zarr(pc1_path); logger.darr_info('pc1', pc1)\n",
    "        logger.info('set up diff pc data dask array.')\n",
    "        pc = da.empty((n_pc,*pc1.shape[1:]),chunks = (pc_chunk_size,*pc1.chunks[1:]), dtype=pc1.dtype)\n",
    "        logger.darr_info('pc',pc)\n",
    "        pc[:] = pc1[iidx1]\n",
    "        _pc = pc.to_zarr(pc_path, overwrite=True,compute=False)\n",
    "        _pc_list += (_pc,)\n",
    "\n",
    "    logger.info('computing graph setted. doing all the computing.')\n",
    "    da.compute(*_pc_list)\n",
    "\n",
    "    logger.info('computing finished.')\n",
    "    cluster.close()\n",
    "    logger.info('dask cluster closed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2053e3-a509-4089-87b4-2fd605a23cab",
   "metadata": {},
   "source": [
    "Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e674d6-5b0d-448c-b456-a0bbf1823db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_data1 = np.random.rand(1000,3).astype(np.float32)+1j*np.random.rand(1000,3).astype(np.float32)\n",
    "\n",
    "idx1 = np.random.choice(np.arange(100*100,dtype=np.int32),size=1000,replace=False)\n",
    "idx1.sort()\n",
    "idx1 = np.stack(np.unravel_index(idx1,shape=(100,100))).astype(np.int32)\n",
    "\n",
    "idx2 = np.random.choice(np.arange(100*100,dtype=np.int32),size=800,replace=False)\n",
    "idx2.sort()\n",
    "idx2 = np.stack(np.unravel_index(idx2,shape=(100,100))).astype(np.int32)\n",
    "\n",
    "idx, iidx1 = pc_diff(idx1,idx2)\n",
    "\n",
    "pc_data = np.empty((idx.shape[1],*pc_data1.shape[1:]),dtype=pc_data1.dtype)\n",
    "pc_data[:] = pc_data1[iidx1]\n",
    "\n",
    "idx1_zarr = zarr.open('pc/idx1.zarr','w',shape=idx1.shape,dtype=idx1.dtype,chunks=(2,200))\n",
    "idx2_zarr = zarr.open('pc/idx2.zarr','w',shape=idx2.shape,dtype=idx2.dtype,chunks=(2,200))\n",
    "pc1_zarr = zarr.open('pc/pc1.zarr','w',shape=pc_data1.shape,dtype=pc_data1.dtype,chunks=(200,1))\n",
    "idx1_zarr[:] = idx1\n",
    "idx2_zarr[:] = idx2\n",
    "pc1_zarr[:] = pc_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bc9d97-3e59-4185-978c-e79606560c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-18 16:45:07 - de_pc_diff - INFO - fetching args:\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - idx1 = 'pc/idx1.zarr'\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - idx2 = 'pc/idx2.zarr'\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - idx = 'pc/idx.zarr'\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - pc1 = None\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - pc = None\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - pc_chunk_size = None\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - n_pc_chunk = None\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - log = None\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - fetching args done.\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - pc/idx1.zarr zarray shape: (2, 1000)\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - pc/idx1.zarr zarray chunks: (2, 200)\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - pc/idx1.zarr zarray dtype: int32\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - pc/idx2.zarr zarray shape: (2, 800)\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - pc/idx2.zarr zarray chunks: (2, 200)\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - pc/idx2.zarr zarray dtype: int32\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - loading idx1 and idx2 into memory.\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - calculate the diff.\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - number of points in the diff: 906\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - automatically determine pc_chunk_size from n_pc of idx and n_pc_chunk of idx1\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - pc_chunk_size for idx: 182\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - write intersect idx\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - write done\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - pc/idx.zarr zarray shape: (2, 906)\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - pc/idx.zarr zarray chunks: (2, 182)\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - pc/idx.zarr zarray dtype: int32\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - no point cloud data provided, exit.\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - fetching args:\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - idx1 = 'pc/idx1.zarr'\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - idx2 = 'pc/idx2.zarr'\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - idx = 'pc/idx.zarr'\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - pc1 = 'pc/pc1.zarr'\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - pc = 'pc/pc.zarr'\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - pc_chunk_size = None\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - n_pc_chunk = None\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - log = None\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - fetching args done.\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - pc/idx1.zarr zarray shape: (2, 1000)\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - pc/idx1.zarr zarray chunks: (2, 200)\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - pc/idx1.zarr zarray dtype: int32\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - pc/idx2.zarr zarray shape: (2, 800)\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - pc/idx2.zarr zarray chunks: (2, 200)\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - pc/idx2.zarr zarray dtype: int32\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - loading idx1 and idx2 into memory.\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - calculate the diff.\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - number of points in the diff: 906\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - automatically determine pc_chunk_size from n_pc of idx and n_pc_chunk of idx1\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - pc_chunk_size for idx: 182\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - write intersect idx\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - write done\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - pc/idx.zarr zarray shape: (2, 906)\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - pc/idx.zarr zarray chunks: (2, 182)\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - pc/idx.zarr zarray dtype: int32\n",
      "2023-10-18 16:45:07 - de_pc_diff - INFO - starting dask local cluster.\n",
      "2023-10-18 16:45:09 - de_pc_diff - INFO - dask local cluster started.\n",
      "2023-10-18 16:45:09 - de_pc_diff - INFO - pc/pc1.zarr zarray shape: (1000, 3)\n",
      "2023-10-18 16:45:09 - de_pc_diff - INFO - pc/pc1.zarr zarray chunks: (200, 1)\n",
      "2023-10-18 16:45:09 - de_pc_diff - INFO - pc/pc1.zarr zarray dtype: complex64\n",
      "2023-10-18 16:45:09 - de_pc_diff - INFO - pc1 dask array shape: (1000, 3)\n",
      "2023-10-18 16:45:09 - de_pc_diff - INFO - pc1 dask array chunksize: (200, 1)\n",
      "2023-10-18 16:45:09 - de_pc_diff - INFO - pc1 dask array dtype: complex64\n",
      "2023-10-18 16:45:09 - de_pc_diff - INFO - set up diff pc data dask array.\n",
      "2023-10-18 16:45:09 - de_pc_diff - INFO - pc dask array shape: (906, 3)\n",
      "2023-10-18 16:45:09 - de_pc_diff - INFO - pc dask array chunksize: (182, 1)\n",
      "2023-10-18 16:45:09 - de_pc_diff - INFO - pc dask array dtype: complex64\n",
      "2023-10-18 16:45:09 - de_pc_diff - INFO - computing graph setted. doing all the computing.\n",
      "2023-10-18 16:45:10 - de_pc_diff - INFO - computing finished.\n",
      "2023-10-18 16:45:10 - de_pc_diff - INFO - dask cluster closed.\n"
     ]
    }
   ],
   "source": [
    "de_pc_diff('pc/idx1.zarr','pc/idx2.zarr','pc/idx.zarr')\n",
    "de_pc_diff('pc/idx1.zarr','pc/idx2.zarr','pc/idx.zarr',pc1='pc/pc1.zarr', pc='pc/pc.zarr')\n",
    "idx_zarr = zarr.open('pc/idx.zarr','r')\n",
    "pc_zarr = zarr.open('pc/pc.zarr','r')\n",
    "np.testing.assert_array_equal(idx_zarr[:],idx)\n",
    "np.testing.assert_array_equal(pc_zarr[:],pc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ac82b4-030c-454e-8193-ebfe8236e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@call_parse\n",
    "@log_args\n",
    "def de_pc_thres_ras(ras, # the raster image used for thresholding\n",
    "                    idx, # output, index of selected pixels\n",
    "                    min_thres=None, # minimum value of `thres_ras` pixels to be selected in the output point cloud\n",
    "                    max_thres=None, # maximum value of `thres_ras` pixels to be selected in the output point cloud\n",
    "                    pc_chunk_size:int=None, # chunk size in output data,optional\n",
    "                    n_pc_chunk:int=None, # number of chunk in output data, optional\n",
    "                    log:str=None, # log file. Default: no log file\n",
    "                   ):\n",
    "    '''generate point cloud index based on threshold of one raster image.\n",
    "    '''\n",
    "    idx_path = idx\n",
    "    logger = get_logger(logfile=log)\n",
    "    ras_zarr = zarr.open(ras, mode='r'); logger.zarr_info(ras,ras_zarr)\n",
    "\n",
    "    ras = ras_zarr[:]; logger.info('loading ras into memory.')\n",
    "    if (min_thres is not None) and (max_thres is not None):\n",
    "        is_pc = (ras >= min_thres)&(ras<= max_thres)\n",
    "        logger.info('select pc based on min_thres and max_thres.')\n",
    "    elif (min_thres is not None) and (max_thres is None):\n",
    "        is_pc = ras >= min_thres\n",
    "        logger.info('select pc based on min_thres.')\n",
    "    elif (min_thres is None) and (max_thres is not None):\n",
    "        is_pc = ras<= max_thres\n",
    "        logger.info('select pc based on max_thres.')\n",
    "    else:\n",
    "        is_pc = np.ones_like(ras,dtype=bool)\n",
    "        logger.info('no input min_thres and max_thres, select all pixels')\n",
    "    idx = np.stack(np.where(is_pc)).astype(np.int32)\n",
    "    n_pc = idx.shape[1]\n",
    "    logger.info(f'number of selected pixels: {n_pc}.')\n",
    "    pc_chunk_size = get_pc_chunk_size_from_n_az_chunk('ras','idx',ras_zarr.shape[0],ras_zarr.chunks[0],n_pc,logger=logger,pc_chunk_size=pc_chunk_size,n_pc_chunk=n_pc_chunk)\n",
    "    idx_zarr = zarr.open(idx_path,'w',dtype=idx.dtype,shape=idx.shape,chunks=(2,pc_chunk_size))\n",
    "    logger.info('writing idx.')\n",
    "    idx_zarr[:] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd58d10-4a59-4a2e-84ad-267ea29d24aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ras = np.random.rand(100,100).astype(np.float32)\n",
    "min_thres = 0.1; max_thres=0.5\n",
    "is_pc = (ras>=min_thres) & (ras<=max_thres)\n",
    "idx = np.stack(np.where(is_pc)).astype(np.int32)\n",
    "ras_zarr = zarr.open('pc/ras.zarr','rw',shape=ras.shape,dtype=ras.dtype,chunks=(10,100))\n",
    "ras_zarr[:] = ras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c82334-d804-4eb9-a0af-2f10f3095ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-18 16:45:10 - de_pc_thres_ras - INFO - fetching args:\n",
      "2023-10-18 16:45:10 - de_pc_thres_ras - INFO - ras = 'pc/ras.zarr'\n",
      "2023-10-18 16:45:10 - de_pc_thres_ras - INFO - idx = 'pc/idx.zarr'\n",
      "2023-10-18 16:45:10 - de_pc_thres_ras - INFO - min_thres = 0.1\n",
      "2023-10-18 16:45:10 - de_pc_thres_ras - INFO - max_thres = 0.5\n",
      "2023-10-18 16:45:10 - de_pc_thres_ras - INFO - pc_chunk_size = None\n",
      "2023-10-18 16:45:10 - de_pc_thres_ras - INFO - n_pc_chunk = None\n",
      "2023-10-18 16:45:10 - de_pc_thres_ras - INFO - log = None\n",
      "2023-10-18 16:45:10 - de_pc_thres_ras - INFO - fetching args done.\n",
      "2023-10-18 16:45:10 - de_pc_thres_ras - INFO - pc/ras.zarr zarray shape: (100, 100)\n",
      "2023-10-18 16:45:10 - de_pc_thres_ras - INFO - pc/ras.zarr zarray chunks: (10, 100)\n",
      "2023-10-18 16:45:10 - de_pc_thres_ras - INFO - pc/ras.zarr zarray dtype: float32\n",
      "2023-10-18 16:45:10 - de_pc_thres_ras - INFO - loading ras into memory.\n",
      "2023-10-18 16:45:10 - de_pc_thres_ras - INFO - select pc based on min_thres and max_thres.\n",
      "2023-10-18 16:45:10 - de_pc_thres_ras - INFO - number of selected pixels: 3995.\n",
      "2023-10-18 16:45:10 - de_pc_thres_ras - INFO - automatically determine pc_chunk_size from n_pc of idx and n_az_chunk of ras\n",
      "2023-10-18 16:45:10 - de_pc_thres_ras - INFO - pc_chunk_size for idx: 400\n",
      "2023-10-18 16:45:10 - de_pc_thres_ras - INFO - writing idx.\n"
     ]
    }
   ],
   "source": [
    "de_pc_thres_ras('pc/ras.zarr','pc/idx.zarr',min_thres,max_thres)\n",
    "idx_zarr = zarr.open('pc/idx.zarr','r')\n",
    "np.testing.assert_array_equal(idx_zarr[:],idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a9b268-9d5b-4073-885d-ad60ebfbbe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@call_parse\n",
    "@log_args\n",
    "def de_pc_thres_pc(idx_in,# the index of input pc data\n",
    "                   pc_in, # the point cloud data used for thresholding\n",
    "                   idx, # output, index of selected pixels\n",
    "                   min_thres=None, # minimum value of `thres_ras` pixels to be selected in the output point cloud\n",
    "                   max_thres=None, # maximum value of `thres_ras` pixels to be selected in the output point cloud\n",
    "                   pc_chunk_size:int=None, # chunk size in output data,optional\n",
    "                   n_pc_chunk:int=None, # number of chunk in output data, optional\n",
    "                   log:str=None, # log file. Default: no log file\n",
    "                   ):\n",
    "    '''generate point cloud index and data based on threshold of one point cloud data.\n",
    "    '''\n",
    "    idx_path = idx\n",
    "    logger = get_logger(logfile=log)\n",
    "    idx_in_zarr = zarr.open(idx_in,mode='r'); logger.zarr_info(idx_in,idx_in_zarr)\n",
    "    pc_in_zarr = zarr.open(pc_in, mode='r'); logger.zarr_info(pc_in,pc_in_zarr)\n",
    "\n",
    "    idx_in = idx_in_zarr[:]; logger.info('loading idx_in into memory.')\n",
    "    pc_in = pc_in_zarr[:]; logger.info('loading pc_in into memory.')\n",
    "\n",
    "    if (min_thres is not None) and (max_thres is not None):\n",
    "        is_pc = (pc_in >= min_thres)&(pc_in <= max_thres)\n",
    "        logger.info('select pc based on min_thres and max_thres.')\n",
    "    elif (min_thres is not None) and (max_thres is None):\n",
    "        is_pc = pc_in >= min_thres\n",
    "        logger.info('select pc based on min_thres.')\n",
    "    elif (min_thres is None) and (max_thres is not None):\n",
    "        is_pc = pc_in <= max_thres\n",
    "        logger.info('select pc based on max_thres.')\n",
    "    else:\n",
    "        is_pc = np.ones_like(pc_in,dtype=bool)\n",
    "        logger.info('no input min_thres and max_thres, select all pixels')\n",
    "\n",
    "    idx = idx_in[:,is_pc]\n",
    "    n_pc = idx.shape[1]\n",
    "    logger.info(f'number of selected pixels: {n_pc}.')\n",
    "    pc_chunk_size = get_pc_chunk_size_from_n_pc_chunk('idx_in','idx',idx_in_zarr.shape[1],idx_in_zarr.chunks[1],n_pc, logger, pc_chunk_size=pc_chunk_size, n_pc_chunk= n_pc_chunk)\n",
    "    idx_zarr = zarr.open(idx_path,'w',dtype=idx.dtype,shape=idx.shape,chunks=(2,pc_chunk_size))\n",
    "    logger.info('writing idx.')\n",
    "    idx_zarr[:] = idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0adbca-48c5-402c-98e3-64b2017d4ec7",
   "metadata": {},
   "source": [
    "Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ea19e0-a5bb-4b1a-ac2e-6ebce272da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_in = np.random.rand(1000).astype(np.float32)\n",
    "idx_in = np.random.choice(np.arange(100*100,dtype=np.int32),size=1000,replace=False)\n",
    "idx_in.sort()\n",
    "idx_in = np.stack(np.unravel_index(idx_in,shape=(100,100))).astype(np.int32)\n",
    "\n",
    "min_thres = 0.1; max_thres=0.5\n",
    "is_pc = (pc_in>=min_thres) & (pc_in<=max_thres)\n",
    "idx = idx_in[:,is_pc]\n",
    "pc_in_zarr = zarr.open('pc/pc_in.zarr','w',shape=pc_in.shape,dtype=pc_in.dtype,chunks=(100,))\n",
    "idx_in_zarr = zarr.open('pc/idx_in.zarr','w',shape=idx_in.shape,dtype=idx_in.dtype,chunks=(2,100))\n",
    "pc_in_zarr[:] = pc_in; idx_in_zarr[:] = idx_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cc0848-2892-40b6-8caf-1e2dfaa05e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-18 16:45:11 - de_pc_thres_pc - INFO - fetching args:\n",
      "2023-10-18 16:45:11 - de_pc_thres_pc - INFO - idx_in = 'pc/idx_in.zarr'\n",
      "2023-10-18 16:45:11 - de_pc_thres_pc - INFO - pc_in = 'pc/pc_in.zarr'\n",
      "2023-10-18 16:45:11 - de_pc_thres_pc - INFO - idx = 'pc/idx.zarr'\n",
      "2023-10-18 16:45:11 - de_pc_thres_pc - INFO - min_thres = 0.1\n",
      "2023-10-18 16:45:11 - de_pc_thres_pc - INFO - max_thres = 0.5\n",
      "2023-10-18 16:45:11 - de_pc_thres_pc - INFO - pc_chunk_size = None\n",
      "2023-10-18 16:45:11 - de_pc_thres_pc - INFO - n_pc_chunk = None\n",
      "2023-10-18 16:45:11 - de_pc_thres_pc - INFO - log = None\n",
      "2023-10-18 16:45:11 - de_pc_thres_pc - INFO - fetching args done.\n",
      "2023-10-18 16:45:11 - de_pc_thres_pc - INFO - pc/idx_in.zarr zarray shape: (2, 1000)\n",
      "2023-10-18 16:45:11 - de_pc_thres_pc - INFO - pc/idx_in.zarr zarray chunks: (2, 100)\n",
      "2023-10-18 16:45:11 - de_pc_thres_pc - INFO - pc/idx_in.zarr zarray dtype: int32\n",
      "2023-10-18 16:45:11 - de_pc_thres_pc - INFO - pc/pc_in.zarr zarray shape: (1000,)\n",
      "2023-10-18 16:45:11 - de_pc_thres_pc - INFO - pc/pc_in.zarr zarray chunks: (100,)\n",
      "2023-10-18 16:45:11 - de_pc_thres_pc - INFO - pc/pc_in.zarr zarray dtype: float32\n",
      "2023-10-18 16:45:11 - de_pc_thres_pc - INFO - loading idx_in into memory.\n",
      "2023-10-18 16:45:11 - de_pc_thres_pc - INFO - loading pc_in into memory.\n",
      "2023-10-18 16:45:11 - de_pc_thres_pc - INFO - select pc based on min_thres and max_thres.\n",
      "2023-10-18 16:45:11 - de_pc_thres_pc - INFO - number of selected pixels: 410.\n",
      "2023-10-18 16:45:11 - de_pc_thres_pc - INFO - automatically determine pc_chunk_size from n_pc of idx and n_pc_chunk of idx_in\n",
      "2023-10-18 16:45:11 - de_pc_thres_pc - INFO - pc_chunk_size for idx: 41\n",
      "2023-10-18 16:45:11 - de_pc_thres_pc - INFO - writing idx.\n"
     ]
    }
   ],
   "source": [
    "de_pc_thres_pc('pc/idx_in.zarr','pc/pc_in.zarr','pc/idx.zarr',min_thres,max_thres)\n",
    "idx_zarr = zarr.open('pc/idx.zarr','r')\n",
    "np.testing.assert_array_equal(idx_zarr[:],idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7d0216-326e-43f7-9b8f-0268497f43e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@call_parse\n",
    "@log_args\n",
    "def de_pc_select_data(idx_in:str, # index of the input data\n",
    "                      idx:str, # index of the output data\n",
    "                      pc_in:str|list, # path (in string) or list of path for the input point cloud data\n",
    "                      pc:str|list, # path (in string) or list of path for the output point cloud data\n",
    "                      pc_chunk_size:int=None, # chunk size in output data,optional\n",
    "                      n_pc_chunk:int=None, # number of chunk in output data, optional\n",
    "                      log:str=None, # log file. Default: no log file\n",
    "                     ):\n",
    "    '''generate point cloud data based on its index and one point cloud data.\n",
    "    The index of generated point cloud data must in the index of the old one.\n",
    "    '''\n",
    "    idx_in_path = idx_in; idx_path = idx\n",
    "    logger = get_logger(logfile=log)\n",
    "    idx_in_zarr = zarr.open(idx_in_path,mode='r'); logger.zarr_info(idx_in_path,idx_in_zarr)\n",
    "    idx_zarr = zarr.open(idx_path,mode='r'); logger.zarr_info(idx_path,idx_zarr)\n",
    "    logger.info('loading idx_in and idx into memory.')\n",
    "    idx_in = idx_in_zarr[:]; idx = idx_zarr[:]\n",
    "    iidx_in, iidx = pc_intersect(idx_in,idx)[1:]\n",
    "    np.testing.assert_array_equal(iidx,np.arange(iidx.shape[0]),err_msg='idx have points that are not covered by idx_in.')\n",
    "    n_pc = iidx_in.shape[0]\n",
    "    pc_chunk_size = get_pc_chunk_size_from_pc_chunk_size('idx','pc',idx_zarr.chunks[1],n_pc,logger,pc_chunk_size=pc_chunk_size,n_pc_chunk=n_pc_chunk)\n",
    "\n",
    "    if isinstance(pc_in,str):\n",
    "        assert isinstance(pc,str)\n",
    "        pc_in_list = [pc_in]; pc_list = [pc]\n",
    "    else:\n",
    "        assert isinstance(pc_in,list); assert isinstance(pc,list)\n",
    "        pc_in_list = pc_in; pc_list = pc\n",
    "\n",
    "    logger.info('starting dask local cluster.')\n",
    "    cluster = LocalCluster(); client = Client(cluster)\n",
    "    logger.info('dask local cluster started.')\n",
    "    \n",
    "    _pc_list = ()\n",
    "    for pc_in_path, pc_path in zip(pc_in_list,pc_list):\n",
    "        pc_in_zarr = zarr.open(pc_in_path,'r'); logger.zarr_info(pc_in_path, pc_in_zarr)\n",
    "        pc_in = da.from_zarr(pc_in_path); logger.darr_info('pc_in', pc_in)\n",
    "        logger.info('set up selected pc data dask array.')\n",
    "        pc = da.empty((n_pc,*pc_in.shape[1:]),chunks = (pc_chunk_size,*pc_in.chunks[1:]), dtype=pc_in.dtype)\n",
    "        logger.darr_info('pc',pc)\n",
    "        pc[:] = pc_in[iidx_in]\n",
    "        _pc = pc.to_zarr(pc_path, overwrite=True,compute=False)\n",
    "        _pc_list += (_pc,)\n",
    "\n",
    "    logger.info('computing graph setted. doing all the computing.')\n",
    "    da.compute(*_pc_list)\n",
    "\n",
    "    logger.info('computing finished.')\n",
    "    cluster.close()\n",
    "    logger.info('dask cluster closed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62fc920-012d-429d-b385-36b0623bacde",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_in = np.random.rand(1000).astype(np.float32)\n",
    "idx_in = np.random.choice(np.arange(100*100,dtype=np.int32),size=1000,replace=False)\n",
    "idx_in.sort()\n",
    "idx_in = np.stack(np.unravel_index(idx_in,shape=(100,100))).astype(np.int32)\n",
    "\n",
    "iidx_in = np.random.choice(np.arange(1000,dtype=np.int64),size=500,replace=False); iidx_in.sort()\n",
    "idx = idx_in[:,iidx_in]\n",
    "pc = pc_in[iidx_in]\n",
    "\n",
    "pc_in_zarr = zarr.open('pc/pc_in.zarr','w',shape=pc_in.shape,dtype=pc_in.dtype,chunks=(100,))\n",
    "idx_in_zarr = zarr.open('pc/idx_in.zarr','w',shape=idx_in.shape,dtype=idx_in.dtype,chunks=(2,100))\n",
    "idx_zarr = zarr.open('pc/idx.zarr','w',shape=idx.shape,dtype=idx.dtype,chunks=(2,100))\n",
    "pc_in_zarr[:] = pc_in; idx_in_zarr[:] = idx_in; idx_zarr[:] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c08eb9c-851b-4084-95d7-2141f00b02f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-18 16:45:11 - de_pc_select_data - INFO - fetching args:\n",
      "2023-10-18 16:45:11 - de_pc_select_data - INFO - idx_in = 'pc/idx_in.zarr'\n",
      "2023-10-18 16:45:11 - de_pc_select_data - INFO - idx = 'pc/idx.zarr'\n",
      "2023-10-18 16:45:11 - de_pc_select_data - INFO - pc_in = 'pc/pc_in.zarr'\n",
      "2023-10-18 16:45:11 - de_pc_select_data - INFO - pc = 'pc/pc.zarr'\n",
      "2023-10-18 16:45:11 - de_pc_select_data - INFO - pc_chunk_size = None\n",
      "2023-10-18 16:45:11 - de_pc_select_data - INFO - n_pc_chunk = None\n",
      "2023-10-18 16:45:11 - de_pc_select_data - INFO - log = None\n",
      "2023-10-18 16:45:11 - de_pc_select_data - INFO - fetching args done.\n",
      "2023-10-18 16:45:11 - de_pc_select_data - INFO - pc/idx_in.zarr zarray shape: (2, 1000)\n",
      "2023-10-18 16:45:11 - de_pc_select_data - INFO - pc/idx_in.zarr zarray chunks: (2, 100)\n",
      "2023-10-18 16:45:11 - de_pc_select_data - INFO - pc/idx_in.zarr zarray dtype: int32\n",
      "2023-10-18 16:45:11 - de_pc_select_data - INFO - pc/idx.zarr zarray shape: (2, 500)\n",
      "2023-10-18 16:45:11 - de_pc_select_data - INFO - pc/idx.zarr zarray chunks: (2, 100)\n",
      "2023-10-18 16:45:11 - de_pc_select_data - INFO - pc/idx.zarr zarray dtype: int32\n",
      "2023-10-18 16:45:11 - de_pc_select_data - INFO - loading idx_in and idx into memory.\n",
      "2023-10-18 16:45:11 - de_pc_select_data - INFO - automatically determine pc_chunk_size from pc_chunk_size of idx.\n",
      "2023-10-18 16:45:11 - de_pc_select_data - INFO - pc_chunk_size for pc: 100\n",
      "2023-10-18 16:45:11 - de_pc_select_data - INFO - starting dask local cluster.\n",
      "2023-10-18 16:45:13 - de_pc_select_data - INFO - dask local cluster started.\n",
      "2023-10-18 16:45:13 - de_pc_select_data - INFO - pc/pc_in.zarr zarray shape: (1000,)\n",
      "2023-10-18 16:45:13 - de_pc_select_data - INFO - pc/pc_in.zarr zarray chunks: (100,)\n",
      "2023-10-18 16:45:13 - de_pc_select_data - INFO - pc/pc_in.zarr zarray dtype: float32\n",
      "2023-10-18 16:45:13 - de_pc_select_data - INFO - pc_in dask array shape: (1000,)\n",
      "2023-10-18 16:45:13 - de_pc_select_data - INFO - pc_in dask array chunksize: (100,)\n",
      "2023-10-18 16:45:13 - de_pc_select_data - INFO - pc_in dask array dtype: float32\n",
      "2023-10-18 16:45:13 - de_pc_select_data - INFO - set up selected pc data dask array.\n",
      "2023-10-18 16:45:13 - de_pc_select_data - INFO - pc dask array shape: (500,)\n",
      "2023-10-18 16:45:13 - de_pc_select_data - INFO - pc dask array chunksize: (100,)\n",
      "2023-10-18 16:45:13 - de_pc_select_data - INFO - pc dask array dtype: float32\n",
      "2023-10-18 16:45:13 - de_pc_select_data - INFO - computing graph setted. doing all the computing.\n",
      "2023-10-18 16:45:15 - de_pc_select_data - INFO - computing finished.\n",
      "2023-10-18 16:45:15 - de_pc_select_data - INFO - dask cluster closed.\n"
     ]
    }
   ],
   "source": [
    "de_pc_select_data('pc/idx_in.zarr','pc/idx.zarr','pc/pc_in.zarr','pc/pc.zarr')\n",
    "pc_zarr = zarr.open('pc/pc.zarr','r')\n",
    "np.testing.assert_array_equal(pc_zarr[:],pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50eda76-1cf8-4fb7-9f5a-df8af874e97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a80c30-b67d-495a-b5f0-ddee13370492",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:work]",
   "language": "python",
   "name": "conda-env-work-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
