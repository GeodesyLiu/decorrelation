{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "238849fa-11ec-4de5-99e4-c4eb367f7913",
   "metadata": {},
   "source": [
    "# pc\n",
    "\n",
    "> Point Cloud data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eed06b-0dd0-4177-8a92-8757961eecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp cli/pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967c14e4-d207-455f-829c-4c3a005838ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b686af00-c16a-401d-baf8-2847eda5416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import math\n",
    "import zarr\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import dask\n",
    "from dask import array as da\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "from decorrelation.pc import pc2ras, pc_union, pc_intersect, pc_diff\n",
    "from decorrelation.cli.utils.logging import get_logger, log_args\n",
    "\n",
    "from fastcore.script import call_parse, Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2d5d0e-48cf-450b-8eb8-91a31cae04a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@log_args\n",
    "def de_ras2pc(idx:str, # point cloud index\n",
    "              ras:str|list, # path (in string) or list of path for raster data\n",
    "              pc:str|list, # output, path (in string) or list of path for point cloud data\n",
    "              pc_chunk_size:int=None, # output point chunk size, same as input idx by default\n",
    "              hd_chunk_size:tuple|list=None, # output high dimension chunk size, tuple or list of tuple, same as input raster data by default\n",
    "              log:str=None, # log file. Default: no log file\n",
    "):\n",
    "    '''Convert raster data to point cloud data'''\n",
    "    logger = get_logger(logfile=log)\n",
    "\n",
    "    idx_zarr = zarr.open(idx,mode='r')\n",
    "    logger.zarr_info(idx,idx_zarr)\n",
    "    assert idx_zarr.ndim == 2, \"idx dimentation is not 2.\"\n",
    "    if pc_chunk_size is None:\n",
    "        pc_chunk_size = idx_zarr.chunks[1]\n",
    "        logger.info('no input pc_chunk_size, use pc_chunk_size as input idx')\n",
    "    logger.info(f'pc_chunk_size: {pc_chunk_size}')\n",
    "\n",
    "    logger.info('loading idx into memory.')\n",
    "    idx = zarr.open(idx,mode='r')[:]\n",
    "    n_pc = idx.shape[1]\n",
    "\n",
    "    if isinstance(ras,str):\n",
    "        assert isinstance(pc,str)\n",
    "        ras_list = [ras]; pc_list = [pc]\n",
    "        if hd_chunk_size is not None:\n",
    "            assert isinstance(hd_chunk_size,tuple)\n",
    "            hd_chunk_size_list = [hd_chunk_size]\n",
    "        else:\n",
    "            hd_chunk_size_list = [None]\n",
    "    else:\n",
    "        assert isinstance(ras,list); assert isinstance(pc,list)\n",
    "        ras_list = ras; pc_list = pc\n",
    "        n_data = len(ras_list)\n",
    "        if hd_chunk_size is not None:\n",
    "            assert isinstance(hd_chunk_size,list)\n",
    "            hd_chunk_size_list = hd_chunk_size\n",
    "        else:\n",
    "            hd_chunk_size_list = [None]*n_data\n",
    "\n",
    "    logger.info('starting dask local cluster.')\n",
    "    cluster = LocalCluster()\n",
    "    client = Client(cluster)\n",
    "    logger.info('dask local cluster started.')\n",
    "\n",
    "    _pc_list = ()\n",
    "    for ras_path, pc_path, hd_chunk_size in zip(ras_list,pc_list,hd_chunk_size_list):\n",
    "        logger.info(f'start to slice on {ras_path}')\n",
    "        ras_zarr = zarr.open(ras_path,'r')\n",
    "        logger.zarr_info(ras_path, ras_zarr)\n",
    "        if hd_chunk_size is None:\n",
    "            logger.info(f'hd_chunk_size not setted. Use the one from {ras_path}.')\n",
    "            hd_chunk_size = ras_zarr.chunks[2:]\n",
    "        logger.info(f'hd_chunk_size: {hd_chunk_size}.')\n",
    "\n",
    "        ras = da.from_zarr(ras_path,chunks=(*ras_zarr.chunks[:2],*hd_chunk_size))\n",
    "        logger.darr_info('ras',ras)\n",
    "\n",
    "        with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
    "            pc = ras.reshape(-1,*ras.shape[2:])[np.ravel_multi_index((idx[0],idx[1]),dims=ras.shape[:2])]\n",
    "        \n",
    "        logger.darr_info('pc', pc)\n",
    "        logger.info('rechunk pc data:')\n",
    "        pc = pc.rechunk((pc_chunk_size,*pc.chunksize[1:]))\n",
    "        logger.darr_info('pc', pc)\n",
    "        _pc = pc.to_zarr(pc_path,overwrite=True,compute=False)\n",
    "        logger.info(f'saving to {pc_path}.')\n",
    "        _pc_list += (_pc,)\n",
    "    \n",
    "    logger.info('computing graph setted. doing all the computing.')\n",
    "    da.compute(*_pc_list)\n",
    "\n",
    "    logger.info('computing finished.')\n",
    "    cluster.close()\n",
    "    logger.info('dask cluster closed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad08c7-bb6c-492a-acd2-44ec6e75fb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@call_parse\n",
    "def console_de_ras2pc(idx:str, # point cloud index\n",
    "                      ras:Param(type=str,required=True,nargs='+',help='one or more path for raster data')=None,\n",
    "                      pc:Param(type=str,required=True,nargs='+',help='output, one or more path for point cloud data')=None,\n",
    "                      pc_chunk_size:int=None, # output point chunk size, same as input idx by default\n",
    "                      hd_chunk_size:Param(type=str,nargs='+',help='''output high dimension chunk size,\n",
    "                      each size should be wrapped in quotation marks and size in each dimension are seperated with \",\",\n",
    "                      same as input raster data by default''')=None,\n",
    "                      log:str=None, # log file. Default: no log file\n",
    "):\n",
    "    '''Convert raster data to point cloud data'''\n",
    "    if hd_chunk_size is not None:\n",
    "        hd_chunk_size_ = []\n",
    "        for size in hd_chunk_size:\n",
    "            if len(size) == 0:\n",
    "                size = ()\n",
    "            else:\n",
    "                size = size.split(',')\n",
    "                size = tuple([int(i) for i in size])\n",
    "            hd_chunk_size_.append(size)\n",
    "    else:\n",
    "        hd_chunk_size_ = None\n",
    "\n",
    "    if len(ras)==1:\n",
    "        ras = ras[0]\n",
    "        pc = pc[0]\n",
    "        if hd_chunk_size_ is not None:\n",
    "            hd_chunk_size_ = hd_chunk_size_[0]\n",
    "\n",
    "    de_ras2pc(idx,ras,pc,pc_chunk_size,hd_chunk_size_,log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec30940a-4ff1-4f22-a282-da51f8fad493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: de_ras2pc [-h] --ras RAS [RAS ...] --pc PC [PC ...]\n",
      "                 [--pc_chunk_size PC_CHUNK_SIZE]\n",
      "                 [--hd_chunk_size HD_CHUNK_SIZE [HD_CHUNK_SIZE ...]] [--log LOG]\n",
      "                 idx\n",
      "\n",
      "Convert raster data to point cloud data\n",
      "\n",
      "positional arguments:\n",
      "  idx                                   point cloud index\n",
      "\n",
      "options:\n",
      "  -h, --help                            show this help message and exit\n",
      "  --ras RAS [RAS ...]                   one or more path for raster data\n",
      "  --pc PC [PC ...]                      output, one or more path for point cloud\n",
      "                                        data\n",
      "  --pc_chunk_size PC_CHUNK_SIZE         output point chunk size, same as input\n",
      "                                        idx by default\n",
      "  --hd_chunk_size HD_CHUNK_SIZE [HD_CHUNK_SIZE ...]\n",
      "                                        output high dimension chunk size, each\n",
      "                                        size should be wrapped in quotation\n",
      "                                        marks and size in each dimension are\n",
      "                                        seperated with \",\", same as input raster\n",
      "                                        data by default\n",
      "  --log LOG                             log file. Default: no log file\n"
     ]
    }
   ],
   "source": [
    "!de_ras2pc -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae4f91c-2870-40d7-ab4f-2378ff6d3e95",
   "metadata": {},
   "source": [
    "Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8042246-2acf-44ad-ab50-c2ad2b326fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ras_data1 = np.random.rand(100,100).astype(np.float32)\n",
    "ras_data2 = np.random.rand(100,100,3).astype(np.float32)+1j*np.random.rand(100,100,3).astype(np.float32)\n",
    "\n",
    "idx = np.random.choice(np.arange(100*100,dtype=np.int32),size=1000,replace=False)\n",
    "idx.sort()\n",
    "idx = np.stack(np.unravel_index(idx,shape=(100,100))).astype(np.int32)\n",
    "\n",
    "pc_data1 = ras_data1[idx[0],idx[1]]\n",
    "pc_data2 = ras_data2[idx[0],idx[1]]\n",
    "\n",
    "idx_zarr = zarr.open('pc/idx.zarr','w',shape=idx.shape,dtype=idx.dtype,chunks=(2,200))\n",
    "ras_zarr1 = zarr.open('pc/ras1.zarr','w',shape=ras_data1.shape,dtype=ras_data1.dtype,chunks=(20,100))\n",
    "ras_zarr2 = zarr.open('pc/ras2.zarr','w',shape=ras_data2.shape,dtype=ras_data2.dtype,chunks=(20,100,1))\n",
    "idx_zarr[:] = idx\n",
    "ras_zarr1[:] = ras_data1\n",
    "ras_zarr2[:] = ras_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5b5824-8365-4107-8088-76aad7304f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-14 22:42:27 - de_ras2pc - INFO - fetching args:\n",
      "2023-10-14 22:42:27 - de_ras2pc - INFO - idx = 'pc/idx.zarr'\n",
      "2023-10-14 22:42:27 - de_ras2pc - INFO - ras = 'pc/ras1.zarr'\n",
      "2023-10-14 22:42:27 - de_ras2pc - INFO - pc = 'pc/pc1.zarr'\n",
      "2023-10-14 22:42:27 - de_ras2pc - INFO - pc_chunk_size = None\n",
      "2023-10-14 22:42:27 - de_ras2pc - INFO - hd_chunk_size = None\n",
      "2023-10-14 22:42:27 - de_ras2pc - INFO - log = None\n",
      "2023-10-14 22:42:27 - de_ras2pc - INFO - fetching args done.\n",
      "2023-10-14 22:42:27 - de_ras2pc - INFO - pc/idx.zarr zarray shape: (2, 1000)\n",
      "2023-10-14 22:42:27 - de_ras2pc - INFO - pc/idx.zarr zarray chunks: (2, 200)\n",
      "2023-10-14 22:42:27 - de_ras2pc - INFO - pc/idx.zarr zarray dtype: int32\n",
      "2023-10-14 22:42:27 - de_ras2pc - INFO - no input pc_chunk_size, use pc_chunk_size as input idx\n",
      "2023-10-14 22:42:27 - de_ras2pc - INFO - pc_chunk_size: 200\n",
      "2023-10-14 22:42:27 - de_ras2pc - INFO - loading idx into memory.\n",
      "2023-10-14 22:42:27 - de_ras2pc - INFO - starting dask local cluster.\n",
      "2023-10-14 22:42:29 - de_ras2pc - INFO - dask local cluster started.\n",
      "2023-10-14 22:42:29 - de_ras2pc - INFO - start to slice on pc/ras1.zarr\n",
      "2023-10-14 22:42:29 - de_ras2pc - INFO - pc/ras1.zarr zarray shape: (100, 100)\n",
      "2023-10-14 22:42:29 - de_ras2pc - INFO - pc/ras1.zarr zarray chunks: (20, 100)\n",
      "2023-10-14 22:42:29 - de_ras2pc - INFO - pc/ras1.zarr zarray dtype: float32\n",
      "2023-10-14 22:42:29 - de_ras2pc - INFO - hd_chunk_size not setted. Use the one from pc/ras1.zarr.\n",
      "2023-10-14 22:42:29 - de_ras2pc - INFO - hd_chunk_size: ().\n",
      "2023-10-14 22:42:29 - de_ras2pc - INFO - ras dask array shape: (100, 100)\n",
      "2023-10-14 22:42:29 - de_ras2pc - INFO - ras dask array chunksize: (20, 100)\n",
      "2023-10-14 22:42:29 - de_ras2pc - INFO - ras dask array dtype: float32\n",
      "2023-10-14 22:42:29 - de_ras2pc - INFO - pc dask array shape: (1000,)\n",
      "2023-10-14 22:42:29 - de_ras2pc - INFO - pc dask array chunksize: (213,)\n",
      "2023-10-14 22:42:29 - de_ras2pc - INFO - pc dask array dtype: float32\n",
      "2023-10-14 22:42:29 - de_ras2pc - INFO - rechunk pc data:\n",
      "2023-10-14 22:42:29 - de_ras2pc - INFO - pc dask array shape: (1000,)\n",
      "2023-10-14 22:42:29 - de_ras2pc - INFO - pc dask array chunksize: (200,)\n",
      "2023-10-14 22:42:29 - de_ras2pc - INFO - pc dask array dtype: float32\n",
      "2023-10-14 22:42:29 - de_ras2pc - INFO - saving to pc/pc1.zarr.\n",
      "2023-10-14 22:42:29 - de_ras2pc - INFO - computing graph setted. doing all the computing.\n",
      "2023-10-14 22:42:29 - de_ras2pc - INFO - computing finished.\n",
      "2023-10-14 22:42:30 - de_ras2pc - INFO - dask cluster closed.\n",
      "2023-10-14 22:42:31 - de_ras2pc - INFO - fetching args:\n",
      "2023-10-14 22:42:31 - de_ras2pc - INFO - idx = 'pc/idx.zarr'\n",
      "2023-10-14 22:42:31 - de_ras2pc - INFO - ras = 'pc/ras2.zarr'\n",
      "2023-10-14 22:42:31 - de_ras2pc - INFO - pc = 'pc/pc2.zarr'\n",
      "2023-10-14 22:42:31 - de_ras2pc - INFO - pc_chunk_size = None\n",
      "2023-10-14 22:42:31 - de_ras2pc - INFO - hd_chunk_size = (1,)\n",
      "2023-10-14 22:42:31 - de_ras2pc - INFO - log = None\n",
      "2023-10-14 22:42:31 - de_ras2pc - INFO - fetching args done.\n",
      "2023-10-14 22:42:31 - de_ras2pc - INFO - pc/idx.zarr zarray shape: (2, 1000)\n",
      "2023-10-14 22:42:31 - de_ras2pc - INFO - pc/idx.zarr zarray chunks: (2, 200)\n",
      "2023-10-14 22:42:31 - de_ras2pc - INFO - pc/idx.zarr zarray dtype: int32\n",
      "2023-10-14 22:42:31 - de_ras2pc - INFO - no input pc_chunk_size, use pc_chunk_size as input idx\n",
      "2023-10-14 22:42:31 - de_ras2pc - INFO - pc_chunk_size: 200\n",
      "2023-10-14 22:42:31 - de_ras2pc - INFO - loading idx into memory.\n",
      "2023-10-14 22:42:31 - de_ras2pc - INFO - starting dask local cluster.\n",
      "2023-10-14 22:42:34 - de_ras2pc - INFO - dask local cluster started.\n",
      "2023-10-14 22:42:34 - de_ras2pc - INFO - start to slice on pc/ras2.zarr\n",
      "2023-10-14 22:42:34 - de_ras2pc - INFO - pc/ras2.zarr zarray shape: (100, 100, 3)\n",
      "2023-10-14 22:42:34 - de_ras2pc - INFO - pc/ras2.zarr zarray chunks: (20, 100, 1)\n",
      "2023-10-14 22:42:34 - de_ras2pc - INFO - pc/ras2.zarr zarray dtype: complex64\n",
      "2023-10-14 22:42:34 - de_ras2pc - INFO - hd_chunk_size: (1,).\n",
      "2023-10-14 22:42:34 - de_ras2pc - INFO - ras dask array shape: (100, 100, 3)\n",
      "2023-10-14 22:42:34 - de_ras2pc - INFO - ras dask array chunksize: (20, 100, 1)\n",
      "2023-10-14 22:42:34 - de_ras2pc - INFO - ras dask array dtype: complex64\n",
      "2023-10-14 22:42:34 - de_ras2pc - INFO - pc dask array shape: (1000, 3)\n",
      "2023-10-14 22:42:34 - de_ras2pc - INFO - pc dask array chunksize: (213, 1)\n",
      "2023-10-14 22:42:34 - de_ras2pc - INFO - pc dask array dtype: complex64\n",
      "2023-10-14 22:42:34 - de_ras2pc - INFO - rechunk pc data:\n",
      "2023-10-14 22:42:34 - de_ras2pc - INFO - pc dask array shape: (1000, 3)\n",
      "2023-10-14 22:42:34 - de_ras2pc - INFO - pc dask array chunksize: (200, 1)\n",
      "2023-10-14 22:42:34 - de_ras2pc - INFO - pc dask array dtype: complex64\n",
      "2023-10-14 22:42:34 - de_ras2pc - INFO - saving to pc/pc2.zarr.\n",
      "2023-10-14 22:42:34 - de_ras2pc - INFO - computing graph setted. doing all the computing.\n",
      "2023-10-14 22:42:35 - de_ras2pc - INFO - computing finished.\n",
      "2023-10-14 22:42:35 - de_ras2pc - INFO - dask cluster closed.\n",
      "2023-10-14 22:42:36 - de_ras2pc - INFO - fetching args:\n",
      "2023-10-14 22:42:36 - de_ras2pc - INFO - idx = 'pc/idx.zarr'\n",
      "2023-10-14 22:42:36 - de_ras2pc - INFO - ras = ['pc/ras1.zarr', 'pc/ras2.zarr']\n",
      "2023-10-14 22:42:36 - de_ras2pc - INFO - pc = ['pc/pc1.zarr', 'pc/pc2.zarr']\n",
      "2023-10-14 22:42:36 - de_ras2pc - INFO - pc_chunk_size = None\n",
      "2023-10-14 22:42:36 - de_ras2pc - INFO - hd_chunk_size = [(), (1,)]\n",
      "2023-10-14 22:42:36 - de_ras2pc - INFO - log = None\n",
      "2023-10-14 22:42:36 - de_ras2pc - INFO - fetching args done.\n",
      "2023-10-14 22:42:36 - de_ras2pc - INFO - pc/idx.zarr zarray shape: (2, 1000)\n",
      "2023-10-14 22:42:36 - de_ras2pc - INFO - pc/idx.zarr zarray chunks: (2, 200)\n",
      "2023-10-14 22:42:36 - de_ras2pc - INFO - pc/idx.zarr zarray dtype: int32\n",
      "2023-10-14 22:42:36 - de_ras2pc - INFO - no input pc_chunk_size, use pc_chunk_size as input idx\n",
      "2023-10-14 22:42:36 - de_ras2pc - INFO - pc_chunk_size: 200\n",
      "2023-10-14 22:42:36 - de_ras2pc - INFO - loading idx into memory.\n",
      "2023-10-14 22:42:36 - de_ras2pc - INFO - starting dask local cluster.\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - dask local cluster started.\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - start to slice on pc/ras1.zarr\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - pc/ras1.zarr zarray shape: (100, 100)\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - pc/ras1.zarr zarray chunks: (20, 100)\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - pc/ras1.zarr zarray dtype: float32\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - hd_chunk_size: ().\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - ras dask array shape: (100, 100)\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - ras dask array chunksize: (20, 100)\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - ras dask array dtype: float32\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - pc dask array shape: (1000,)\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - pc dask array chunksize: (213,)\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - pc dask array dtype: float32\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - rechunk pc data:\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - pc dask array shape: (1000,)\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - pc dask array chunksize: (200,)\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - pc dask array dtype: float32\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - saving to pc/pc1.zarr.\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - start to slice on pc/ras2.zarr\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - pc/ras2.zarr zarray shape: (100, 100, 3)\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - pc/ras2.zarr zarray chunks: (20, 100, 1)\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - pc/ras2.zarr zarray dtype: complex64\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - hd_chunk_size: (1,).\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - ras dask array shape: (100, 100, 3)\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - ras dask array chunksize: (20, 100, 1)\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - ras dask array dtype: complex64\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - pc dask array shape: (1000, 3)\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - pc dask array chunksize: (213, 1)\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - pc dask array dtype: complex64\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - rechunk pc data:\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - pc dask array shape: (1000, 3)\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - pc dask array chunksize: (200, 1)\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - pc dask array dtype: complex64\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - saving to pc/pc2.zarr.\n",
      "2023-10-14 22:42:38 - de_ras2pc - INFO - computing graph setted. doing all the computing.\n",
      "2023-10-14 22:42:39 - de_ras2pc - INFO - computing finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 22:42:39,280 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/core.py\", line 1427, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/comm/core.py\", line 329, in connect\n",
      "    handshake = await wait_for(comm.read(), time_left())\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/utils.py\", line 1849, in wait_for\n",
      "    return await asyncio.wait_for(fut, timeout)\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/asyncio/tasks.py\", line 432, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/worker.py\", line 1244, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/utils_comm.py\", line 434, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/utils_comm.py\", line 413, in retry\n",
      "    return await coro()\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/core.py\", line 1262, in send_recv_from_rpc\n",
      "    comm = await self.pool.connect(self.addr)\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/core.py\", line 1506, in connect\n",
      "    return await connect_attempt\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/core.py\", line 1450, in _connect\n",
      "    raise CommClosedError(reason)\n",
      "distributed.comm.core.CommClosedError: ConnectionPool closing.\n",
      "2023-10-14 22:42:39,286 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/core.py\", line 1427, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/comm/core.py\", line 329, in connect\n",
      "    handshake = await wait_for(comm.read(), time_left())\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/utils.py\", line 1849, in wait_for\n",
      "    return await asyncio.wait_for(fut, timeout)\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/asyncio/tasks.py\", line 432, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/worker.py\", line 1244, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/utils_comm.py\", line 434, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/utils_comm.py\", line 413, in retry\n",
      "    return await coro()\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/core.py\", line 1262, in send_recv_from_rpc\n",
      "    comm = await self.pool.connect(self.addr)\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/core.py\", line 1506, in connect\n",
      "    return await connect_attempt\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/core.py\", line 1450, in _connect\n",
      "    raise CommClosedError(reason)\n",
      "distributed.comm.core.CommClosedError: ConnectionPool closing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-14 22:42:39 - de_ras2pc - INFO - dask cluster closed.\n",
      "2023-10-14 22:42:40 - de_ras2pc - INFO - fetching args:\n",
      "2023-10-14 22:42:40 - de_ras2pc - INFO - idx = 'pc/idx.zarr'\n",
      "2023-10-14 22:42:40 - de_ras2pc - INFO - ras = ['pc/ras1.zarr', 'pc/ras2.zarr']\n",
      "2023-10-14 22:42:40 - de_ras2pc - INFO - pc = ['pc/pc1.zarr', 'pc/pc2.zarr']\n",
      "2023-10-14 22:42:40 - de_ras2pc - INFO - pc_chunk_size = None\n",
      "2023-10-14 22:42:40 - de_ras2pc - INFO - hd_chunk_size = [(), (1,)]\n",
      "2023-10-14 22:42:40 - de_ras2pc - INFO - log = None\n",
      "2023-10-14 22:42:40 - de_ras2pc - INFO - fetching args done.\n",
      "2023-10-14 22:42:40 - de_ras2pc - INFO - pc/idx.zarr zarray shape: (2, 1000)\n",
      "2023-10-14 22:42:40 - de_ras2pc - INFO - pc/idx.zarr zarray chunks: (2, 200)\n",
      "2023-10-14 22:42:40 - de_ras2pc - INFO - pc/idx.zarr zarray dtype: int32\n",
      "2023-10-14 22:42:40 - de_ras2pc - INFO - no input pc_chunk_size, use pc_chunk_size as input idx\n",
      "2023-10-14 22:42:40 - de_ras2pc - INFO - pc_chunk_size: 200\n",
      "2023-10-14 22:42:40 - de_ras2pc - INFO - loading idx into memory.\n",
      "2023-10-14 22:42:40 - de_ras2pc - INFO - starting dask local cluster.\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - dask local cluster started.\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - start to slice on pc/ras1.zarr\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - pc/ras1.zarr zarray shape: (100, 100)\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - pc/ras1.zarr zarray chunks: (20, 100)\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - pc/ras1.zarr zarray dtype: float32\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - hd_chunk_size: ().\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - ras dask array shape: (100, 100)\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - ras dask array chunksize: (20, 100)\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - ras dask array dtype: float32\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - pc dask array shape: (1000,)\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - pc dask array chunksize: (213,)\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - pc dask array dtype: float32\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - rechunk pc data:\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - pc dask array shape: (1000,)\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - pc dask array chunksize: (200,)\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - pc dask array dtype: float32\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - saving to pc/pc1.zarr.\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - start to slice on pc/ras2.zarr\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - pc/ras2.zarr zarray shape: (100, 100, 3)\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - pc/ras2.zarr zarray chunks: (20, 100, 1)\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - pc/ras2.zarr zarray dtype: complex64\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - hd_chunk_size: (1,).\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - ras dask array shape: (100, 100, 3)\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - ras dask array chunksize: (20, 100, 1)\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - ras dask array dtype: complex64\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - pc dask array shape: (1000, 3)\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - pc dask array chunksize: (213, 1)\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - pc dask array dtype: complex64\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - rechunk pc data:\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - pc dask array shape: (1000, 3)\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - pc dask array chunksize: (200, 1)\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - pc dask array dtype: complex64\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - saving to pc/pc2.zarr.\n",
      "2023-10-14 22:42:43 - de_ras2pc - INFO - computing graph setted. doing all the computing.\n",
      "2023-10-14 22:42:45 - de_ras2pc - INFO - computing finished.\n",
      "2023-10-14 22:42:45 - de_ras2pc - INFO - dask cluster closed.\n"
     ]
    }
   ],
   "source": [
    "de_ras2pc('pc/idx.zarr','pc/ras1.zarr','pc/pc1.zarr')\n",
    "pc_zarr1 = zarr.open('pc/pc1.zarr','r')\n",
    "np.testing.assert_array_equal(pc_data1,pc_zarr1[:])\n",
    "\n",
    "!de_ras2pc pc/idx.zarr --ras pc/ras2.zarr --pc pc/pc2.zarr --hd_chunk_size '1'\n",
    "pc_zarr2 = zarr.open('pc/pc2.zarr','r')\n",
    "np.testing.assert_array_equal(pc_data2,pc_zarr2[:])\n",
    "\n",
    "de_ras2pc('pc/idx.zarr',ras=['pc/ras1.zarr','pc/ras2.zarr'],pc=['pc/pc1.zarr','pc/pc2.zarr'],hd_chunk_size=[(),(1,)])\n",
    "pc_zarr1 = zarr.open('pc/pc1.zarr','r')\n",
    "pc_zarr2 = zarr.open('pc/pc2.zarr','r')\n",
    "np.testing.assert_array_equal(pc_data1,pc_zarr1[:])\n",
    "np.testing.assert_array_equal(pc_data2,pc_zarr2[:])\n",
    "\n",
    "!de_ras2pc pc/idx.zarr --ras pc/ras1.zarr pc/ras2.zarr --pc pc/pc1.zarr pc/pc2.zarr --hd_chunk_size '' '1'\n",
    "pc_zarr1 = zarr.open('pc/pc1.zarr','r')\n",
    "pc_zarr2 = zarr.open('pc/pc2.zarr','r')\n",
    "np.testing.assert_array_equal(pc_data1,pc_zarr1[:])\n",
    "np.testing.assert_array_equal(pc_data2,pc_zarr2[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbaeef3-786c-49d6-9e6b-d2617383f511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@log_args\n",
    "def de_pc2ras(idx:str, # point cloud index\n",
    "              pc:str|list, # path (in string) or list of path for point cloud data\n",
    "              ras:str|list, # output, path (in string) or list of path for raster data\n",
    "              shape:tuple, # shape of one image (nlines,width)\n",
    "              # output azimuth chunk size, \n",
    "              # automatically set az_chunk_size to make n_az_chunk equals to n_pc_chunk by default\n",
    "              az_chunk_size:int=None,\n",
    "              log:str=None, # log file. Default: no log file\n",
    "):\n",
    "    '''Convert point cloud data to raster data, filled with nan'''\n",
    "    logger = get_logger(logfile=log)\n",
    "\n",
    "    idx_zarr = zarr.open(idx,mode='r')\n",
    "    logger.info('idx dataset shape: '+str(idx_zarr.shape))\n",
    "    logger.info('idx dataset chunks: '+str(idx_zarr.chunks))\n",
    "    assert idx_zarr.ndim == 2, \"idx dimentation is not 2.\"\n",
    "    if az_chunk_size is None:\n",
    "        n_pc_chunk = math.ceil(idx_zarr.shape[1]/idx_zarr.chunks[1])\n",
    "        az_chunk_size = math.ceil(shape[0]/n_pc_chunk)\n",
    "        logger.info('no input az_chunk_size, automatically set az_chunk_size to make n_az_chunk equals to n_pc_chunk.')\n",
    "    logger.info(f'az_chunk_size: {az_chunk_size}')\n",
    "\n",
    "    logger.info('loading idx into memory.')\n",
    "    idx = zarr.open(idx,mode='r')[:]\n",
    "    n_pc = idx.shape[1]\n",
    "    \n",
    "    if isinstance(pc,str):\n",
    "        assert isinstance(ras,str)\n",
    "        pc_list = [pc]; ras_list = [ras]\n",
    "    else:\n",
    "        assert isinstance(pc,list); assert isinstance(ras,list)\n",
    "        pc_list = pc; ras_list = ras\n",
    "\n",
    "    logger.info('starting dask local cluster.')\n",
    "    cluster = LocalCluster()\n",
    "    client = Client(cluster)\n",
    "    logger.info('dask local cluster started.')\n",
    "\n",
    "    _ras_list = ()\n",
    "\n",
    "    for ras_path, pc_path in zip(ras_list,pc_list):\n",
    "        logger.info(f'start to work on {pc_path}')\n",
    "        pc_zarr = zarr.open(pc_path,'r')\n",
    "        logger.zarr_info(pc_path,pc_zarr)\n",
    "        \n",
    "        pc = da.from_zarr(pc_path)\n",
    "        logger.darr_info('pc', pc)\n",
    "        ras = da.empty((shape[0]*shape[1],*pc.shape[1:]),chunks = (az_chunk_size*shape[1],*pc_zarr.chunks[1:]), dtype=pc.dtype)\n",
    "        ras[:] = np.nan\n",
    "        ras[np.ravel_multi_index((idx[0],idx[1]),dims=shape)] = pc\n",
    "        ras = ras.reshape(*shape,*pc.shape[1:])\n",
    "        logger.info('create ras dask array')\n",
    "        logger.darr_info('ras', ras)\n",
    "        _ras = ras.to_zarr(ras_path,overwrite=True,compute=False)\n",
    "        _ras_list += (_ras,)\n",
    "\n",
    "    logger.info('computing graph setted. doing all the computing.')\n",
    "    da.compute(*_ras_list)\n",
    "\n",
    "    logger.info('computing finished.')\n",
    "    cluster.close()\n",
    "    logger.info('dask cluster closed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0420061b-1fad-4150-9c6b-e11665e37c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@call_parse\n",
    "def console_de_pc2ras(idx:str, # point cloud index\n",
    "                      pc:Param(type=str,required=True,nargs='+',help='one or more path for point cloud data')=None,\n",
    "                      ras:Param(type=str,required=True,nargs='+',help='output, one or more path for raster data')=None,\n",
    "                      shape:Param(type=str,required=True,help='shape of one image \"nlines,width\"')=None,\n",
    "                      az_chunk_size:int=None, # output azimuth chunk size, only one chunk by default\n",
    "                      log:str=None, # log file. Default: no log file\n",
    "):\n",
    "    '''Convert point cloud data to raster data'''\n",
    "    if len(ras)==1:\n",
    "        ras = ras[0]\n",
    "        pc = pc[0]\n",
    "    \n",
    "    shape = shape.split(',')\n",
    "    shape = [int(i) for i in shape]\n",
    "    shape=tuple(shape)\n",
    "\n",
    "    de_pc2ras(idx,pc,ras,shape,az_chunk_size,log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b9b586-35bf-41b4-b5b0-7d4a4e70233e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: de_pc2ras [-h] --pc PC [PC ...] --ras RAS [RAS ...] --shape SHAPE\n",
      "                 [--az_chunk_size AZ_CHUNK_SIZE] [--log LOG]\n",
      "                 idx\n",
      "\n",
      "Convert point cloud data to raster data\n",
      "\n",
      "positional arguments:\n",
      "  idx                            point cloud index\n",
      "\n",
      "options:\n",
      "  -h, --help                     show this help message and exit\n",
      "  --pc PC [PC ...]               one or more path for point cloud data\n",
      "  --ras RAS [RAS ...]            output, one or more path for raster data\n",
      "  --shape SHAPE                  shape of one image \"nlines,width\"\n",
      "  --az_chunk_size AZ_CHUNK_SIZE  output azimuth chunk size, only one chunk by\n",
      "                                 default\n",
      "  --log LOG                      log file. Default: no log file\n"
     ]
    }
   ],
   "source": [
    "!de_pc2ras -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f998e06-f4f2-4d2a-816b-c6ca8b5c8492",
   "metadata": {},
   "source": [
    "Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff5e158-5b51-4182-bc09-10481e605d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_data1 = np.random.rand(1000).astype(np.float32)\n",
    "pc_data2 = np.random.rand(1000,3).astype(np.float32)+1j*np.random.rand(1000,3).astype(np.float32)\n",
    "\n",
    "idx = np.random.choice(np.arange(100*100,dtype=np.int32),size=1000,replace=False)\n",
    "idx.sort()\n",
    "idx = np.stack(np.unravel_index(idx,shape=(100,100))).astype(np.int32)\n",
    "\n",
    "ras_data1 = np.zeros((100,100),dtype=np.float32)\n",
    "ras_data2 = np.zeros((100,100,3),dtype=np.complex64)\n",
    "ras_data1[:] = np.nan\n",
    "ras_data2[:] = np.nan\n",
    "\n",
    "ras_data1[idx[0],idx[1]] = pc_data1\n",
    "ras_data2[idx[0],idx[1]] = pc_data2\n",
    "\n",
    "idx_zarr = zarr.open('pc/idx.zarr','w',shape=idx.shape,dtype=idx.dtype,chunks=(2,200))\n",
    "pc_zarr1 = zarr.open('pc/pc1.zarr','w',shape=pc_data1.shape,dtype=pc_data1.dtype,chunks=(200,))\n",
    "pc_zarr2 = zarr.open('pc/pc2.zarr','w',shape=pc_data2.shape,dtype=pc_data2.dtype,chunks=(200,1))\n",
    "idx_zarr[:] = idx\n",
    "pc_zarr1[:] = pc_data1\n",
    "pc_zarr2[:] = pc_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7cb6b1-5a9d-4cde-8c76-0b0fb8bf4d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-14 22:42:47 - de_pc2ras - INFO - fetching args:\n",
      "2023-10-14 22:42:47 - de_pc2ras - INFO - idx = 'pc/idx.zarr'\n",
      "2023-10-14 22:42:47 - de_pc2ras - INFO - pc = 'pc/pc1.zarr'\n",
      "2023-10-14 22:42:47 - de_pc2ras - INFO - ras = 'pc/ras1.zarr'\n",
      "2023-10-14 22:42:47 - de_pc2ras - INFO - shape = (100, 100)\n",
      "2023-10-14 22:42:47 - de_pc2ras - INFO - az_chunk_size = 20\n",
      "2023-10-14 22:42:47 - de_pc2ras - INFO - log = None\n",
      "2023-10-14 22:42:47 - de_pc2ras - INFO - fetching args done.\n",
      "2023-10-14 22:42:47 - de_pc2ras - INFO - idx dataset shape: (2, 1000)\n",
      "2023-10-14 22:42:47 - de_pc2ras - INFO - idx dataset chunks: (2, 200)\n",
      "2023-10-14 22:42:47 - de_pc2ras - INFO - az_chunk_size: 20\n",
      "2023-10-14 22:42:47 - de_pc2ras - INFO - loading idx into memory.\n",
      "2023-10-14 22:42:47 - de_pc2ras - INFO - starting dask local cluster.\n",
      "2023-10-14 22:42:49 - de_pc2ras - INFO - dask local cluster started.\n",
      "2023-10-14 22:42:49 - de_pc2ras - INFO - start to work on pc/pc1.zarr\n",
      "2023-10-14 22:42:49 - de_pc2ras - INFO - pc/pc1.zarr zarray shape: (1000,)\n",
      "2023-10-14 22:42:49 - de_pc2ras - INFO - pc/pc1.zarr zarray chunks: (200,)\n",
      "2023-10-14 22:42:49 - de_pc2ras - INFO - pc/pc1.zarr zarray dtype: float32\n",
      "2023-10-14 22:42:49 - de_pc2ras - INFO - pc dask array shape: (1000,)\n",
      "2023-10-14 22:42:49 - de_pc2ras - INFO - pc dask array chunksize: (200,)\n",
      "2023-10-14 22:42:49 - de_pc2ras - INFO - pc dask array dtype: float32\n",
      "2023-10-14 22:42:49 - de_pc2ras - INFO - create ras dask array\n",
      "2023-10-14 22:42:49 - de_pc2ras - INFO - ras dask array shape: (100, 100)\n",
      "2023-10-14 22:42:49 - de_pc2ras - INFO - ras dask array chunksize: (20, 100)\n",
      "2023-10-14 22:42:49 - de_pc2ras - INFO - ras dask array dtype: float32\n",
      "2023-10-14 22:42:49 - de_pc2ras - INFO - computing graph setted. doing all the computing.\n",
      "2023-10-14 22:42:50 - de_pc2ras - INFO - computing finished.\n",
      "2023-10-14 22:42:50 - de_pc2ras - INFO - dask cluster closed.\n",
      "2023-10-14 22:42:52 - de_pc2ras - INFO - fetching args:\n",
      "2023-10-14 22:42:52 - de_pc2ras - INFO - idx = 'pc/idx.zarr/'\n",
      "2023-10-14 22:42:52 - de_pc2ras - INFO - pc = 'pc/pc2.zarr/'\n",
      "2023-10-14 22:42:52 - de_pc2ras - INFO - ras = 'pc/ras2.zarr/'\n",
      "2023-10-14 22:42:52 - de_pc2ras - INFO - shape = (100, 100)\n",
      "2023-10-14 22:42:52 - de_pc2ras - INFO - az_chunk_size = 20\n",
      "2023-10-14 22:42:52 - de_pc2ras - INFO - log = None\n",
      "2023-10-14 22:42:52 - de_pc2ras - INFO - fetching args done.\n",
      "2023-10-14 22:42:52 - de_pc2ras - INFO - idx dataset shape: (2, 1000)\n",
      "2023-10-14 22:42:52 - de_pc2ras - INFO - idx dataset chunks: (2, 200)\n",
      "2023-10-14 22:42:52 - de_pc2ras - INFO - az_chunk_size: 20\n",
      "2023-10-14 22:42:52 - de_pc2ras - INFO - loading idx into memory.\n",
      "2023-10-14 22:42:52 - de_pc2ras - INFO - starting dask local cluster.\n",
      "2023-10-14 22:42:55 - de_pc2ras - INFO - dask local cluster started.\n",
      "2023-10-14 22:42:55 - de_pc2ras - INFO - start to work on pc/pc2.zarr/\n",
      "2023-10-14 22:42:55 - de_pc2ras - INFO - pc/pc2.zarr/ zarray shape: (1000, 3)\n",
      "2023-10-14 22:42:55 - de_pc2ras - INFO - pc/pc2.zarr/ zarray chunks: (200, 1)\n",
      "2023-10-14 22:42:55 - de_pc2ras - INFO - pc/pc2.zarr/ zarray dtype: complex64\n",
      "2023-10-14 22:42:55 - de_pc2ras - INFO - pc dask array shape: (1000, 3)\n",
      "2023-10-14 22:42:55 - de_pc2ras - INFO - pc dask array chunksize: (200, 1)\n",
      "2023-10-14 22:42:55 - de_pc2ras - INFO - pc dask array dtype: complex64\n",
      "2023-10-14 22:42:55 - de_pc2ras - INFO - create ras dask array\n",
      "2023-10-14 22:42:55 - de_pc2ras - INFO - ras dask array shape: (100, 100, 3)\n",
      "2023-10-14 22:42:55 - de_pc2ras - INFO - ras dask array chunksize: (20, 100, 1)\n",
      "2023-10-14 22:42:55 - de_pc2ras - INFO - ras dask array dtype: complex64\n",
      "2023-10-14 22:42:55 - de_pc2ras - INFO - computing graph setted. doing all the computing.\n",
      "2023-10-14 22:42:56 - de_pc2ras - INFO - computing finished.\n",
      "2023-10-14 22:42:56 - de_pc2ras - INFO - dask cluster closed.\n",
      "2023-10-14 22:42:57 - de_pc2ras - INFO - fetching args:\n",
      "2023-10-14 22:42:57 - de_pc2ras - INFO - idx = 'pc/idx.zarr'\n",
      "2023-10-14 22:42:57 - de_pc2ras - INFO - pc = ['pc/pc1.zarr', 'pc/pc2.zarr']\n",
      "2023-10-14 22:42:57 - de_pc2ras - INFO - ras = ['pc/ras1.zarr', 'pc/ras2.zarr']\n",
      "2023-10-14 22:42:57 - de_pc2ras - INFO - shape = (100, 100)\n",
      "2023-10-14 22:42:57 - de_pc2ras - INFO - az_chunk_size = 20\n",
      "2023-10-14 22:42:57 - de_pc2ras - INFO - log = None\n",
      "2023-10-14 22:42:57 - de_pc2ras - INFO - fetching args done.\n",
      "2023-10-14 22:42:57 - de_pc2ras - INFO - idx dataset shape: (2, 1000)\n",
      "2023-10-14 22:42:57 - de_pc2ras - INFO - idx dataset chunks: (2, 200)\n",
      "2023-10-14 22:42:57 - de_pc2ras - INFO - az_chunk_size: 20\n",
      "2023-10-14 22:42:57 - de_pc2ras - INFO - loading idx into memory.\n",
      "2023-10-14 22:42:57 - de_pc2ras - INFO - starting dask local cluster.\n",
      "2023-10-14 22:42:58 - de_pc2ras - INFO - dask local cluster started.\n",
      "2023-10-14 22:42:58 - de_pc2ras - INFO - start to work on pc/pc1.zarr\n",
      "2023-10-14 22:42:58 - de_pc2ras - INFO - pc/pc1.zarr zarray shape: (1000,)\n",
      "2023-10-14 22:42:58 - de_pc2ras - INFO - pc/pc1.zarr zarray chunks: (200,)\n",
      "2023-10-14 22:42:58 - de_pc2ras - INFO - pc/pc1.zarr zarray dtype: float32\n",
      "2023-10-14 22:42:58 - de_pc2ras - INFO - pc dask array shape: (1000,)\n",
      "2023-10-14 22:42:58 - de_pc2ras - INFO - pc dask array chunksize: (200,)\n",
      "2023-10-14 22:42:58 - de_pc2ras - INFO - pc dask array dtype: float32\n",
      "2023-10-14 22:42:58 - de_pc2ras - INFO - create ras dask array\n",
      "2023-10-14 22:42:58 - de_pc2ras - INFO - ras dask array shape: (100, 100)\n",
      "2023-10-14 22:42:58 - de_pc2ras - INFO - ras dask array chunksize: (20, 100)\n",
      "2023-10-14 22:42:58 - de_pc2ras - INFO - ras dask array dtype: float32\n",
      "2023-10-14 22:42:58 - de_pc2ras - INFO - start to work on pc/pc2.zarr\n",
      "2023-10-14 22:42:58 - de_pc2ras - INFO - pc/pc2.zarr zarray shape: (1000, 3)\n",
      "2023-10-14 22:42:58 - de_pc2ras - INFO - pc/pc2.zarr zarray chunks: (200, 1)\n",
      "2023-10-14 22:42:58 - de_pc2ras - INFO - pc/pc2.zarr zarray dtype: complex64\n",
      "2023-10-14 22:42:58 - de_pc2ras - INFO - pc dask array shape: (1000, 3)\n",
      "2023-10-14 22:42:58 - de_pc2ras - INFO - pc dask array chunksize: (200, 1)\n",
      "2023-10-14 22:42:58 - de_pc2ras - INFO - pc dask array dtype: complex64\n",
      "2023-10-14 22:42:58 - de_pc2ras - INFO - create ras dask array\n",
      "2023-10-14 22:42:58 - de_pc2ras - INFO - ras dask array shape: (100, 100, 3)\n",
      "2023-10-14 22:42:58 - de_pc2ras - INFO - ras dask array chunksize: (20, 100, 1)\n",
      "2023-10-14 22:42:58 - de_pc2ras - INFO - ras dask array dtype: complex64\n",
      "2023-10-14 22:42:59 - de_pc2ras - INFO - computing graph setted. doing all the computing.\n",
      "2023-10-14 22:42:59 - de_pc2ras - INFO - computing finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 22:42:59,764 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/core.py\", line 1427, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/comm/core.py\", line 329, in connect\n",
      "    handshake = await wait_for(comm.read(), time_left())\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/utils.py\", line 1849, in wait_for\n",
      "    return await asyncio.wait_for(fut, timeout)\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/asyncio/tasks.py\", line 432, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/worker.py\", line 1244, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/utils_comm.py\", line 434, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/utils_comm.py\", line 413, in retry\n",
      "    return await coro()\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/core.py\", line 1262, in send_recv_from_rpc\n",
      "    comm = await self.pool.connect(self.addr)\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/core.py\", line 1506, in connect\n",
      "    return await connect_attempt\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/core.py\", line 1450, in _connect\n",
      "    raise CommClosedError(reason)\n",
      "distributed.comm.core.CommClosedError: ConnectionPool closing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-14 22:43:00 - de_pc2ras - INFO - dask cluster closed.\n",
      "2023-10-14 22:43:01 - de_pc2ras - INFO - fetching args:\n",
      "2023-10-14 22:43:01 - de_pc2ras - INFO - idx = 'pc/idx.zarr/'\n",
      "2023-10-14 22:43:01 - de_pc2ras - INFO - pc = ['pc/pc1.zarr/', 'pc/pc2.zarr/']\n",
      "2023-10-14 22:43:01 - de_pc2ras - INFO - ras = ['pc/ras1.zarr/', 'pc/ras2.zarr/']\n",
      "2023-10-14 22:43:01 - de_pc2ras - INFO - shape = (100, 100)\n",
      "2023-10-14 22:43:01 - de_pc2ras - INFO - az_chunk_size = 20\n",
      "2023-10-14 22:43:01 - de_pc2ras - INFO - log = None\n",
      "2023-10-14 22:43:01 - de_pc2ras - INFO - fetching args done.\n",
      "2023-10-14 22:43:01 - de_pc2ras - INFO - idx dataset shape: (2, 1000)\n",
      "2023-10-14 22:43:01 - de_pc2ras - INFO - idx dataset chunks: (2, 200)\n",
      "2023-10-14 22:43:01 - de_pc2ras - INFO - az_chunk_size: 20\n",
      "2023-10-14 22:43:01 - de_pc2ras - INFO - loading idx into memory.\n",
      "2023-10-14 22:43:01 - de_pc2ras - INFO - starting dask local cluster.\n",
      "2023-10-14 22:43:04 - de_pc2ras - INFO - dask local cluster started.\n",
      "2023-10-14 22:43:04 - de_pc2ras - INFO - start to work on pc/pc1.zarr/\n",
      "2023-10-14 22:43:04 - de_pc2ras - INFO - pc/pc1.zarr/ zarray shape: (1000,)\n",
      "2023-10-14 22:43:04 - de_pc2ras - INFO - pc/pc1.zarr/ zarray chunks: (200,)\n",
      "2023-10-14 22:43:04 - de_pc2ras - INFO - pc/pc1.zarr/ zarray dtype: float32\n",
      "2023-10-14 22:43:04 - de_pc2ras - INFO - pc dask array shape: (1000,)\n",
      "2023-10-14 22:43:04 - de_pc2ras - INFO - pc dask array chunksize: (200,)\n",
      "2023-10-14 22:43:04 - de_pc2ras - INFO - pc dask array dtype: float32\n",
      "2023-10-14 22:43:04 - de_pc2ras - INFO - create ras dask array\n",
      "2023-10-14 22:43:04 - de_pc2ras - INFO - ras dask array shape: (100, 100)\n",
      "2023-10-14 22:43:04 - de_pc2ras - INFO - ras dask array chunksize: (20, 100)\n",
      "2023-10-14 22:43:04 - de_pc2ras - INFO - ras dask array dtype: float32\n",
      "2023-10-14 22:43:04 - de_pc2ras - INFO - start to work on pc/pc2.zarr/\n",
      "2023-10-14 22:43:04 - de_pc2ras - INFO - pc/pc2.zarr/ zarray shape: (1000, 3)\n",
      "2023-10-14 22:43:04 - de_pc2ras - INFO - pc/pc2.zarr/ zarray chunks: (200, 1)\n",
      "2023-10-14 22:43:04 - de_pc2ras - INFO - pc/pc2.zarr/ zarray dtype: complex64\n",
      "2023-10-14 22:43:04 - de_pc2ras - INFO - pc dask array shape: (1000, 3)\n",
      "2023-10-14 22:43:04 - de_pc2ras - INFO - pc dask array chunksize: (200, 1)\n",
      "2023-10-14 22:43:04 - de_pc2ras - INFO - pc dask array dtype: complex64\n",
      "2023-10-14 22:43:04 - de_pc2ras - INFO - create ras dask array\n",
      "2023-10-14 22:43:04 - de_pc2ras - INFO - ras dask array shape: (100, 100, 3)\n",
      "2023-10-14 22:43:04 - de_pc2ras - INFO - ras dask array chunksize: (20, 100, 1)\n",
      "2023-10-14 22:43:04 - de_pc2ras - INFO - ras dask array dtype: complex64\n",
      "2023-10-14 22:43:04 - de_pc2ras - INFO - computing graph setted. doing all the computing.\n",
      "2023-10-14 22:43:05 - de_pc2ras - INFO - computing finished.\n",
      "2023-10-14 22:43:05,188 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nbytes = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/worker.py\", line 1244, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/utils_comm.py\", line 434, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/utils_comm.py\", line 413, in retry\n",
      "    return await coro()\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/core.py\", line 1265, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/core.py\", line 1024, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 241, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/users/kangl/miniconda3/envs/work/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 144, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:57274 remote=tcp://127.0.0.1:34963>: Stream is closed\n",
      "2023-10-14 22:43:05,201 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:40669'.\n",
      "2023-10-14 22:43:05 - de_pc2ras - INFO - dask cluster closed.\n"
     ]
    }
   ],
   "source": [
    "de_pc2ras('pc/idx.zarr','pc/pc1.zarr','pc/ras1.zarr',shape=(100,100),az_chunk_size=20)\n",
    "ras_zarr1 = zarr.open('pc/ras1.zarr','r')\n",
    "np.testing.assert_array_equal(ras_data1,ras_zarr1[:])\n",
    "\n",
    "!de_pc2ras pc/idx.zarr/ --pc pc/pc2.zarr/ --ras pc/ras2.zarr/ --shape \"100,100\" --az_chunk_size 20\n",
    "ras_zarr2 = zarr.open('pc/ras2.zarr','r')\n",
    "np.testing.assert_array_equal(ras_data2,ras_zarr2[:])\n",
    "\n",
    "de_pc2ras('pc/idx.zarr',['pc/pc1.zarr','pc/pc2.zarr'],['pc/ras1.zarr','pc/ras2.zarr'],shape=(100,100),az_chunk_size=20)\n",
    "ras_zarr1 = zarr.open('pc/ras1.zarr','r')\n",
    "ras_zarr2 = zarr.open('pc/ras2.zarr','r')\n",
    "np.testing.assert_array_equal(ras_data1,ras_zarr1[:])\n",
    "np.testing.assert_array_equal(ras_data2,ras_zarr2[:])\n",
    "\n",
    "!de_pc2ras pc/idx.zarr/ --pc pc/pc1.zarr/ pc/pc2.zarr/ --ras pc/ras1.zarr/ pc/ras2.zarr/ --shape \"100,100\" --az_chunk_size 20\n",
    "ras_zarr1 = zarr.open('pc/ras1.zarr','r')\n",
    "ras_zarr2 = zarr.open('pc/ras2.zarr','r')\n",
    "np.testing.assert_array_equal(ras_data1,ras_zarr1[:])\n",
    "np.testing.assert_array_equal(ras_data2,ras_zarr2[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dc751e-b9b3-4dec-b928-2735c432cec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _pc_chunk_size(idx1_zarr,n_pc,logger,pc_chunk_size=None,n_pc_chunk=None):\n",
    "    if pc_chunk_size is not None:\n",
    "        logger.info(f'got pc_chunk_size: {pc_chunk_size}')\n",
    "        return pc_chunk_size\n",
    "    else:\n",
    "        if n_pc_chunk is None:\n",
    "            logger.info(f'use n_pc_chunk from the idx1')\n",
    "            n_pc_chunk = math.ceil(idx1_zarr.shape[1]/idx1_zarr.chunks[1])\n",
    "        logger.info(f'got n_pc_chunk: {n_pc_chunk}')\n",
    "        logger.info(f'automatically determine pc_chunk_size from n_pc and n_pc_chunk')\n",
    "        pc_chunk_size = math.ceil(n_pc/n_pc_chunk)\n",
    "        logger.info(f'pc_chunk_size: {pc_chunk_size}')\n",
    "        return pc_chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bae521-e1b0-4b4d-82eb-699964597b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@log_args\n",
    "def de_pc_union(idx1:str, # index of the first point cloud\n",
    "                idx2:str, # index of the second point cloud\n",
    "                idx:str, # output, index of the union point cloud\n",
    "                pc1:str|list=None, # path (in string) or list of path for the first point cloud data\n",
    "                pc2:str|list=None, # path (in string) or list of path for the second point cloud data\n",
    "                pc:str|list=None, #output, path (in string) or list of path for the union point cloud data\n",
    "                pc_chunk_size:int=None, # chunk size in output data,optional\n",
    "                n_pc_chunk:int=None, # number of chunk in output data, optional, only one chunk if both pc_chunk_size and n_pc_chunk are not set.\n",
    "                log:str=None, # log file. Default: no log file\n",
    "):\n",
    "    '''Get the union of two point cloud dataset.\n",
    "    For points at their intersection, pc_data1 rather than pc_data2 is copied to the result pc_data.\n",
    "    `pc_chunk_size` and `n_pc_chunk` are used to determine the final pc_chunk_size.\n",
    "    If non of them are provided, the n_pc_chunk is set to n_chunk in idx1.\n",
    "    '''\n",
    "    logger = get_logger(logfile=log)\n",
    "\n",
    "    idx1_zarr = zarr.open(idx1,mode='r'); logger.zarr_info('idx1',idx1_zarr)\n",
    "    idx2_zarr = zarr.open(idx2,mode='r'); logger.zarr_info('idx2',idx2_zarr)\n",
    "    logger.info('loading idx1 and idx2 into memory.')\n",
    "    idx1 = idx1_zarr[:]; idx2 = idx2_zarr[:]\n",
    "\n",
    "    logger.info('calculate the union')\n",
    "    idx_path = idx\n",
    "    idx, inv_iidx1, inv_iidx2, iidx2 = pc_union(idx1,idx2)\n",
    "    n_pc = idx.shape[1]\n",
    "    logger.info(f'number of points in the union: {idx.shape[1]}')\n",
    "    pc_chunk_size = _pc_chunk_size(idx1_zarr, n_pc, logger, pc_chunk_size=pc_chunk_size, n_pc_chunk=n_pc_chunk)\n",
    "    \n",
    "    idx_zarr = zarr.open(idx_path,'w',shape=idx.shape,dtype=idx.dtype,chunks=(2,pc_chunk_size))\n",
    "    logger.info('write union idx')\n",
    "    idx_zarr[:] = idx\n",
    "    logger.info('write done')\n",
    "    logger.zarr_info(idx_path, idx_zarr)\n",
    "\n",
    "    if isinstance(pc1,str):\n",
    "        assert isinstance(pc2,str); assert isinstance(pc,str)\n",
    "        pc1_list = [pc1]; pc2_list = [pc2]; pc_list = [pc]\n",
    "    else:\n",
    "        assert isinstance(pc1,list); assert isinstance(pc2,list); assert isinstance(pc,list)\n",
    "        pc1_list = pc1; pc2_list = pc2; pc_list = pc\n",
    "\n",
    "    logger.info('starting dask local cluster.')\n",
    "    cluster = LocalCluster()\n",
    "    client = Client(cluster)\n",
    "    logger.info('dask local cluster started.')\n",
    "    \n",
    "    _pc_list = ()\n",
    "    for pc1_path, pc2_path, pc_path in zip(pc1_list,pc2_list,pc_list):\n",
    "        pc1_zarr = zarr.open(pc1_path,'r'); pc2_zarr = zarr.open(pc2_path,'r')\n",
    "        logger.zarr_info(pc1_path, pc1_zarr); logger.zarr_info(pc2_path, pc2_zarr);\n",
    "        pc1 = da.from_zarr(pc1_path); pc2 = da.from_zarr(pc2_path)\n",
    "        logger.darr_info('pc1', pc1); logger.darr_info('pc2',pc2)\n",
    "        logger.info('set up union pc data dask array.')\n",
    "        pc = da.empty((n_pc,*pc1.shape[1:]),chunks = (pc_chunk_size,*pc1.chunks[1:]), dtype=pc1.dtype)\n",
    "        logger.darr_info('pc',pc)\n",
    "        pc[inv_iidx1] = pc1\n",
    "        pc[inv_iidx2] = pc2[iidx2]\n",
    "        _pc = pc.to_zarr(pc_path, overwrite=True,compute=False)\n",
    "        _pc_list += (_pc,)\n",
    "\n",
    "    logger.info('computing graph setted. doing all the computing.')\n",
    "    da.compute(*_pc_list)\n",
    "\n",
    "    logger.info('computing finished.')\n",
    "    cluster.close()\n",
    "    logger.info('dask cluster closed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16bf1ca-6d42-4265-9fc6-0440e217a807",
   "metadata": {},
   "source": [
    "Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61804e8c-9fd9-4f91-9d2e-75b327b4f11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_data1 = np.random.rand(1000,3).astype(np.float32)+1j*np.random.rand(1000,3).astype(np.float32)\n",
    "pc_data2 = np.random.rand(800,3).astype(np.float32)+1j*np.random.rand(800,3).astype(np.float32)\n",
    "\n",
    "idx1 = np.random.choice(np.arange(100*100,dtype=np.int32),size=1000,replace=False)\n",
    "idx1.sort()\n",
    "idx1 = np.stack(np.unravel_index(idx1,shape=(100,100))).astype(np.int32)\n",
    "\n",
    "idx2 = np.random.choice(np.arange(100*100,dtype=np.int32),size=800,replace=False)\n",
    "idx2.sort()\n",
    "idx2 = np.stack(np.unravel_index(idx2,shape=(100,100))).astype(np.int32)\n",
    "\n",
    "idx, inv_iidx1, inv_iidx2, iidx2 = pc_union(idx1,idx2)\n",
    "\n",
    "pc_data = np.empty((idx.shape[1],*pc_data1.shape[1:]),dtype=pc_data1.dtype)\n",
    "pc_data[inv_iidx1] = pc_data1\n",
    "pc_data[inv_iidx2] = pc_data2[iidx2]\n",
    "\n",
    "idx1_zarr = zarr.open('pc/idx1.zarr','w',shape=idx1.shape,dtype=idx1.dtype,chunks=(2,200))\n",
    "idx2_zarr = zarr.open('pc/idx2.zarr','w',shape=idx2.shape,dtype=idx2.dtype,chunks=(2,200))\n",
    "pc1_zarr = zarr.open('pc/pc1.zarr','w',shape=pc_data1.shape,dtype=pc_data1.dtype,chunks=(200,1))\n",
    "pc2_zarr = zarr.open('pc/pc2.zarr','w',shape=pc_data2.shape,dtype=pc_data2.dtype,chunks=(200,1))\n",
    "idx1_zarr[:] = idx1\n",
    "idx2_zarr[:] = idx2\n",
    "pc1_zarr[:] = pc_data1\n",
    "pc2_zarr[:] = pc_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32ea61e-8437-4fa8-b6ed-844040dc293c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-14 22:43:06 - de_pc_union - INFO - fetching args:\n",
      "2023-10-14 22:43:06 - de_pc_union - INFO - idx1 = 'pc/idx1.zarr'\n",
      "2023-10-14 22:43:06 - de_pc_union - INFO - idx2 = 'pc/idx2.zarr'\n",
      "2023-10-14 22:43:06 - de_pc_union - INFO - idx = 'pc/idx.zarr'\n",
      "2023-10-14 22:43:06 - de_pc_union - INFO - pc1 = 'pc/pc1.zarr'\n",
      "2023-10-14 22:43:06 - de_pc_union - INFO - pc2 = 'pc/pc2.zarr'\n",
      "2023-10-14 22:43:06 - de_pc_union - INFO - pc = 'pc/pc.zarr'\n",
      "2023-10-14 22:43:06 - de_pc_union - INFO - pc_chunk_size = None\n",
      "2023-10-14 22:43:06 - de_pc_union - INFO - n_pc_chunk = None\n",
      "2023-10-14 22:43:06 - de_pc_union - INFO - log = None\n",
      "2023-10-14 22:43:06 - de_pc_union - INFO - fetching args done.\n",
      "2023-10-14 22:43:06 - de_pc_union - INFO - idx1 zarray shape: (2, 1000)\n",
      "2023-10-14 22:43:06 - de_pc_union - INFO - idx1 zarray chunks: (2, 200)\n",
      "2023-10-14 22:43:06 - de_pc_union - INFO - idx1 zarray dtype: int32\n",
      "2023-10-14 22:43:06 - de_pc_union - INFO - idx2 zarray shape: (2, 800)\n",
      "2023-10-14 22:43:06 - de_pc_union - INFO - idx2 zarray chunks: (2, 200)\n",
      "2023-10-14 22:43:06 - de_pc_union - INFO - idx2 zarray dtype: int32\n",
      "2023-10-14 22:43:06 - de_pc_union - INFO - loading idx1 and idx2 into memory.\n",
      "2023-10-14 22:43:06 - de_pc_union - INFO - calculate the union\n",
      "2023-10-14 22:43:06 - de_pc_union - INFO - number of points in the union: 1727\n",
      "2023-10-14 22:43:06 - de_pc_union - INFO - use n_pc_chunk from the idx1\n",
      "2023-10-14 22:43:06 - de_pc_union - INFO - got n_pc_chunk: 5\n",
      "2023-10-14 22:43:06 - de_pc_union - INFO - automatically determine pc_chunk_size from n_pc and n_pc_chunk\n",
      "2023-10-14 22:43:06 - de_pc_union - INFO - pc_chunk_size: 346\n",
      "2023-10-14 22:43:06 - de_pc_union - INFO - write union idx\n",
      "2023-10-14 22:43:06 - de_pc_union - INFO - write done\n",
      "2023-10-14 22:43:06 - de_pc_union - INFO - pc/idx.zarr zarray shape: (2, 1727)\n",
      "2023-10-14 22:43:06 - de_pc_union - INFO - pc/idx.zarr zarray chunks: (2, 346)\n",
      "2023-10-14 22:43:06 - de_pc_union - INFO - pc/idx.zarr zarray dtype: int32\n",
      "2023-10-14 22:43:06 - de_pc_union - INFO - starting dask local cluster.\n",
      "2023-10-14 22:43:07 - de_pc_union - INFO - dask local cluster started.\n",
      "2023-10-14 22:43:07 - de_pc_union - INFO - pc/pc1.zarr zarray shape: (1000, 3)\n",
      "2023-10-14 22:43:07 - de_pc_union - INFO - pc/pc1.zarr zarray chunks: (200, 1)\n",
      "2023-10-14 22:43:07 - de_pc_union - INFO - pc/pc1.zarr zarray dtype: complex64\n",
      "2023-10-14 22:43:07 - de_pc_union - INFO - pc/pc2.zarr zarray shape: (800, 3)\n",
      "2023-10-14 22:43:07 - de_pc_union - INFO - pc/pc2.zarr zarray chunks: (200, 1)\n",
      "2023-10-14 22:43:07 - de_pc_union - INFO - pc/pc2.zarr zarray dtype: complex64\n",
      "2023-10-14 22:43:07 - de_pc_union - INFO - pc1 dask array shape: (1000, 3)\n",
      "2023-10-14 22:43:07 - de_pc_union - INFO - pc1 dask array chunksize: (200, 1)\n",
      "2023-10-14 22:43:07 - de_pc_union - INFO - pc1 dask array dtype: complex64\n",
      "2023-10-14 22:43:07 - de_pc_union - INFO - pc2 dask array shape: (800, 3)\n",
      "2023-10-14 22:43:07 - de_pc_union - INFO - pc2 dask array chunksize: (200, 1)\n",
      "2023-10-14 22:43:07 - de_pc_union - INFO - pc2 dask array dtype: complex64\n",
      "2023-10-14 22:43:07 - de_pc_union - INFO - set up union pc data dask array.\n",
      "2023-10-14 22:43:07 - de_pc_union - INFO - pc dask array shape: (1727, 3)\n",
      "2023-10-14 22:43:07 - de_pc_union - INFO - pc dask array chunksize: (346, 1)\n",
      "2023-10-14 22:43:07 - de_pc_union - INFO - pc dask array dtype: complex64\n",
      "2023-10-14 22:43:07 - de_pc_union - INFO - computing graph setted. doing all the computing.\n",
      "2023-10-14 22:43:08 - de_pc_union - INFO - computing finished.\n",
      "2023-10-14 22:43:09 - de_pc_union - INFO - dask cluster closed.\n"
     ]
    }
   ],
   "source": [
    "de_pc_union('pc/idx1.zarr','pc/idx2.zarr','pc/idx.zarr','pc/pc1.zarr','pc/pc2.zarr','pc/pc.zarr')\n",
    "idx_zarr = zarr.open('pc/idx.zarr','r')\n",
    "pc_zarr = zarr.open('pc/pc.zarr','r')\n",
    "np.testing.assert_array_equal(idx_zarr[:],idx)\n",
    "np.testing.assert_array_equal(pc_zarr[:],pc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e165db47-38a1-4ce9-870f-4d27f79bd848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@log_args\n",
    "def de_pc_intersect(idx1:str, # index of the first point cloud\n",
    "                    idx2:str, # index of the second point cloud\n",
    "                    idx:str, # output, index of the union point cloud\n",
    "                    pc1:str|list=None, # path (in string) or list of path for the first point cloud data\n",
    "                    pc2:str|list=None, # path (in string) or list of path for the second point cloud data\n",
    "                    pc:str|list=None, #output, path (in string) or list of path for the union point cloud data\n",
    "                    pc_chunk_size:int=None, # chunk size in output data,optional\n",
    "                    n_pc_chunk:int=None, # number of chunk in output data, optional, only one chunk if both pc_chunk_size and n_pc_chunk are not set.\n",
    "                    prefer_1=True, # save pc1 on intersection to output pc dataset by default `True`. Otherwise, save data from pc2\n",
    "                    log:str=None, # log file. Default: no log file\n",
    "):\n",
    "    '''Get the intersection of two point cloud dataset.\n",
    "    `pc_chunk_size` and `n_pc_chunk` are used to determine the final pc_chunk_size.\n",
    "    If non of them are provided, the n_pc_chunk is set to n_chunk in idx1.\n",
    "    '''\n",
    "    logger = get_logger(logfile=log)\n",
    "\n",
    "    idx1_zarr = zarr.open(idx1,mode='r'); logger.zarr_info('idx1',idx1_zarr)\n",
    "    idx2_zarr = zarr.open(idx2,mode='r'); logger.zarr_info('idx2',idx2_zarr)\n",
    "    logger.info('loading idx1 and idx2 into memory.')\n",
    "    idx1 = idx1_zarr[:]; idx2 = idx2_zarr[:]\n",
    "\n",
    "    logger.info('calculate the intersection')\n",
    "    idx_path = idx\n",
    "    idx, iidx1, iidx2 = pc_intersect(idx1,idx2)\n",
    "    n_pc = idx.shape[1]\n",
    "    logger.info(f'number of points in the intersection: {idx.shape[1]}')\n",
    "    pc_chunk_size = _pc_chunk_size(idx1_zarr, n_pc, logger, pc_chunk_size=pc_chunk_size, n_pc_chunk=n_pc_chunk)\n",
    "    \n",
    "    idx_zarr = zarr.open(idx_path,'w',shape=idx.shape,dtype=idx.dtype,chunks=(2,pc_chunk_size))\n",
    "    logger.info('write intersect idx')\n",
    "    idx_zarr[:] = idx\n",
    "    logger.info('write done')\n",
    "    logger.zarr_info(idx_path, idx_zarr)\n",
    "\n",
    "    if prefer_1:\n",
    "        logger.info('select pc1 as pc_input.')\n",
    "        iidx = iidx1\n",
    "        pc_input = pc1\n",
    "    else:\n",
    "        logger.info('select pc2 as pc_input.')\n",
    "        iidx = iidx2\n",
    "        pc_input = pc2\n",
    "\n",
    "    if isinstance(pc_input,str):\n",
    "        assert isinstance(pc,str)\n",
    "        pc_input_list = [pc_input]; pc_list = [pc]\n",
    "    else:\n",
    "        assert isinstance(pc_input,list); assert isinstance(pc,list)\n",
    "        pc_input_list = pc_input; pc_list = pc\n",
    "\n",
    "    logger.info('starting dask local cluster.')\n",
    "    cluster = LocalCluster()\n",
    "    client = Client(cluster)\n",
    "    logger.info('dask local cluster started.')\n",
    "    \n",
    "    _pc_list = ()\n",
    "    for pc_input_path, pc_path in zip(pc_input_list,pc_list):\n",
    "        pc_input_zarr = zarr.open(pc_input_path,'r')\n",
    "        logger.zarr_info(pc_input_path,pc_input_zarr)\n",
    "        pc_input = da.from_zarr(pc_input_path)\n",
    "        logger.darr_info('pc_input', pc_input)\n",
    "\n",
    "        logger.info('set up intersect pc data dask array.')\n",
    "        pc = da.empty((n_pc,*pc_input.shape[1:]),chunks = (pc_chunk_size,*pc_input.chunks[1:]), dtype=pc_input.dtype)\n",
    "        logger.darr_info('pc',pc)\n",
    "        pc[:] = pc_input[iidx]\n",
    "        _pc = pc.to_zarr(pc_path, overwrite=True,compute=False)\n",
    "        _pc_list += (_pc,)\n",
    "\n",
    "    logger.info('computing graph setted. doing all the computing.')\n",
    "    da.compute(*_pc_list)\n",
    "\n",
    "    logger.info('computing finished.')\n",
    "    cluster.close()\n",
    "    logger.info('dask cluster closed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d15aec-f241-4fcf-96e0-c839994ac04b",
   "metadata": {},
   "source": [
    "Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5e1d41-a087-4bdd-9e17-fa3021fc0045",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_data1 = np.random.rand(1000,3).astype(np.float32)+1j*np.random.rand(1000,3).astype(np.float32)\n",
    "pc_data2 = np.random.rand(800,3).astype(np.float32)+1j*np.random.rand(800,3).astype(np.float32)\n",
    "\n",
    "idx1 = np.random.choice(np.arange(100*100,dtype=np.int32),size=1000,replace=False)\n",
    "idx1.sort()\n",
    "idx1 = np.stack(np.unravel_index(idx1,shape=(100,100))).astype(np.int32)\n",
    "\n",
    "idx2 = np.random.choice(np.arange(100*100,dtype=np.int32),size=800,replace=False)\n",
    "idx2.sort()\n",
    "idx2 = np.stack(np.unravel_index(idx2,shape=(100,100))).astype(np.int32)\n",
    "\n",
    "idx, iidx1, iidx2 = pc_intersect(idx1,idx2)\n",
    "\n",
    "pc_data = np.empty((idx.shape[1],*pc_data1.shape[1:]),dtype=pc_data1.dtype)\n",
    "pc_data[:] = pc_data2[iidx2]\n",
    "\n",
    "idx1_zarr = zarr.open('pc/idx1.zarr','w',shape=idx1.shape,dtype=idx1.dtype,chunks=(2,200))\n",
    "idx2_zarr = zarr.open('pc/idx2.zarr','w',shape=idx2.shape,dtype=idx2.dtype,chunks=(2,200))\n",
    "pc1_zarr = zarr.open('pc/pc1.zarr','w',shape=pc_data1.shape,dtype=pc_data1.dtype,chunks=(200,1))\n",
    "pc2_zarr = zarr.open('pc/pc2.zarr','w',shape=pc_data2.shape,dtype=pc_data2.dtype,chunks=(200,1))\n",
    "idx1_zarr[:] = idx1\n",
    "idx2_zarr[:] = idx2\n",
    "pc1_zarr[:] = pc_data1\n",
    "pc2_zarr[:] = pc_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79624277-e4e9-488f-9785-b41a201db068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - fetching args:\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - idx1 = 'pc/idx1.zarr'\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - idx2 = 'pc/idx2.zarr'\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - idx = 'pc/idx.zarr'\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - pc1 = None\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - pc2 = 'pc/pc2.zarr'\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - pc = 'pc/pc.zarr'\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - pc_chunk_size = None\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - n_pc_chunk = None\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - prefer_1 = False\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - log = None\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - fetching args done.\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - idx1 zarray shape: (2, 1000)\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - idx1 zarray chunks: (2, 200)\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - idx1 zarray dtype: int32\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - idx2 zarray shape: (2, 800)\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - idx2 zarray chunks: (2, 200)\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - idx2 zarray dtype: int32\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - loading idx1 and idx2 into memory.\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - calculate the intersection\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - number of points in the intersection: 71\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - use n_pc_chunk from the idx1\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - got n_pc_chunk: 5\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - automatically determine pc_chunk_size from n_pc and n_pc_chunk\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - pc_chunk_size: 15\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - write intersect idx\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - write done\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - pc/idx.zarr zarray shape: (2, 71)\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - pc/idx.zarr zarray chunks: (2, 15)\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - pc/idx.zarr zarray dtype: int32\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - select pc2 as pc_input.\n",
      "2023-10-14 22:43:09 - de_pc_intersect - INFO - starting dask local cluster.\n",
      "2023-10-14 22:43:11 - de_pc_intersect - INFO - dask local cluster started.\n",
      "2023-10-14 22:43:11 - de_pc_intersect - INFO - pc/pc2.zarr zarray shape: (800, 3)\n",
      "2023-10-14 22:43:11 - de_pc_intersect - INFO - pc/pc2.zarr zarray chunks: (200, 1)\n",
      "2023-10-14 22:43:11 - de_pc_intersect - INFO - pc/pc2.zarr zarray dtype: complex64\n",
      "2023-10-14 22:43:11 - de_pc_intersect - INFO - pc_input dask array shape: (800, 3)\n",
      "2023-10-14 22:43:11 - de_pc_intersect - INFO - pc_input dask array chunksize: (200, 1)\n",
      "2023-10-14 22:43:11 - de_pc_intersect - INFO - pc_input dask array dtype: complex64\n",
      "2023-10-14 22:43:11 - de_pc_intersect - INFO - set up intersect pc data dask array.\n",
      "2023-10-14 22:43:11 - de_pc_intersect - INFO - pc dask array shape: (71, 3)\n",
      "2023-10-14 22:43:11 - de_pc_intersect - INFO - pc dask array chunksize: (15, 1)\n",
      "2023-10-14 22:43:11 - de_pc_intersect - INFO - pc dask array dtype: complex64\n",
      "2023-10-14 22:43:11 - de_pc_intersect - INFO - computing graph setted. doing all the computing.\n",
      "2023-10-14 22:43:12 - de_pc_intersect - INFO - computing finished.\n",
      "2023-10-14 22:43:12 - de_pc_intersect - INFO - dask cluster closed.\n"
     ]
    }
   ],
   "source": [
    "de_pc_intersect('pc/idx1.zarr','pc/idx2.zarr','pc/idx.zarr',pc2='pc/pc2.zarr', pc='pc/pc.zarr',prefer_1=False)\n",
    "idx_zarr = zarr.open('pc/idx.zarr','r')\n",
    "pc_zarr = zarr.open('pc/pc.zarr','r')\n",
    "np.testing.assert_array_equal(idx_zarr[:],idx)\n",
    "np.testing.assert_array_equal(pc_zarr[:],pc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6709657-ac69-48d5-8c89-72a42cc19939",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@log_args\n",
    "def de_pc_diff(idx1:str, # index of the first point cloud\n",
    "               idx2:str, # index of the second point cloud\n",
    "               idx:str, # output, index of the union point cloud\n",
    "               pc1:str|list=None, # path (in string) or list of path for the first point cloud data\n",
    "               pc:str|list=None, #output, path (in string) or list of path for the union point cloud data\n",
    "               pc_chunk_size:int=None, # chunk size in output data,optional\n",
    "               n_pc_chunk:int=None, # number of chunk in output data, optional, only one chunk if both pc_chunk_size and n_pc_chunk are not set.\n",
    "               log:str=None, # log file. Default: no log file\n",
    "              ):\n",
    "    '''Get the point cloud in `idx1` that are not in `idx2`.\n",
    "    `pc_chunk_size` and `n_pc_chunk` are used to determine the final pc_chunk_size.\n",
    "    If non of them are provided, the n_pc_chunk is set to n_chunk in idx1.\n",
    "    '''\n",
    "    logger = get_logger(logfile=log)\n",
    "\n",
    "    idx1_zarr = zarr.open(idx1,mode='r'); logger.zarr_info('idx1',idx1_zarr)\n",
    "    idx2_zarr = zarr.open(idx2,mode='r'); logger.zarr_info('idx2',idx2_zarr)\n",
    "    logger.info('loading idx1 and idx2 into memory.')\n",
    "    idx1 = idx1_zarr[:]; idx2 = idx2_zarr[:]\n",
    "\n",
    "    logger.info('calculate the diff.')\n",
    "    idx_path = idx\n",
    "    idx, iidx1 = pc_diff(idx1,idx2)\n",
    "    n_pc = idx.shape[1]\n",
    "    logger.info(f'number of points in the diff: {idx.shape[1]}')\n",
    "    pc_chunk_size = _pc_chunk_size(idx1_zarr, n_pc, logger, pc_chunk_size=pc_chunk_size, n_pc_chunk=n_pc_chunk)\n",
    "    \n",
    "    idx_zarr = zarr.open(idx_path,'w',shape=idx.shape,dtype=idx.dtype,chunks=(2,pc_chunk_size))\n",
    "    logger.info('write intersect idx')\n",
    "    idx_zarr[:] = idx\n",
    "    logger.info('write done')\n",
    "    logger.zarr_info(idx_path, idx_zarr)\n",
    "\n",
    "    if isinstance(pc1,str):\n",
    "        assert isinstance(pc,str)\n",
    "        pc1_list = [pc1]; pc_list = [pc]\n",
    "    else:\n",
    "        assert isinstance(pc1,list); assert isinstance(pc,list)\n",
    "        pc1_list = pc1; pc_list = pc\n",
    "\n",
    "    logger.info('starting dask local cluster.')\n",
    "    cluster = LocalCluster()\n",
    "    client = Client(cluster)\n",
    "    logger.info('dask local cluster started.')\n",
    "    \n",
    "    _pc_list = ()\n",
    "    for pc1_path, pc_path in zip(pc1_list,pc_list):\n",
    "        pc1_zarr = zarr.open(pc1_path,'r')\n",
    "        logger.zarr_info(pc1_path, pc1_zarr)\n",
    "        pc1 = da.from_zarr(pc1_path)\n",
    "        logger.darr_info('pc1', pc1)\n",
    "        logger.info('set up diff pc data dask array.')\n",
    "        pc = da.empty((n_pc,*pc1.shape[1:]),chunks = (pc_chunk_size,*pc1.chunks[1:]), dtype=pc1.dtype)\n",
    "        logger.darr_info('pc',pc)\n",
    "        pc[:] = pc1[iidx1]\n",
    "        _pc = pc.to_zarr(pc_path, overwrite=True,compute=False)\n",
    "        _pc_list += (_pc,)\n",
    "\n",
    "    logger.info('computing graph setted. doing all the computing.')\n",
    "    da.compute(*_pc_list)\n",
    "\n",
    "    logger.info('computing finished.')\n",
    "    cluster.close()\n",
    "    logger.info('dask cluster closed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2053e3-a509-4089-87b4-2fd605a23cab",
   "metadata": {},
   "source": [
    "Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e674d6-5b0d-448c-b456-a0bbf1823db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_data1 = np.random.rand(1000,3).astype(np.float32)+1j*np.random.rand(1000,3).astype(np.float32)\n",
    "\n",
    "idx1 = np.random.choice(np.arange(100*100,dtype=np.int32),size=1000,replace=False)\n",
    "idx1.sort()\n",
    "idx1 = np.stack(np.unravel_index(idx1,shape=(100,100))).astype(np.int32)\n",
    "\n",
    "idx2 = np.random.choice(np.arange(100*100,dtype=np.int32),size=800,replace=False)\n",
    "idx2.sort()\n",
    "idx2 = np.stack(np.unravel_index(idx2,shape=(100,100))).astype(np.int32)\n",
    "\n",
    "idx, iidx1 = pc_diff(idx1,idx2)\n",
    "\n",
    "pc_data = np.empty((idx.shape[1],*pc_data1.shape[1:]),dtype=pc_data1.dtype)\n",
    "pc_data[:] = pc_data1[iidx1]\n",
    "\n",
    "idx1_zarr = zarr.open('pc/idx1.zarr','w',shape=idx1.shape,dtype=idx1.dtype,chunks=(2,200))\n",
    "idx2_zarr = zarr.open('pc/idx2.zarr','w',shape=idx2.shape,dtype=idx2.dtype,chunks=(2,200))\n",
    "pc1_zarr = zarr.open('pc/pc1.zarr','w',shape=pc_data1.shape,dtype=pc_data1.dtype,chunks=(200,1))\n",
    "idx1_zarr[:] = idx1\n",
    "idx2_zarr[:] = idx2\n",
    "pc1_zarr[:] = pc_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bc9d97-3e59-4185-978c-e79606560c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-14 22:43:12 - de_pc_diff - INFO - fetching args:\n",
      "2023-10-14 22:43:12 - de_pc_diff - INFO - idx1 = 'pc/idx1.zarr'\n",
      "2023-10-14 22:43:12 - de_pc_diff - INFO - idx2 = 'pc/idx2.zarr'\n",
      "2023-10-14 22:43:12 - de_pc_diff - INFO - idx = 'pc/idx.zarr'\n",
      "2023-10-14 22:43:12 - de_pc_diff - INFO - pc1 = 'pc/pc1.zarr'\n",
      "2023-10-14 22:43:12 - de_pc_diff - INFO - pc = 'pc/pc.zarr'\n",
      "2023-10-14 22:43:12 - de_pc_diff - INFO - pc_chunk_size = None\n",
      "2023-10-14 22:43:12 - de_pc_diff - INFO - n_pc_chunk = None\n",
      "2023-10-14 22:43:12 - de_pc_diff - INFO - log = None\n",
      "2023-10-14 22:43:12 - de_pc_diff - INFO - fetching args done.\n",
      "2023-10-14 22:43:12 - de_pc_diff - INFO - idx1 zarray shape: (2, 1000)\n",
      "2023-10-14 22:43:12 - de_pc_diff - INFO - idx1 zarray chunks: (2, 200)\n",
      "2023-10-14 22:43:12 - de_pc_diff - INFO - idx1 zarray dtype: int32\n",
      "2023-10-14 22:43:12 - de_pc_diff - INFO - idx2 zarray shape: (2, 800)\n",
      "2023-10-14 22:43:12 - de_pc_diff - INFO - idx2 zarray chunks: (2, 200)\n",
      "2023-10-14 22:43:12 - de_pc_diff - INFO - idx2 zarray dtype: int32\n",
      "2023-10-14 22:43:12 - de_pc_diff - INFO - loading idx1 and idx2 into memory.\n",
      "2023-10-14 22:43:12 - de_pc_diff - INFO - calculate the diff.\n",
      "2023-10-14 22:43:12 - de_pc_diff - INFO - number of points in the diff: 914\n",
      "2023-10-14 22:43:12 - de_pc_diff - INFO - use n_pc_chunk from the idx1\n",
      "2023-10-14 22:43:12 - de_pc_diff - INFO - got n_pc_chunk: 5\n",
      "2023-10-14 22:43:12 - de_pc_diff - INFO - automatically determine pc_chunk_size from n_pc and n_pc_chunk\n",
      "2023-10-14 22:43:12 - de_pc_diff - INFO - pc_chunk_size: 183\n",
      "2023-10-14 22:43:12 - de_pc_diff - INFO - write intersect idx\n",
      "2023-10-14 22:43:12 - de_pc_diff - INFO - write done\n",
      "2023-10-14 22:43:12 - de_pc_diff - INFO - pc/idx.zarr zarray shape: (2, 914)\n",
      "2023-10-14 22:43:12 - de_pc_diff - INFO - pc/idx.zarr zarray chunks: (2, 183)\n",
      "2023-10-14 22:43:12 - de_pc_diff - INFO - pc/idx.zarr zarray dtype: int32\n",
      "2023-10-14 22:43:12 - de_pc_diff - INFO - starting dask local cluster.\n",
      "2023-10-14 22:43:14 - de_pc_diff - INFO - dask local cluster started.\n",
      "2023-10-14 22:43:14 - de_pc_diff - INFO - pc/pc1.zarr zarray shape: (1000, 3)\n",
      "2023-10-14 22:43:14 - de_pc_diff - INFO - pc/pc1.zarr zarray chunks: (200, 1)\n",
      "2023-10-14 22:43:14 - de_pc_diff - INFO - pc/pc1.zarr zarray dtype: complex64\n",
      "2023-10-14 22:43:14 - de_pc_diff - INFO - pc1 dask array shape: (1000, 3)\n",
      "2023-10-14 22:43:14 - de_pc_diff - INFO - pc1 dask array chunksize: (200, 1)\n",
      "2023-10-14 22:43:14 - de_pc_diff - INFO - pc1 dask array dtype: complex64\n",
      "2023-10-14 22:43:14 - de_pc_diff - INFO - set up diff pc data dask array.\n",
      "2023-10-14 22:43:14 - de_pc_diff - INFO - pc dask array shape: (914, 3)\n",
      "2023-10-14 22:43:14 - de_pc_diff - INFO - pc dask array chunksize: (183, 1)\n",
      "2023-10-14 22:43:14 - de_pc_diff - INFO - pc dask array dtype: complex64\n",
      "2023-10-14 22:43:14 - de_pc_diff - INFO - computing graph setted. doing all the computing.\n",
      "2023-10-14 22:43:15 - de_pc_diff - INFO - computing finished.\n",
      "2023-10-14 22:43:15 - de_pc_diff - INFO - dask cluster closed.\n"
     ]
    }
   ],
   "source": [
    "de_pc_diff('pc/idx1.zarr','pc/idx2.zarr','pc/idx.zarr',pc1='pc/pc1.zarr', pc='pc/pc.zarr')\n",
    "idx_zarr = zarr.open('pc/idx.zarr','r')\n",
    "pc_zarr = zarr.open('pc/pc.zarr','r')\n",
    "np.testing.assert_array_equal(idx_zarr[:],idx)\n",
    "np.testing.assert_array_equal(pc_zarr[:],pc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50eda76-1cf8-4fb7-9f5a-df8af874e97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3474c7-05b2-4147-8a8f-a313e81e5c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:work] *",
   "language": "python",
   "name": "conda-env-work-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
