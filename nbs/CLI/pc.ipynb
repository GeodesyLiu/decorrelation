{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "238849fa-11ec-4de5-99e4-c4eb367f7913",
   "metadata": {},
   "source": [
    "# pc\n",
    "\n",
    "> Point Cloud data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eed06b-0dd0-4177-8a92-8757961eecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp cli/pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967c14e4-d207-455f-829c-4c3a005838ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b686af00-c16a-401d-baf8-2847eda5416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from itertools import product\n",
    "import math\n",
    "from typing import Union\n",
    "import re\n",
    "\n",
    "import zarr\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import colorcet\n",
    "\n",
    "import dask\n",
    "from dask import array as da\n",
    "from dask import delayed\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "from decorrelation.pc import pc2ras\n",
    "from decorrelation.cli.utils.logging import get_logger, log_args\n",
    "\n",
    "from fastcore.script import call_parse, Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2d5d0e-48cf-450b-8eb8-91a31cae04a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@log_args\n",
    "def de_ras2pc(idx:str, # point cloud index\n",
    "              ras:str|list, # path (in string) or list of path for raster data\n",
    "              pc:str|list, # output, path (in string) or list of path for point cloud data\n",
    "              pc_chunk_size:int=None, # output point chunk size, same as input idx by default\n",
    "              hd_chunk_size:tuple|list=None, # output high dimension chunk size, tuple or list of tuple, same as input raster data by default\n",
    "              log:str=None, # log file. Default: no log file\n",
    "):\n",
    "    '''Convert raster data to point cloud data'''\n",
    "    # I find there is no need to set this hd_chunk_size, generally we do not need it\n",
    "    logger = get_logger(logfile=log)\n",
    "\n",
    "    idx_zarr = zarr.open(idx,mode='r')\n",
    "    logger.zarr_info(idx,idx_zarr)\n",
    "    assert idx_zarr.ndim == 2, \"idx dimentation is not 2.\"\n",
    "    if not pc_chunk_size:\n",
    "        pc_chunk_size = idx_zarr.chunks[1]\n",
    "        logger.info('no input pc_chunk_size, use pc_chunk_size as input idx')\n",
    "    logger.info(f'pc_chunk_size: {pc_chunk_size}')\n",
    "\n",
    "    logger.info('loading idx into memory.')\n",
    "    idx = zarr.open(idx,mode='r')[:]\n",
    "    n_pc = idx.shape[1]\n",
    "\n",
    "    if isinstance(ras,str):\n",
    "        assert isinstance(pc,str)\n",
    "        ras_list = [ras]\n",
    "        pc_list = [pc]\n",
    "        if hd_chunk_size is not None:\n",
    "            assert isinstance(hd_chunk_size,tuple)\n",
    "            hd_chunk_size_list = [hd_chunk_size]\n",
    "        else:\n",
    "            hd_chunk_size_list = [None]\n",
    "    else:\n",
    "        assert isinstance(ras,list)\n",
    "        assert isinstance(pc,list)\n",
    "        ras_list = ras\n",
    "        pc_list = pc\n",
    "        n_data = len(ras_list)\n",
    "        if hd_chunk_size is not None:\n",
    "            assert isinstance(hd_chunk_size,list)\n",
    "            hd_chunk_size_list = hd_chunk_size\n",
    "        else:\n",
    "            hd_chunk_size_list = [None]*n_data\n",
    "\n",
    "    logger.info('starting dask local cluster.')\n",
    "    cluster = LocalCluster()\n",
    "    client = Client(cluster)\n",
    "    logger.info('dask local cluster started.')\n",
    "\n",
    "    _pc_list = ()\n",
    "    for ras_path, pc_path, hd_chunk_size in zip(ras_list,pc_list,hd_chunk_size_list):\n",
    "        logger.info(f'start to slice on {ras_path}')\n",
    "        ras_zarr = zarr.open(ras_path,'r')\n",
    "        logger.zarr_info(ras_path, ras_zarr)\n",
    "        if hd_chunk_size is None:\n",
    "            logger.info(f'hd_chunk_size not setted. Use the one from {ras_path}.')\n",
    "            hd_chunk_size = ras_zarr.chunks[2:]\n",
    "        logger.info(f'hd_chunk_size: {hd_chunk_size}.')\n",
    "\n",
    "        ras = da.from_zarr(ras_path,chunks=(*ras_zarr.chunks[:2],*hd_chunk_size))\n",
    "        logger.darr_info('ras',ras)\n",
    "\n",
    "        with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
    "            pc = ras.reshape(-1,*ras.shape[2:])[np.ravel_multi_index((idx[0],idx[1]),dims=ras.shape[:2])]\n",
    "        \n",
    "        logger.darr_info('pc', pc)\n",
    "        logger.info('rechunk pc data:')\n",
    "        pc = pc.rechunk((pc_chunk_size,*pc.chunksize[1:]))\n",
    "        logger.darr_info('pc', pc)\n",
    "        _pc = pc.to_zarr(pc_path,overwrite=True,compute=False)\n",
    "        logger.info(f'saving to {pc_path}.')\n",
    "        _pc_list += (_pc,)\n",
    "    \n",
    "    logger.info('computing graph setted. doing all the computing.')\n",
    "    da.compute(*_pc_list)\n",
    "\n",
    "    logger.info('computing finished.')\n",
    "    cluster.close()\n",
    "    logger.info('dask cluster closed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad08c7-bb6c-492a-acd2-44ec6e75fb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@call_parse\n",
    "def console_de_ras2pc(idx:str, # point cloud index\n",
    "                      ras:Param(type=str,required=True,nargs='+',help='one or more path for raster data')=None,\n",
    "                      pc:Param(type=str,required=True,nargs='+',help='output, one or more path for point cloud data')=None,\n",
    "                      pc_chunk_size:int=None, # output point chunk size, same as input idx by default\n",
    "                      hd_chunk_size:Param(type=str,nargs='+',help='''output high dimension chunk size,\n",
    "                      each size should be wrapped in quotation marks and size in each dimension are seperated with \",\",\n",
    "                      same as input raster data by default''')=None,\n",
    "                      log:str=None, # log file. Default: no log file\n",
    "):\n",
    "    '''Convert raster data to point cloud data'''\n",
    "    if hd_chunk_size is not None:\n",
    "        hd_chunk_size_ = []\n",
    "        for size in hd_chunk_size:\n",
    "            if len(size) == 0:\n",
    "                size = ()\n",
    "            else:\n",
    "                size = size.split(',')\n",
    "                size = tuple([int(i) for i in size])\n",
    "            hd_chunk_size_.append(size)\n",
    "    else:\n",
    "        hd_chunk_size_ = None\n",
    "\n",
    "    if len(ras)==1:\n",
    "        ras = ras[0]\n",
    "        pc = pc[0]\n",
    "        if hd_chunk_size_ is not None:\n",
    "            hd_chunk_size_ = hd_chunk_size_[0]\n",
    "\n",
    "    de_ras2pc(idx,ras,pc,pc_chunk_size,hd_chunk_size_,log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec30940a-4ff1-4f22-a282-da51f8fad493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: de_ras2pc [-h] --ras RAS [RAS ...] --pc PC [PC ...]\n",
      "                 [--pc_chunk_size PC_CHUNK_SIZE]\n",
      "                 [--hd_chunk_size HD_CHUNK_SIZE [HD_CHUNK_SIZE ...]] [--log LOG]\n",
      "                 idx\n",
      "\n",
      "Convert raster data to point cloud data\n",
      "\n",
      "positional arguments:\n",
      "  idx                                   point cloud index\n",
      "\n",
      "options:\n",
      "  -h, --help                            show this help message and exit\n",
      "  --ras RAS [RAS ...]                   one or more path for raster data\n",
      "  --pc PC [PC ...]                      output, one or more path for point cloud\n",
      "                                        data\n",
      "  --pc_chunk_size PC_CHUNK_SIZE         output point chunk size, same as input\n",
      "                                        idx by default\n",
      "  --hd_chunk_size HD_CHUNK_SIZE [HD_CHUNK_SIZE ...]\n",
      "                                        output high dimension chunk size, each\n",
      "                                        size should be wrapped in quotation\n",
      "                                        marks and size in each dimension are\n",
      "                                        seperated with \",\", same as input raster\n",
      "                                        data by default\n",
      "  --log LOG                             log file. Default: no log file\n"
     ]
    }
   ],
   "source": [
    "!de_ras2pc -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae4f91c-2870-40d7-ab4f-2378ff6d3e95",
   "metadata": {},
   "source": [
    "Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38fc5b0-a8e9-4c8e-9900-b36c6bcfc952",
   "metadata": {},
   "outputs": [],
   "source": [
    "ras_data1 = np.random.rand(100,100).astype(np.float32)\n",
    "ras_data2 = np.random.rand(100,100,3).astype(np.float32)+1j*np.random.rand(100,100,3).astype(np.float32)\n",
    "\n",
    "idx = np.random.choice(np.arange(100*100,dtype=np.int32),size=1000,replace=False)\n",
    "idx.sort()\n",
    "idx = np.stack(np.unravel_index(idx,shape=(100,100))).astype(np.int32)\n",
    "\n",
    "pc_data1 = ras_data1[idx[0],idx[1]]\n",
    "pc_data2 = ras_data2[idx[0],idx[1]]\n",
    "\n",
    "idx_zarr = zarr.open('pc/idx.zarr','w',shape=idx.shape,dtype=idx.dtype,chunks=(2,200))\n",
    "ras_zarr1 = zarr.open('pc/ras1.zarr','w',shape=ras_data1.shape,dtype=ras_data1.dtype,chunks=(20,100))\n",
    "ras_zarr2 = zarr.open('pc/ras2.zarr','w',shape=ras_data2.shape,dtype=ras_data2.dtype,chunks=(20,100,1))\n",
    "idx_zarr[:] = idx\n",
    "ras_zarr1[:] = ras_data1\n",
    "ras_zarr2[:] = ras_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5b5824-8365-4107-8088-76aad7304f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-13 23:26:53 - de_ras2pc - INFO - fetching args:\n",
      "2023-10-13 23:26:53 - de_ras2pc - INFO - idx = 'pc/idx.zarr'\n",
      "2023-10-13 23:26:53 - de_ras2pc - INFO - ras = 'pc/ras1.zarr'\n",
      "2023-10-13 23:26:53 - de_ras2pc - INFO - pc = 'pc/pc1.zarr'\n",
      "2023-10-13 23:26:53 - de_ras2pc - INFO - pc_chunk_size = None\n",
      "2023-10-13 23:26:53 - de_ras2pc - INFO - hd_chunk_size = None\n",
      "2023-10-13 23:26:53 - de_ras2pc - INFO - log = None\n",
      "2023-10-13 23:26:53 - de_ras2pc - INFO - fetching args done.\n",
      "2023-10-13 23:26:53 - de_ras2pc - INFO - pc/idx.zarr zarray shape: (2, 1000)\n",
      "2023-10-13 23:26:53 - de_ras2pc - INFO - pc/idx.zarr zarray chunks: (2, 200)\n",
      "2023-10-13 23:26:53 - de_ras2pc - INFO - pc/idx.zarr zarray dtype: int32\n",
      "2023-10-13 23:26:53 - de_ras2pc - INFO - no input pc_chunk_size, use pc_chunk_size as input idx\n",
      "2023-10-13 23:26:53 - de_ras2pc - INFO - pc_chunk_size: 200\n",
      "2023-10-13 23:26:53 - de_ras2pc - INFO - loading idx into memory.\n",
      "2023-10-13 23:26:53 - de_ras2pc - INFO - starting dask local cluster.\n",
      "2023-10-13 23:26:56 - de_ras2pc - INFO - dask local cluster started.\n",
      "2023-10-13 23:26:56 - de_ras2pc - INFO - start to slice on pc/ras1.zarr\n",
      "2023-10-13 23:26:56 - de_ras2pc - INFO - pc/ras1.zarr zarray shape: (100, 100)\n",
      "2023-10-13 23:26:56 - de_ras2pc - INFO - pc/ras1.zarr zarray chunks: (20, 100)\n",
      "2023-10-13 23:26:56 - de_ras2pc - INFO - pc/ras1.zarr zarray dtype: float32\n",
      "2023-10-13 23:26:56 - de_ras2pc - INFO - hd_chunk_size not setted. Use the one from pc/ras1.zarr.\n",
      "2023-10-13 23:26:56 - de_ras2pc - INFO - hd_chunk_size: ().\n",
      "2023-10-13 23:26:56 - de_ras2pc - INFO - ras dask array shape: (100, 100)\n",
      "2023-10-13 23:26:56 - de_ras2pc - INFO - ras dask array chunksize: (20, 100)\n",
      "2023-10-13 23:26:56 - de_ras2pc - INFO - ras dask array dtype: float32\n",
      "2023-10-13 23:26:56 - de_ras2pc - INFO - pc dask array shape: (1000,)\n",
      "2023-10-13 23:26:56 - de_ras2pc - INFO - pc dask array chunksize: (215,)\n",
      "2023-10-13 23:26:56 - de_ras2pc - INFO - pc dask array dtype: float32\n",
      "2023-10-13 23:26:56 - de_ras2pc - INFO - rechunk pc data:\n",
      "2023-10-13 23:26:56 - de_ras2pc - INFO - pc dask array shape: (1000,)\n",
      "2023-10-13 23:26:56 - de_ras2pc - INFO - pc dask array chunksize: (200,)\n",
      "2023-10-13 23:26:56 - de_ras2pc - INFO - pc dask array dtype: float32\n",
      "2023-10-13 23:26:56 - de_ras2pc - INFO - saving to pc/pc1.zarr.\n",
      "2023-10-13 23:26:56 - de_ras2pc - INFO - computing graph setted. doing all the computing.\n",
      "2023-10-13 23:26:57 - de_ras2pc - INFO - computing finished.\n",
      "2023-10-13 23:26:57 - de_ras2pc - INFO - dask cluster closed.\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - fetching args:\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - idx = 'pc/idx.zarr'\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - ras = 'pc/ras2.zarr'\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - pc = 'pc/pc2.zarr'\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - pc_chunk_size = None\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - hd_chunk_size = (1,)\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - log = None\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - fetching args done.\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - pc/idx.zarr zarray shape: (2, 1000)\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - pc/idx.zarr zarray chunks: (2, 200)\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - pc/idx.zarr zarray dtype: int32\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - no input pc_chunk_size, use pc_chunk_size as input idx\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - pc_chunk_size: 200\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - loading idx into memory.\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - pc/ras2.zarr zarray shape: (100, 100, 3)\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - pc/ras2.zarr zarray chunks: (20, 100, 1)\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - pc/ras2.zarr zarray dtype: complex64\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - hd_chunk_size: (1,).\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - loading pc/ras2.zarr into memory.\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - open pc/pc2.zarr zarr in write mode.\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - pc/pc2.zarr zarray shape: (1000, 3)\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - pc/pc2.zarr zarray chunks: (200, 1)\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - pc/pc2.zarr zarray dtype: complex64\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - slice raster data and write to pc/pc2.zarr.\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - write data to pc/pc2.zarr done.\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - fetching args:\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - idx = 'pc/idx.zarr'\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - ras = ['pc/ras1.zarr', 'pc/ras2.zarr']\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - pc = ['pc/pc1.zarr', 'pc/pc2.zarr']\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - pc_chunk_size = None\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - hd_chunk_size = [(), (1,)]\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - log = None\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - fetching args done.\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - pc/idx.zarr zarray shape: (2, 1000)\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - pc/idx.zarr zarray chunks: (2, 200)\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - pc/idx.zarr zarray dtype: int32\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - no input pc_chunk_size, use pc_chunk_size as input idx\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - pc_chunk_size: 200\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - loading idx into memory.\n",
      "2023-10-13 23:27:00 - de_ras2pc - INFO - starting dask local cluster.\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - dask local cluster started.\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - start to slice on pc/ras1.zarr\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - pc/ras1.zarr zarray shape: (100, 100)\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - pc/ras1.zarr zarray chunks: (20, 100)\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - pc/ras1.zarr zarray dtype: float32\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - hd_chunk_size: ().\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - ras dask array shape: (100, 100)\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - ras dask array chunksize: (20, 100)\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - ras dask array dtype: float32\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - pc dask array shape: (1000,)\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - pc dask array chunksize: (215,)\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - pc dask array dtype: float32\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - rechunk pc data:\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - pc dask array shape: (1000,)\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - pc dask array chunksize: (200,)\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - pc dask array dtype: float32\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - saving to pc/pc1.zarr.\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - start to slice on pc/ras2.zarr\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - pc/ras2.zarr zarray shape: (100, 100, 3)\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - pc/ras2.zarr zarray chunks: (20, 100, 1)\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - pc/ras2.zarr zarray dtype: complex64\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - hd_chunk_size: (1,).\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - ras dask array shape: (100, 100, 3)\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - ras dask array chunksize: (20, 100, 1)\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - ras dask array dtype: complex64\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - pc dask array shape: (1000, 3)\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - pc dask array chunksize: (215, 1)\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - pc dask array dtype: complex64\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - rechunk pc data:\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - pc dask array shape: (1000, 3)\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - pc dask array chunksize: (200, 1)\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - pc dask array dtype: complex64\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - saving to pc/pc2.zarr.\n",
      "2023-10-13 23:27:02 - de_ras2pc - INFO - computing graph setted. doing all the computing.\n",
      "2023-10-13 23:27:03 - de_ras2pc - INFO - computing finished.\n",
      "2023-10-13 23:27:03 - de_ras2pc - INFO - dask cluster closed.\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - fetching args:\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - idx = 'pc/idx.zarr'\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - ras = ['pc/ras1.zarr', 'pc/ras2.zarr']\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - pc = ['pc/pc1.zarr', 'pc/pc2.zarr']\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - pc_chunk_size = None\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - hd_chunk_size = [(), (1,)]\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - log = None\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - fetching args done.\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - pc/idx.zarr zarray shape: (2, 1000)\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - pc/idx.zarr zarray chunks: (2, 200)\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - pc/idx.zarr zarray dtype: int32\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - no input pc_chunk_size, use pc_chunk_size as input idx\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - pc_chunk_size: 200\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - loading idx into memory.\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - pc/ras1.zarr zarray shape: (100, 100)\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - pc/ras1.zarr zarray chunks: (20, 100)\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - pc/ras1.zarr zarray dtype: float32\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - hd_chunk_size: ().\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - loading pc/ras1.zarr into memory.\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - open pc/pc1.zarr zarr in write mode.\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - pc/pc1.zarr zarray shape: (1000,)\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - pc/pc1.zarr zarray chunks: (200,)\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - pc/pc1.zarr zarray dtype: float32\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - slice raster data and write to pc/pc1.zarr.\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - write data to pc/pc1.zarr done.\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - pc/ras2.zarr zarray shape: (100, 100, 3)\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - pc/ras2.zarr zarray chunks: (20, 100, 1)\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - pc/ras2.zarr zarray dtype: complex64\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - hd_chunk_size: (1,).\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - loading pc/ras2.zarr into memory.\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - open pc/pc2.zarr zarr in write mode.\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - pc/pc2.zarr zarray shape: (1000, 3)\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - pc/pc2.zarr zarray chunks: (200, 1)\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - pc/pc2.zarr zarray dtype: complex64\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - slice raster data and write to pc/pc2.zarr.\n",
      "2023-10-13 23:27:06 - de_ras2pc - INFO - write data to pc/pc2.zarr done.\n"
     ]
    }
   ],
   "source": [
    "de_ras2pc('pc/idx.zarr','pc/ras1.zarr','pc/pc1.zarr')\n",
    "pc_zarr1 = zarr.open('pc/pc1.zarr','r')\n",
    "np.testing.assert_array_equal(pc_data1,pc_zarr1[:])\n",
    "\n",
    "!de_ras2pc pc/idx.zarr --ras pc/ras2.zarr --pc pc/pc2.zarr --hd_chunk_size '1'\n",
    "pc_zarr2 = zarr.open('pc/pc2.zarr','r')\n",
    "np.testing.assert_array_equal(pc_data2,pc_zarr2[:])\n",
    "\n",
    "de_ras2pc('pc/idx.zarr',ras=['pc/ras1.zarr','pc/ras2.zarr'],pc=['pc/pc1.zarr','pc/pc2.zarr'],hd_chunk_size=[(),(1,)])\n",
    "pc_zarr1 = zarr.open('pc/pc1.zarr','r')\n",
    "pc_zarr2 = zarr.open('pc/pc2.zarr','r')\n",
    "np.testing.assert_array_equal(pc_data1,pc_zarr1[:])\n",
    "np.testing.assert_array_equal(pc_data2,pc_zarr2[:])\n",
    "\n",
    "!de_ras2pc pc/idx.zarr --ras pc/ras1.zarr pc/ras2.zarr --pc pc/pc1.zarr pc/pc2.zarr --hd_chunk_size '' '1'\n",
    "pc_zarr1 = zarr.open('pc/pc1.zarr','r')\n",
    "pc_zarr2 = zarr.open('pc/pc2.zarr','r')\n",
    "np.testing.assert_array_equal(pc_data1,pc_zarr1[:])\n",
    "np.testing.assert_array_equal(pc_data2,pc_zarr2[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbaeef3-786c-49d6-9e6b-d2617383f511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@log_args\n",
    "def de_pc2ras(idx:str, # point cloud index\n",
    "              pc:str|list, # path (in string) or list of path for point cloud data\n",
    "              ras:str|list, # output, path (in string) or list of path for raster data\n",
    "              shape:tuple, # shape of one image (nlines,width)\n",
    "              az_chunk_size:int=None, # output azimuth chunk size, only one chunk by default\n",
    "              log:str=None, # log file. Default: no log file\n",
    "):\n",
    "    '''Convert point cloud data to raster data, filled with nan'''\n",
    "    # I find there is no need to set this hd_chunk_size, generally we do not need it\n",
    "    logger = get_logger(logfile=log)\n",
    "\n",
    "    idx_zarr = zarr.open(idx,mode='r')\n",
    "    logger.info('idx dataset shape: '+str(idx_zarr.shape))\n",
    "    logger.info('idx dataset chunks: '+str(idx_zarr.chunks))\n",
    "    assert idx_zarr.ndim == 2, \"idx dimentation is not 2.\"\n",
    "    if not az_chunk_size:\n",
    "        az_chunk_size = shape[0]\n",
    "        logger.info('no input az_chunk_size, use only one chunk.')\n",
    "    logger.info(f'az_chunk_size: {az_chunk_size}')\n",
    "\n",
    "    logger.info('loading idx into memory.')\n",
    "    idx = zarr.open(idx,mode='r')[:]\n",
    "    n_pc = idx.shape[1]\n",
    "    \n",
    "    if isinstance(pc,str):\n",
    "        assert isinstance(ras,str)\n",
    "        pc_list = [pc]\n",
    "        ras_list = [ras]\n",
    "    else:\n",
    "        assert isinstance(pc,list)\n",
    "        assert isinstance(ras,list)\n",
    "        pc_list = pc\n",
    "        ras_list = ras\n",
    "        n_data = len(pc_list)\n",
    "\n",
    "    logger.info('starting dask local cluster.')\n",
    "    cluster = LocalCluster()\n",
    "    client = Client(cluster)\n",
    "    logger.info('dask local cluster started.')\n",
    "\n",
    "    _ras_list = ()\n",
    "\n",
    "    for ras_path, pc_path in zip(ras_list,pc_list):\n",
    "        logger.info(f'start to work on {pc_path}')\n",
    "        pc_zarr = zarr.open(pc_path,'r')\n",
    "        logger.zarr_info(pc_path,pc_zarr)\n",
    "        \n",
    "        pc = da.from_zarr(pc_path)\n",
    "        logger.darr_info('pc', pc)\n",
    "        ras = da.empty((shape[0]*shape[1],*pc.shape[1:]),chunks = (az_chunk_size*shape[1],*pc_zarr.chunks[1:]), dtype=pc.dtype)\n",
    "        ras[:] = np.nan\n",
    "        ras[np.ravel_multi_index((idx[0],idx[1]),dims=shape)] = pc\n",
    "        ras = ras.reshape(*shape,*pc.shape[1:])\n",
    "        logger.info('create ras dask array')\n",
    "        logger.darr_info('ras', ras)\n",
    "        _ras = ras.to_zarr(ras_path,overwrite=True,compute=False)\n",
    "        _ras_list += (_ras,)\n",
    "\n",
    "    logger.info('computing graph setted. doing all the computing.')\n",
    "    da.compute(*_ras_list)\n",
    "\n",
    "    logger.info('computing finished.')\n",
    "    cluster.close()\n",
    "    logger.info('dask cluster closed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0420061b-1fad-4150-9c6b-e11665e37c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@call_parse\n",
    "def console_de_pc2ras(idx:str, # point cloud index\n",
    "                      pc:Param(type=str,required=True,nargs='+',help='one or more path for point cloud data')=None,\n",
    "                      ras:Param(type=str,required=True,nargs='+',help='output, one or more path for raster data')=None,\n",
    "                      shape:Param(type=str,required=True,help='shape of one image \"nlines,width\"')=None,\n",
    "                      az_chunk_size:int=None, # output azimuth chunk size, only one chunk by default\n",
    "                      log:str=None, # log file. Default: no log file\n",
    "):\n",
    "    '''Convert point cloud data to raster data'''\n",
    "    if len(ras)==1:\n",
    "        ras = ras[0]\n",
    "        pc = pc[0]\n",
    "    \n",
    "    shape = shape.split(',')\n",
    "    shape = [int(i) for i in shape]\n",
    "    shape=tuple(shape)\n",
    "\n",
    "    de_pc2ras(idx,pc,ras,shape,az_chunk_size,log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b9b586-35bf-41b4-b5b0-7d4a4e70233e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: de_pc2ras [-h] --pc PC [PC ...] --ras RAS [RAS ...] --shape SHAPE\n",
      "                 [--az_chunk_size AZ_CHUNK_SIZE] [--log LOG]\n",
      "                 idx\n",
      "\n",
      "Convert point cloud data to raster data\n",
      "\n",
      "positional arguments:\n",
      "  idx                            point cloud index\n",
      "\n",
      "options:\n",
      "  -h, --help                     show this help message and exit\n",
      "  --pc PC [PC ...]               one or more path for point cloud data\n",
      "  --ras RAS [RAS ...]            output, one or more path for raster data\n",
      "  --shape SHAPE                  shape of one image \"nlines,width\"\n",
      "  --az_chunk_size AZ_CHUNK_SIZE  output azimuth chunk size, only one chunk by\n",
      "                                 default\n",
      "  --log LOG                      log file. Default: no log file\n"
     ]
    }
   ],
   "source": [
    "!de_pc2ras -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f998e06-f4f2-4d2a-816b-c6ca8b5c8492",
   "metadata": {},
   "source": [
    "Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff5e158-5b51-4182-bc09-10481e605d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_data1 = np.random.rand(1000).astype(np.float32)\n",
    "pc_data2 = np.random.rand(1000,3).astype(np.float32)+1j*np.random.rand(1000,3).astype(np.float32)\n",
    "\n",
    "idx = np.random.randint(0,100*100,size=1000,dtype=np.int32)\n",
    "idx.sort()\n",
    "idx = np.stack(np.unravel_index(idx,shape=(100,100)))\n",
    "\n",
    "ras_data1 = np.zeros((100,100),dtype=np.float32)\n",
    "ras_data2 = np.zeros((100,100,3),dtype=np.complex64)\n",
    "ras_data1[:] = np.nan\n",
    "ras_data2[:] = np.nan\n",
    "\n",
    "ras_data1[idx[0],idx[1]] = pc_data1\n",
    "ras_data2[idx[0],idx[1]] = pc_data2\n",
    "\n",
    "idx_zarr = zarr.open('pc/idx.zarr','w',shape=idx.shape,dtype=idx.dtype,chunks=(2,200))\n",
    "pc_zarr1 = zarr.open('pc/pc1.zarr','w',shape=pc_data1.shape,dtype=pc_data1.dtype,chunks=(200,))\n",
    "pc_zarr2 = zarr.open('pc/pc2.zarr','w',shape=pc_data2.shape,dtype=pc_data2.dtype,chunks=(200,1))\n",
    "idx_zarr[:] = idx\n",
    "pc_zarr1[:] = pc_data1\n",
    "pc_zarr2[:] = pc_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd20483b-d3b2-4351-a650-da1777f5ae1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-13 23:27:10 - de_pc2ras - INFO - fetching args:\n",
      "2023-10-13 23:27:10 - de_pc2ras - INFO - idx = 'pc/idx.zarr'\n",
      "2023-10-13 23:27:10 - de_pc2ras - INFO - pc = 'pc/pc1.zarr'\n",
      "2023-10-13 23:27:10 - de_pc2ras - INFO - ras = 'pc/ras1.zarr'\n",
      "2023-10-13 23:27:10 - de_pc2ras - INFO - shape = (100, 100)\n",
      "2023-10-13 23:27:10 - de_pc2ras - INFO - az_chunk_size = 20\n",
      "2023-10-13 23:27:10 - de_pc2ras - INFO - log = None\n",
      "2023-10-13 23:27:10 - de_pc2ras - INFO - fetching args done.\n",
      "2023-10-13 23:27:10 - de_pc2ras - INFO - idx dataset shape: (2, 1000)\n",
      "2023-10-13 23:27:10 - de_pc2ras - INFO - idx dataset chunks: (2, 200)\n",
      "2023-10-13 23:27:10 - de_pc2ras - INFO - az_chunk_size: 20\n",
      "2023-10-13 23:27:10 - de_pc2ras - INFO - loading idx into memory.\n",
      "2023-10-13 23:27:10 - de_pc2ras - INFO - starting dask local cluster.\n",
      "2023-10-13 23:27:12 - de_pc2ras - INFO - dask local cluster started.\n",
      "2023-10-13 23:27:12 - de_pc2ras - INFO - start to work on pc/pc1.zarr\n",
      "2023-10-13 23:27:12 - de_pc2ras - INFO - pc/pc1.zarr zarray shape: (1000,)\n",
      "2023-10-13 23:27:12 - de_pc2ras - INFO - pc/pc1.zarr zarray chunks: (200,)\n",
      "2023-10-13 23:27:12 - de_pc2ras - INFO - pc/pc1.zarr zarray dtype: float32\n",
      "2023-10-13 23:27:12 - de_pc2ras - INFO - pc dask array shape: (1000,)\n",
      "2023-10-13 23:27:12 - de_pc2ras - INFO - pc dask array chunksize: (200,)\n",
      "2023-10-13 23:27:12 - de_pc2ras - INFO - pc dask array dtype: float32\n",
      "2023-10-13 23:27:12 - de_pc2ras - INFO - create ras dask array\n",
      "2023-10-13 23:27:12 - de_pc2ras - INFO - ras dask array shape: (100, 100)\n",
      "2023-10-13 23:27:12 - de_pc2ras - INFO - ras dask array chunksize: (20, 100)\n",
      "2023-10-13 23:27:12 - de_pc2ras - INFO - ras dask array dtype: float32\n",
      "2023-10-13 23:27:12 - de_pc2ras - INFO - computing graph setted. doing all the computing.\n",
      "2023-10-13 23:27:13 - de_pc2ras - INFO - computing finished.\n",
      "2023-10-13 23:27:13 - de_pc2ras - INFO - dask cluster closed.\n",
      "2023-10-13 23:27:16 - de_pc2ras - INFO - fetching args:\n",
      "2023-10-13 23:27:16 - de_pc2ras - INFO - idx = 'pc/idx.zarr/'\n",
      "2023-10-13 23:27:16 - de_pc2ras - INFO - pc = 'pc/pc2.zarr/'\n",
      "2023-10-13 23:27:16 - de_pc2ras - INFO - ras = 'pc/ras2.zarr/'\n",
      "2023-10-13 23:27:16 - de_pc2ras - INFO - shape = (100, 100)\n",
      "2023-10-13 23:27:16 - de_pc2ras - INFO - az_chunk_size = 20\n",
      "2023-10-13 23:27:16 - de_pc2ras - INFO - log = None\n",
      "2023-10-13 23:27:16 - de_pc2ras - INFO - fetching args done.\n",
      "2023-10-13 23:27:16 - de_pc2ras - INFO - idx dataset shape: (2, 1000)\n",
      "2023-10-13 23:27:16 - de_pc2ras - INFO - idx dataset chunks: (2, 200)\n",
      "2023-10-13 23:27:16 - de_pc2ras - INFO - az_chunk_size: 20\n",
      "2023-10-13 23:27:16 - de_pc2ras - INFO - loading idx into memory.\n",
      "2023-10-13 23:27:16 - de_pc2ras - INFO - pc/pc2.zarr/ dataset shape: (1000, 3)\n",
      "2023-10-13 23:27:16 - de_pc2ras - INFO - pc/pc2.zarr/ dataset chunks: (200, 1)\n",
      "2023-10-13 23:27:16 - de_pc2ras - INFO - loading pc/pc2.zarr/ into memory.\n",
      "2023-10-13 23:27:16 - de_pc2ras - INFO - open pc/ras2.zarr/ zarr in write mode.\n",
      "2023-10-13 23:27:16 - de_pc2ras - INFO - pc/ras2.zarr/ dataset shape: (100, 100, 3)\n",
      "2023-10-13 23:27:16 - de_pc2ras - INFO - pc/ras2.zarr/ dataset chunks: (20, 100, 1)\n",
      "2023-10-13 23:27:16 - de_pc2ras - INFO - write to pc/ras2.zarr/.\n",
      "2023-10-13 23:27:16 - de_pc2ras - INFO - write data to pc/ras2.zarr/ done.\n",
      "2023-10-13 23:27:17 - de_pc2ras - INFO - fetching args:\n",
      "2023-10-13 23:27:17 - de_pc2ras - INFO - idx = 'pc/idx.zarr'\n",
      "2023-10-13 23:27:17 - de_pc2ras - INFO - pc = ['pc/pc1.zarr', 'pc/pc2.zarr']\n",
      "2023-10-13 23:27:17 - de_pc2ras - INFO - ras = ['pc/ras1.zarr', 'pc/ras2.zarr']\n",
      "2023-10-13 23:27:17 - de_pc2ras - INFO - shape = (100, 100)\n",
      "2023-10-13 23:27:17 - de_pc2ras - INFO - az_chunk_size = 20\n",
      "2023-10-13 23:27:17 - de_pc2ras - INFO - log = None\n",
      "2023-10-13 23:27:17 - de_pc2ras - INFO - fetching args done.\n",
      "2023-10-13 23:27:17 - de_pc2ras - INFO - idx dataset shape: (2, 1000)\n",
      "2023-10-13 23:27:17 - de_pc2ras - INFO - idx dataset chunks: (2, 200)\n",
      "2023-10-13 23:27:17 - de_pc2ras - INFO - az_chunk_size: 20\n",
      "2023-10-13 23:27:17 - de_pc2ras - INFO - loading idx into memory.\n",
      "2023-10-13 23:27:17 - de_pc2ras - INFO - starting dask local cluster.\n",
      "2023-10-13 23:27:18 - de_pc2ras - INFO - dask local cluster started.\n",
      "2023-10-13 23:27:18 - de_pc2ras - INFO - start to work on pc/pc1.zarr\n",
      "2023-10-13 23:27:18 - de_pc2ras - INFO - pc/pc1.zarr zarray shape: (1000,)\n",
      "2023-10-13 23:27:18 - de_pc2ras - INFO - pc/pc1.zarr zarray chunks: (200,)\n",
      "2023-10-13 23:27:18 - de_pc2ras - INFO - pc/pc1.zarr zarray dtype: float32\n",
      "2023-10-13 23:27:18 - de_pc2ras - INFO - pc dask array shape: (1000,)\n",
      "2023-10-13 23:27:18 - de_pc2ras - INFO - pc dask array chunksize: (200,)\n",
      "2023-10-13 23:27:18 - de_pc2ras - INFO - pc dask array dtype: float32\n",
      "2023-10-13 23:27:18 - de_pc2ras - INFO - create ras dask array\n",
      "2023-10-13 23:27:18 - de_pc2ras - INFO - ras dask array shape: (100, 100)\n",
      "2023-10-13 23:27:18 - de_pc2ras - INFO - ras dask array chunksize: (20, 100)\n",
      "2023-10-13 23:27:18 - de_pc2ras - INFO - ras dask array dtype: float32\n",
      "2023-10-13 23:27:18 - de_pc2ras - INFO - start to work on pc/pc2.zarr\n",
      "2023-10-13 23:27:18 - de_pc2ras - INFO - pc/pc2.zarr zarray shape: (1000, 3)\n",
      "2023-10-13 23:27:18 - de_pc2ras - INFO - pc/pc2.zarr zarray chunks: (200, 1)\n",
      "2023-10-13 23:27:18 - de_pc2ras - INFO - pc/pc2.zarr zarray dtype: complex64\n",
      "2023-10-13 23:27:18 - de_pc2ras - INFO - pc dask array shape: (1000, 3)\n",
      "2023-10-13 23:27:18 - de_pc2ras - INFO - pc dask array chunksize: (200, 1)\n",
      "2023-10-13 23:27:18 - de_pc2ras - INFO - pc dask array dtype: complex64\n",
      "2023-10-13 23:27:18 - de_pc2ras - INFO - create ras dask array\n",
      "2023-10-13 23:27:18 - de_pc2ras - INFO - ras dask array shape: (100, 100, 3)\n",
      "2023-10-13 23:27:18 - de_pc2ras - INFO - ras dask array chunksize: (20, 100, 1)\n",
      "2023-10-13 23:27:18 - de_pc2ras - INFO - ras dask array dtype: complex64\n",
      "2023-10-13 23:27:18 - de_pc2ras - INFO - computing graph setted. doing all the computing.\n",
      "2023-10-13 23:27:19 - de_pc2ras - INFO - computing finished.\n",
      "2023-10-13 23:27:20 - de_pc2ras - INFO - dask cluster closed.\n",
      "2023-10-13 23:27:22 - de_pc2ras - INFO - fetching args:\n",
      "2023-10-13 23:27:22 - de_pc2ras - INFO - idx = 'pc/idx.zarr/'\n",
      "2023-10-13 23:27:22 - de_pc2ras - INFO - pc = ['pc/pc1.zarr/', 'pc/pc2.zarr/']\n",
      "2023-10-13 23:27:22 - de_pc2ras - INFO - ras = ['pc/ras1.zarr/', 'pc/ras2.zarr/']\n",
      "2023-10-13 23:27:22 - de_pc2ras - INFO - shape = (100, 100)\n",
      "2023-10-13 23:27:22 - de_pc2ras - INFO - az_chunk_size = 20\n",
      "2023-10-13 23:27:22 - de_pc2ras - INFO - log = None\n",
      "2023-10-13 23:27:22 - de_pc2ras - INFO - fetching args done.\n",
      "2023-10-13 23:27:22 - de_pc2ras - INFO - idx dataset shape: (2, 1000)\n",
      "2023-10-13 23:27:22 - de_pc2ras - INFO - idx dataset chunks: (2, 200)\n",
      "2023-10-13 23:27:22 - de_pc2ras - INFO - az_chunk_size: 20\n",
      "2023-10-13 23:27:22 - de_pc2ras - INFO - loading idx into memory.\n",
      "2023-10-13 23:27:22 - de_pc2ras - INFO - pc/pc1.zarr/ dataset shape: (1000,)\n",
      "2023-10-13 23:27:22 - de_pc2ras - INFO - pc/pc1.zarr/ dataset chunks: (200,)\n",
      "2023-10-13 23:27:22 - de_pc2ras - INFO - loading pc/pc1.zarr/ into memory.\n",
      "2023-10-13 23:27:22 - de_pc2ras - INFO - open pc/ras1.zarr/ zarr in write mode.\n",
      "2023-10-13 23:27:22 - de_pc2ras - INFO - pc/ras1.zarr/ dataset shape: (100, 100)\n",
      "2023-10-13 23:27:22 - de_pc2ras - INFO - pc/ras1.zarr/ dataset chunks: (20, 100)\n",
      "2023-10-13 23:27:22 - de_pc2ras - INFO - write to pc/ras1.zarr/.\n",
      "2023-10-13 23:27:22 - de_pc2ras - INFO - write data to pc/ras1.zarr/ done.\n",
      "2023-10-13 23:27:22 - de_pc2ras - INFO - pc/pc2.zarr/ dataset shape: (1000, 3)\n",
      "2023-10-13 23:27:22 - de_pc2ras - INFO - pc/pc2.zarr/ dataset chunks: (200, 1)\n",
      "2023-10-13 23:27:22 - de_pc2ras - INFO - loading pc/pc2.zarr/ into memory.\n",
      "2023-10-13 23:27:22 - de_pc2ras - INFO - open pc/ras2.zarr/ zarr in write mode.\n",
      "2023-10-13 23:27:22 - de_pc2ras - INFO - pc/ras2.zarr/ dataset shape: (100, 100, 3)\n",
      "2023-10-13 23:27:22 - de_pc2ras - INFO - pc/ras2.zarr/ dataset chunks: (20, 100, 1)\n",
      "2023-10-13 23:27:22 - de_pc2ras - INFO - write to pc/ras2.zarr/.\n",
      "2023-10-13 23:27:22 - de_pc2ras - INFO - write data to pc/ras2.zarr/ done.\n"
     ]
    }
   ],
   "source": [
    "de_pc2ras('pc/idx.zarr','pc/pc1.zarr','pc/ras1.zarr',shape=(100,100),az_chunk_size=20)\n",
    "ras_zarr1 = zarr.open('pc/ras1.zarr','r')\n",
    "np.testing.assert_array_equal(ras_data1,ras_zarr1[:])\n",
    "\n",
    "!de_pc2ras pc/idx.zarr/ --pc pc/pc2.zarr/ --ras pc/ras2.zarr/ --shape \"100,100\" --az_chunk_size 20\n",
    "ras_zarr2 = zarr.open('pc/ras2.zarr','r')\n",
    "np.testing.assert_array_equal(ras_data2,ras_zarr2[:])\n",
    "\n",
    "de_pc2ras('pc/idx.zarr',['pc/pc1.zarr','pc/pc2.zarr'],['pc/ras1.zarr','pc/ras2.zarr'],shape=(100,100),az_chunk_size=20)\n",
    "ras_zarr1 = zarr.open('pc/ras1.zarr','r')\n",
    "ras_zarr2 = zarr.open('pc/ras2.zarr','r')\n",
    "np.testing.assert_array_equal(ras_data1,ras_zarr1[:])\n",
    "np.testing.assert_array_equal(ras_data2,ras_zarr2[:])\n",
    "\n",
    "!de_pc2ras pc/idx.zarr/ --pc pc/pc1.zarr/ pc/pc2.zarr/ --ras pc/ras1.zarr/ pc/ras2.zarr/ --shape \"100,100\" --az_chunk_size 20\n",
    "ras_zarr1 = zarr.open('pc/ras1.zarr','r')\n",
    "ras_zarr2 = zarr.open('pc/ras2.zarr','r')\n",
    "np.testing.assert_array_equal(ras_data1,ras_zarr1[:])\n",
    "np.testing.assert_array_equal(ras_data2,ras_zarr2[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bae521-e1b0-4b4d-82eb-699964597b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@log_args\n",
    "def de_pc_union(idx1:str, # index of the first point cloud\n",
    "                idx2:str, # index of the second point cloud\n",
    "                idx:str, # output, index of the union point cloud\n",
    "                pc1:str|list=None, # path (in string) or list of path for the first point cloud data\n",
    "                pc2:str|list=None, # path (in string) or list of path for the second point cloud data\n",
    "                pc:str|list=None, #output, path (in string) or list of path for the union point cloud data\n",
    "                pc_chunk_size:int=None, # chunk size in output data,optional\n",
    "                n_pc_chunk:int=None, # number of chunk in output data, optional, only one chunk if both pc_chunk_size and n_pc_chunk are not set.\n",
    "                log:str=None, # log file. Default: no log file\n",
    "):\n",
    "    '''Get the union of two point cloud dataset. For points at their intersection, pc_data1 rather than pc_data2 is copied to the result pc_data.'''\n",
    "    # I find there is no need to set this hd_chunk_size, generally we do not need it\n",
    "    logger = get_logger(logfile=log)\n",
    "\n",
    "    idx_zarr = zarr.open(idx,mode='r')\n",
    "    logger.info('idx dataset shape: '+str(idx_zarr.shape))\n",
    "    logger.info('idx dataset chunks: '+str(idx_zarr.chunks))\n",
    "    assert idx_zarr.ndim == 2, \"idx dimentation is not 2.\"\n",
    "    if not az_chunk_size:\n",
    "        az_chunk_size = shape[0]\n",
    "        logger.info('no input az_chunk_size, use only one chunk.')\n",
    "    logger.info(f'az_chunk_size: {az_chunk_size}')\n",
    "\n",
    "    logger.info('loading idx into memory.')\n",
    "    idx = idx_zarr[:]\n",
    "    n_pc = idx.shape[1]\n",
    "    \n",
    "    if isinstance(pc,str):\n",
    "        assert isinstance(ras,str)\n",
    "        pc_list = [pc]\n",
    "        ras_list = [ras]\n",
    "    else:\n",
    "        assert isinstance(pc,list)\n",
    "        assert isinstance(ras,list)\n",
    "        pc_list = pc\n",
    "        ras_list = ras\n",
    "        n_data = len(pc_list)\n",
    "\n",
    "    for ras_path, pc_path in zip(ras_list,pc_list):\n",
    "        pc_zarr = zarr.open(pc_path,'r')\n",
    "        logger.info(f'{pc_path} dataset shape: '+str(pc_zarr.shape))\n",
    "        logger.info(f'{pc_path} dataset chunks: '+str(pc_zarr.chunks))\n",
    "\n",
    "        logger.info(f'loading {pc_path} into memory.')\n",
    "        pc_data = pc_zarr[:]\n",
    "\n",
    "        logger.info(f'open {ras_path} zarr in write mode.')\n",
    "        ras_zarr = zarr.open(ras_path,'w',shape=(*shape,*pc_data.shape[1:]),dtype=pc_data.dtype,chunks=(az_chunk_size,shape[1],*pc_zarr.chunks[1:]))\n",
    "        logger.info(f'{ras_path} dataset shape: '+str(ras_zarr.shape))\n",
    "        logger.info(f'{ras_path} dataset chunks: '+str(ras_zarr.chunks))\n",
    "        logger.info(f'write to {ras_path}.')\n",
    "        ras_zarr[:] = pc2ras(idx,pc_data,shape)\n",
    "        logger.info(f'write data to {ras_path} done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e165db47-38a1-4ce9-870f-4d27f79bd848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@log_args\n",
    "def de_pc_intersect(idx:str, # point cloud index\n",
    "              pc:str|list, # path (in string) or list of path for point cloud data\n",
    "              ras:str|list, # output, path (in string) or list of path for raster data\n",
    "              shape:tuple, # shape of one image (nlines,width)\n",
    "              az_chunk_size:int=None, # output azimuth chunk size, only one chunk by default\n",
    "              log:str=None, # log file. Default: no log file\n",
    "):\n",
    "    '''Convert point cloud data to raster data, filled with nan'''\n",
    "    # I find there is no need to set this hd_chunk_size, generally we do not need it\n",
    "    logger = get_logger(logfile=log)\n",
    "\n",
    "    idx_zarr = zarr.open(idx,mode='r')\n",
    "    logger.info('idx dataset shape: '+str(idx_zarr.shape))\n",
    "    logger.info('idx dataset chunks: '+str(idx_zarr.chunks))\n",
    "    assert idx_zarr.ndim == 2, \"idx dimentation is not 2.\"\n",
    "    if not az_chunk_size:\n",
    "        az_chunk_size = shape[0]\n",
    "        logger.info('no input az_chunk_size, use only one chunk.')\n",
    "    logger.info(f'az_chunk_size: {az_chunk_size}')\n",
    "\n",
    "    logger.info('loading idx into memory.')\n",
    "    idx = zarr.open(idx,mode='r')[:]\n",
    "    n_pc = idx.shape[1]\n",
    "    \n",
    "    if isinstance(pc,str):\n",
    "        assert isinstance(ras,str)\n",
    "        pc_list = [pc]\n",
    "        ras_list = [ras]\n",
    "    else:\n",
    "        assert isinstance(pc,list)\n",
    "        assert isinstance(ras,list)\n",
    "        pc_list = pc\n",
    "        ras_list = ras\n",
    "        n_data = len(pc_list)\n",
    "\n",
    "    for ras_path, pc_path in zip(ras_list,pc_list):\n",
    "        pc_zarr = zarr.open(pc_path,'r')\n",
    "        logger.info(f'{pc_path} dataset shape: '+str(pc_zarr.shape))\n",
    "        logger.info(f'{pc_path} dataset chunks: '+str(pc_zarr.chunks))\n",
    "\n",
    "        logger.info(f'loading {pc_path} into memory.')\n",
    "        pc_data = pc_zarr[:]\n",
    "\n",
    "        logger.info(f'open {ras_path} zarr in write mode.')\n",
    "        ras_zarr = zarr.open(ras_path,'w',shape=(*shape,*pc_data.shape[1:]),dtype=pc_data.dtype,chunks=(az_chunk_size,shape[1],*pc_zarr.chunks[1:]))\n",
    "        logger.info(f'{ras_path} dataset shape: '+str(ras_zarr.shape))\n",
    "        logger.info(f'{ras_path} dataset chunks: '+str(ras_zarr.chunks))\n",
    "        logger.info(f'write to {ras_path}.')\n",
    "        ras_zarr[:] = pc2ras(idx,pc_data,shape)\n",
    "        logger.info(f'write data to {ras_path} done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6709657-ac69-48d5-8c89-72a42cc19939",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@log_args\n",
    "def de_pc_diff(idx:str, # point cloud index\n",
    "              pc:str|list, # path (in string) or list of path for point cloud data\n",
    "              ras:str|list, # output, path (in string) or list of path for raster data\n",
    "              shape:tuple, # shape of one image (nlines,width)\n",
    "              az_chunk_size:int=None, # output azimuth chunk size, only one chunk by default\n",
    "              log:str=None, # log file. Default: no log file\n",
    "):\n",
    "    '''Convert point cloud data to raster data, filled with nan'''\n",
    "    # I find there is no need to set this hd_chunk_size, generally we do not need it\n",
    "    logger = get_logger(logfile=log)\n",
    "\n",
    "    idx_zarr = zarr.open(idx,mode='r')\n",
    "    logger.info('idx dataset shape: '+str(idx_zarr.shape))\n",
    "    logger.info('idx dataset chunks: '+str(idx_zarr.chunks))\n",
    "    assert idx_zarr.ndim == 2, \"idx dimentation is not 2.\"\n",
    "    if not az_chunk_size:\n",
    "        az_chunk_size = shape[0]\n",
    "        logger.info('no input az_chunk_size, use only one chunk.')\n",
    "    logger.info(f'az_chunk_size: {az_chunk_size}')\n",
    "\n",
    "    logger.info('loading idx into memory.')\n",
    "    idx = zarr.open(idx,mode='r')[:]\n",
    "    n_pc = idx.shape[1]\n",
    "    \n",
    "    if isinstance(pc,str):\n",
    "        assert isinstance(ras,str)\n",
    "        pc_list = [pc]\n",
    "        ras_list = [ras]\n",
    "    else:\n",
    "        assert isinstance(pc,list)\n",
    "        assert isinstance(ras,list)\n",
    "        pc_list = pc\n",
    "        ras_list = ras\n",
    "        n_data = len(pc_list)\n",
    "\n",
    "    for ras_path, pc_path in zip(ras_list,pc_list):\n",
    "        pc_zarr = zarr.open(pc_path,'r')\n",
    "        logger.info(f'{pc_path} dataset shape: '+str(pc_zarr.shape))\n",
    "        logger.info(f'{pc_path} dataset chunks: '+str(pc_zarr.chunks))\n",
    "\n",
    "        logger.info(f'loading {pc_path} into memory.')\n",
    "        pc_data = pc_zarr[:]\n",
    "\n",
    "        logger.info(f'open {ras_path} zarr in write mode.')\n",
    "        ras_zarr = zarr.open(ras_path,'w',shape=(*shape,*pc_data.shape[1:]),dtype=pc_data.dtype,chunks=(az_chunk_size,shape[1],*pc_zarr.chunks[1:]))\n",
    "        logger.info(f'{ras_path} dataset shape: '+str(ras_zarr.shape))\n",
    "        logger.info(f'{ras_path} dataset chunks: '+str(ras_zarr.chunks))\n",
    "        logger.info(f'write to {ras_path}.')\n",
    "        ras_zarr[:] = pc2ras(idx,pc_data,shape)\n",
    "        logger.info(f'write data to {ras_path} done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50eda76-1cf8-4fb7-9f5a-df8af874e97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3474c7-05b2-4147-8a8f-a313e81e5c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:work]",
   "language": "python",
   "name": "conda-env-work-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
