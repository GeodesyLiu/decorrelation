[
  {
    "objectID": "API/shp.html",
    "href": "API/shp.html",
    "title": "shp",
    "section": "",
    "text": "from scipy import stats\nimport numpy as np\nimport itertools"
  },
  {
    "objectID": "API/shp.html#kolmogorov-smirnov-ks-two-sample-test",
    "href": "API/shp.html#kolmogorov-smirnov-ks-two-sample-test",
    "title": "shp",
    "section": "Kolmogorov-Smirnov (KS) two-sample test",
    "text": "Kolmogorov-Smirnov (KS) two-sample test\n\nsource\n\nks_test\n\n ks_test (rmli:cupy.ndarray, az_half_win:int, r_half_win:int,\n          block_size:int=128)\n\nSHP identification based on Two-Sample Kolmogorov-Smirnov Test.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nrmli\nndarray\n\nthe rmli stack, dtype: cupy.floating\n\n\naz_half_win\nint\n\nSHP identification half search window size in azimuth direction\n\n\nr_half_win\nint\n\nSHP identification half search window size in range direction\n\n\nblock_size\nint\n128\nthe CUDA block size, it only affects the calculation speed\n\n\nReturns\ntuple\n\nthe KS test statistics dist and p value p\n\n\n\nThe ks_test function apply the Two-Sample Kolmogorov-Smirnov Test on a stack of rmli images to identify SHPs candidate for further processing. This method is originally published in [@ferrettiNewAlgorithmProcessing2011]. This function is designed to run on GPU for high speed.\nThe rmli is a three dimentional cupy ndarray. The dtype should be float. From outerest to innerest, the three dimentions are azimuth, range and image. For each pixel P, a search window centered at P is defined by az_half_win and r_half_win. All pixels in this search window is compared with P by KS test. They are refered here as secondary pixels. The total number of secondary pixels (including P) is (2*az_half_win+1)*(2*r_half_win+1).\nThe returns are the ks test statistic which is the maximum value of the absolute difference between the emperical cumulative distribution functions of the two samples, and p value. Both of them are 4 dimentional cupy ndarrays. From outerest ot innerest, they are azimuth, range, secondary pixel relative azimuth, secondary pixel relative range. For P at the corner of the image where part of the search window is out of the image, the result is -1.\nHere is a simplest example. First simulate rmli time series of two pixels from two correlated normal distributions:\n\nsample_size = 20\nrng = np.random.default_rng()\nsample1 = stats.uniform.rvs(size=sample_size, random_state=rng).astype(cp.float32)\nsample2 = stats.norm.rvs(size=sample_size, random_state=rng).astype(cp.float32)\n\nConvert the data to cupy ndarray and make sure the dtype is cp.float32 and the data are sorted:\n\nrmli_stack = cp.stack((cp.asarray(sample1), cp.asarray(sample2))).reshape(1,2,sample_size)\nrmli_stack = rmli_stack.astype(cp.float32)\nrmli_stack.shape\n\n(1, 2, 20)\n\n\nThe shape of rmli_stack shows it contains 20 images. Each of the image has 1 pixel in azimuth dimention and 2 pixels in range dimention. Set the az_half_win and r_half_win to 1 and apply the ks_test function:\n\ndist,p = ks_test(rmli_stack,1,1)\nprint(dist.shape)\nprint(dist)\n\n(1, 2, 3, 3)\n[[[[-1.  -1.  -1. ]\n   [-1.   0.   0.6]\n   [-1.  -1.  -1. ]]\n\n  [[-1.  -1.  -1. ]\n   [ 0.6  0.  -1. ]\n   [-1.  -1.  -1. ]]]]\n\n\ndist is the ks test statistic. The shape of it shows for each pixel P in this 1*2 image, a 3*3 search window is defined and all pixels in this search window is test with P. The value 0 in dist is the ks test result of pixel P and pixel P itself. The value -1 means the secondary pixel is out of the image and no ks test is applied.\n\nprint(p.shape)\nprint(p)\n\n(1, 2, 3, 3)\n[[[[-1.0000000e+00 -1.0000000e+00 -1.0000000e+00]\n   [-1.0000000e+00  0.0000000e+00  7.2528544e-04]\n   [-1.0000000e+00 -1.0000000e+00 -1.0000000e+00]]\n\n  [[-1.0000000e+00 -1.0000000e+00 -1.0000000e+00]\n   [ 7.2528544e-04  0.0000000e+00 -1.0000000e+00]\n   [-1.0000000e+00 -1.0000000e+00 -1.0000000e+00]]]]\n\n\np is the ks test p value with same shape of dist.\n\nprint(stats.ks_2samp(sample1, sample2,method='asymp'))\n\nKstestResult(statistic=0.6, pvalue=0.0005681672000000003, statistic_location=-0.12029845, statistic_sign=-1)\n\n\nBy comparing the result of ks_test and ks_2samp from scipy, the statistics are same which prove the correctness of ks_test. The difference in p value is because the approcimation method used are different but the orders of magnitudes are consistent."
  },
  {
    "objectID": "API/plot.html",
    "href": "API/plot.html",
    "title": "Plot",
    "section": "",
    "text": "source\n\nbg_alpha\n\n bg_alpha (pwr)"
  },
  {
    "objectID": "API/co.html",
    "href": "API/co.html",
    "title": "co",
    "section": "",
    "text": "For generating data for doc and test\nimport cupy as cp\nimport zarr\nfrom decorrelation.shp import ks_test\nimport math\nimport itertools\nfrom cupy.testing import assert_array_almost_equal"
  },
  {
    "objectID": "API/co.html#covariance-and-coherence-matrix-estimator",
    "href": "API/co.html#covariance-and-coherence-matrix-estimator",
    "title": "co",
    "section": "Covariance and Coherence Matrix Estimator",
    "text": "Covariance and Coherence Matrix Estimator\n\nsource\n\nemperical_co\n\n emperical_co (rslc:cupy.ndarray, is_shp:cupy.ndarray, block_size:int=128)\n\nMaximum likelihood covariance estimator.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nrslc\nndarray\n\nrslc stack, dtype: cupy.complexfloating\n\n\nis_shp\nndarray\n\nshp bool, dtype: cupy.bool\n\n\nblock_size\nint\n128\nthe CUDA block size, it only affects the calculation speed\n\n\nReturns\ntuple\n\nthe covariance and coherence matrix cov and coh\n\n\n\nThe cov and coh is defined as:\n\\[\ncov = E(z_1z_2^*) \\quad coh=\\frac{E(z_1z_2^*)}{\\sqrt{E(|z_1|^2)E(|z_2|^2)}}\n\\]\nand estimated as:\n\\[\ncov = \\frac{\\sum_{i=1}^{L}z_1^{i}z_2^{i*}}{L} \\quad coh = \\frac{\\sum_{i=1}^{L}z_1^{i}z_2^{i*}}{\\sqrt(\\sum_{i=1}^{L}|z_1^{i}|^2)(\\sum_{i=1}^{L}|z_2^{i}|^2)}\n\\]\nusing all selected SHPs. Their shapes are [nlines,width,nimages,nimages].\nThe rslc is a three dimentional cupy ndarray. The dtype should be cupy.complex64. From outerest to innerest, the three dimentions are azimuth, range and image. is_shp is a four dimentional cupy ndarray. It describes if pixels in the search window are SHP to the central pixel. From outerest ot innerest, they are azimuth, range, secondary pixel relative azimuth, secondary pixel relative range.\nHere is an example:\n\n\nFor generating data for doc and test\nrslc = zarr.open('../../data/rslc.zarr/','r')[600:605,600:610]\nrslc = cp.asarray(rslc)\n\n# SHP selection\naz_half_win = 1; r_half_win = 2\naz_win = 2*az_half_win+1; r_win = 2*r_half_win+1\n\nrmli = cp.abs(rslc)**2\nsorted_rmli = cp.sort(rmli,axis=-1)\ndist,p = ks_test(sorted_rmli,az_half_win=az_half_win,r_half_win=r_half_win)\nis_shp = (p < 0.05) & (p >= 0.0)\n\n# Select DS candidate\nshp_num = cp.count_nonzero(is_shp,axis=(-2,-1))\nis_ds_can = shp_num >= 3\nds_can_is_shp = is_shp[is_ds_can]\nds_can_idx = cp.where(is_ds_can)\n\n\n\nrslc.shape, is_shp.shape, is_shp[2,3]\n\n((5, 10, 17),\n (5, 10, 3, 5),\n array([[False, False, False, False,  True],\n        [False, False,  True, False, False],\n        [False, False,  True, False, False]]))\n\n\nrslc is a stack of 17 rslc images. Each of the image has 5 pixel in azimuth dimention and 10 pixels in range dimention. It shows for pixel (2,3), the (3*5) window around it has 2 SHPs to it (the central one is itself).\n\ncov,coh = emperical_co(rslc,is_shp)\ncov.shape, coh.shape\n\n((5, 10, 17, 17), (5, 10, 17, 17))\n\n\nBoth cov and coh are complex data. The shape shows each covarience or coherence matrix is 17 by 17 since there are 17 images. And cov and coh are matrix for all 5*10 pixels.\n\nsource\n\n\nemperical_co_sp\n\n emperical_co_sp (rslc:cupy.ndarray,\n                  sp_idx:tuple[cupy.ndarray,cupy.ndarray],\n                  is_shp_sp:cupy.ndarray, block_size:int=128)\n\nMaximum likelihood covariance estimator for sparse data.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nrslc\nndarray\n\nrslc stack, dtype: cupy.complexfloating\n\n\nsp_idx\ntuple\n\nindex of sparse data (azimuth_index, range_index), dtype: cupy.int, shape: (n_sp,)\n\n\nis_shp_sp\nndarray\n\nshp bool, dtype: cupy.bool\n\n\nblock_size\nint\n128\nthe CUDA block size, it only affects the calculation speed\n\n\nReturns\ntuple\n\nthe covariance and coherence matrix cov and coh\n\n\n\nemperical_co_sp is the emperical_co on sparse data, e.g., DSs. rslc is same as emperical_co. sp_idx is the index, i.e., a tuple of (azimuth_idx, range_idx). Each index is 1D array. is_shp_sp is similar to is_shp in emperical_co but it only contains information about the sparse data. It is a 3D array with shape [number_of_point,az_win,r_win].\nCompared with emperical_co, emperical_co_sp only estimate coherence/covariance at specific position so the memory usage is much small.\nExample:\n\n\nCode for generating data for doc\nrslc = zarr.open('../../data/rslc.zarr/','r')[600:605,600:610]\nrslc = cp.asarray(rslc)\n\n# SHP selection\naz_half_win = 1; r_half_win = 2\naz_win = 2*az_half_win+1; r_win = 2*r_half_win+1\n\nrmli = cp.abs(rslc)**2\nsorted_rmli = cp.sort(rmli,axis=-1)\ndist,p = ks_test(sorted_rmli,az_half_win=az_half_win,r_half_win=r_half_win)\nis_shp = (p < 0.05) & (p >= 0.0)\n\n# Select DS candidate\nshp_num = cp.count_nonzero(is_shp,axis=(-2,-1))\nis_ds_can = shp_num >= 3\nds_can_is_shp = is_shp[is_ds_can]\nds_can_idx = cp.where(is_ds_can)\n\n\n\nrslc.shape,ds_can_idx,ds_can_is_shp\n\n((5, 10, 17),\n (array([2, 3, 3, 4, 4]), array([3, 3, 5, 1, 4])),\n array([[[False, False, False, False,  True],\n         [False, False,  True, False, False],\n         [False, False,  True, False, False]],\n \n        [[False, False,  True, False, False],\n         [False, False,  True, False, False],\n         [False, False, False,  True, False]],\n \n        [[False, False, False, False, False],\n         [False, False,  True, False, False],\n         [ True,  True, False, False, False]],\n \n        [[False, False,  True, False, False],\n         [False,  True,  True, False, False],\n         [False, False, False, False, False]],\n \n        [[False,  True,  True,  True, False],\n         [False, False,  True, False,  True],\n         [False, False, False, False, False]]]))\n\n\nrslc is a stack of 17 rslc images. Each of the image has 5 pixel in azimuth dimention and 10 pixels in range dimention. ds_can_idx shows the index of the DS candidates and ds_can_is_shp shows the corrosponding SHPs.\n\nds_can_cov, ds_can_coh = emperical_co_sp(rslc,ds_can_idx,ds_can_is_shp)"
  },
  {
    "objectID": "API/co.html#covariance-and-coherence-matrix-regularizer",
    "href": "API/co.html#covariance-and-coherence-matrix-regularizer",
    "title": "co",
    "section": "Covariance and Coherence Matrix Regularizer",
    "text": "Covariance and Coherence Matrix Regularizer\n\nsource\n\nisPD\n\n isPD (co:cupy.ndarray)\n\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nco\nndarray\nabsolute value of complex coherence/covariance stack\n\n\nReturns\nndarray\nbool array indicating wheather coherence/covariance is positive define\n\n\n\nThis function tells if the matrix is positive defined or not.\n\n\nCode for generating data for doc\nrslc = zarr.open('../../data/rslc.zarr/','r')[600:650,600:650]\nrslc = cp.asarray(rslc)\n\n# SHP selection\naz_half_win = 5; r_half_win = 5\naz_win = 2*az_half_win+1; r_win = 2*r_half_win+1\n\nrmli = cp.abs(rslc)**2\nsorted_rmli = cp.sort(rmli,axis=-1)\ndist,p = ks_test(sorted_rmli,az_half_win=az_half_win,r_half_win=r_half_win)\nis_shp = (p < 0.05) & (p >= 0.0)\n\n# Select DS candidate\nshp_num = cp.count_nonzero(is_shp,axis=(-2,-1))\nis_ds_can = shp_num >= 50\nds_can_is_shp = is_shp[is_ds_can]\nds_can_idx = cp.where(is_ds_can)\n\nds_can_coh = emperical_co_sp(rslc,ds_can_idx,ds_can_is_shp)[1]\n\n\n\nds_can_coh.shape\n\n(149, 17, 17)\n\n\n\nisPD_ds_can = isPD(ds_can_coh)\n\n\nisPD_ds_can\n\narray([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True])\n\n\nAll coherence matrix are positive defined.\n\nsource\n\n\nnearestPD\n\n nearestPD (co:cupy.ndarray)\n\nFind the nearest positive-definite matrix to input matrix.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nco\nndarray\nstack of matrix with shape […,N,N]\n\n\nReturns\nndarray\nnearest positive definite matrix of input, shape […,N,N]\n\n\n\nnearest means the Frobenius norm of the difference is minimized.\n\nsource\n\n\nregularize_spectral\n\n regularize_spectral (coh:cupy.ndarray, beta:Union[float,cupy.ndarray])\n\nSpectral regularizer for coherence matrix.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ncoh\nndarray\nstack of matrix with shape […,N,N]\n\n\nbeta\nUnion\nthe regularization parameter, a float number or cupy ndarray with shape […]\n\n\nReturns\nndarray\nregularized matrix, shape […,N,N]\n\n\n\nregularize_spectral can regularize the absolute value of coherence matrix for better phase linking. It is first presented in [@zwiebackCheapValidRegularizers2022a].\nExamples:\n\n\nCode for generating data for doc\nrslc = zarr.open('../../data/rslc.zarr/','r')[600:605,600:610]\nrslc = cp.asarray(rslc)\n\n# SHP selection\naz_half_win = 1; r_half_win = 2\naz_win = 2*az_half_win+1; r_win = 2*r_half_win+1\n\nrmli = cp.abs(rslc)**2\nsorted_rmli = cp.sort(rmli,axis=-1)\ndist,p = ks_test(sorted_rmli,az_half_win=az_half_win,r_half_win=r_half_win)\nis_shp = (p < 0.05) & (p >= 0.0)\n\ncov,coh = emperical_co(rslc,is_shp)\n\n\n\ncoh.shape\n\n(5, 10, 17, 17)\n\n\n\nregularized_coh1 = regularize_spectral(coh,0.1)\n\nMore general, bata can be a cp.ndarray:\n\nbeta = cp.ones(coh.shape[:-2])/10\nregularized_coh2 = regularize_spectral(coh,beta)"
  },
  {
    "objectID": "API/pl.html",
    "href": "API/pl.html",
    "title": "pl",
    "section": "",
    "text": "Code for generating data for test and doc\nimport cupy as cp\nimport numpy as np\nimport zarr\nimport h5py\nfrom decorrelation.shp import ks_test\nfrom decorrelation.co import emperical_co,emperical_co_sp, regularize_spectral\n\nfrom matplotlib import pyplot as plt"
  },
  {
    "objectID": "API/pl.html#emi",
    "href": "API/pl.html#emi",
    "title": "pl",
    "section": "EMI",
    "text": "EMI\n\nsource\n\nemi\n\n emi (coh:cupy.ndarray)\n\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ncoh\nndarray\ncomplex coherence metrix,dtype cupy.complex\n\n\nReturns\ntuple\nestimated phase history ph, dtype complex; quality (minimum eigvalue, dtype float)\n\n\n\nemi is a phase estimator base on Eigendecomposition-based Maximum-likelihood-estimator of Interferometric phase (EMI) [@ansariEfficientPhaseEstimation2018] phase linking method.\nThe amplitude of coh should range between 0 and 1 and the phase of coh should be the interferometric phase. The returned phase is also complex but the amplitude is setted to 1. The quality factor is a measure for the inadequacy of EMI’s model that adding real-valued dyadic for calibration of real coherence matrix which is generally poorly estimated. It is supposed to larger than 1 and smaller means better.\nExample: Complex coherence matrix from a stack of 17 SLC images:\n\n\nCode for generating data for test and doc\nrslc = zarr.open('../../data/rslc.zarr/','r')\nrslc = cp.asarray(rslc[:])\n\n# SHP selection\naz_half_win = 5; r_half_win = 5\naz_win = 2*az_half_win+1; r_win = 2*r_half_win+1\n\nrmli = cp.abs(rslc)**2\nsorted_rmli = cp.sort(rmli,axis=-1)\ndel rmli\ndist,p = ks_test(sorted_rmli,az_half_win=az_half_win,r_half_win=r_half_win)\nis_shp = (p < 0.05) & (p >= 0.0)\ndel p\n\n# Select DS candidate\nshp_num = cp.count_nonzero(is_shp,axis=(-2,-1))\nis_ds_can = shp_num >= 50\n\nds_can_is_shp = is_shp[is_ds_can]\nds_can_idx = cp.where(is_ds_can)\nds_can_cov, ds_can_coh = emperical_co_sp(rslc,ds_can_idx,ds_can_is_shp)\n\n\n\nds_can_coh.shape\n\n(740397, 17, 17)\n\n\n\nds_can_ph, ds_can_emi_quality = emi(ds_can_coh)\nds_can_ph.shape, ds_can_emi_quality.shape\n\n((740397, 17), (740397,))\n\n\n\nds_can_emi_quality_2d = cp.empty_like(is_ds_can,dtype=ds_can_emi_quality.dtype)\nds_can_emi_quality_2d[:] = cp.nan\nds_can_emi_quality_2d[is_ds_can] = ds_can_emi_quality\n\n\nfig, ax = plt.subplots(1,1,figsize=(10,10))\npcm = ax.imshow(cp.asnumpy(ds_can_emi_quality_2d),interpolation='nearest',vmin=1,vmax=1.3)\nax.set(title='DS EMI quality factor',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()"
  },
  {
    "objectID": "API/pl.html#temporal-coherence-for-distributed-scatterer",
    "href": "API/pl.html#temporal-coherence-for-distributed-scatterer",
    "title": "pl",
    "section": "Temporal Coherence for Distributed Scatterer",
    "text": "Temporal Coherence for Distributed Scatterer\n\nsource\n\ntemp_coh\n\n temp_coh (coh:cupy.ndarray, ds_ph=<class 'cupy.ndarray'>)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncoh\nndarray\n\ncomplex coherence metrix, dtype cupy.complex\n\n\nds_ph\ntype\nndarray\ncomplex phase history, dtype cupy.complex\n\n\n\nThis function estimate the temporal coherence of DSs which is defined as [@ferrettiNewAlgorithmProcessing2011]:\n\\[\\gamma = \\frac{1}{N^2-N} \\sum_{n=1}^{N} \\sum_{k \\neq n}^{N} e^{i\\phi_{nk}} e^{-i(\\theta_n-\\theta_k)}\\]\nWhere \\(\\phi_{nk}\\) is the phase of complex coherence matrix and \\(\\theta_{n}\\) is the phase after phase linking.\n\n\nCode for generating data for test and doc\nrslc = zarr.open('../../data/rslc.zarr/','r')\nrslc = cp.asarray(rslc[:])\n\n# SHP selection\naz_half_win = 5; r_half_win = 5\naz_win = 2*az_half_win+1; r_win = 2*r_half_win+1\n\nrmli = cp.abs(rslc)**2\nsorted_rmli = cp.sort(rmli,axis=-1)\ndel rmli\ndist,p = ks_test(sorted_rmli,az_half_win=az_half_win,r_half_win=r_half_win)\nis_shp = (p < 0.05) & (p >= 0.0)\n\n# Select DS candidate\nshp_num = cp.count_nonzero(is_shp,axis=(-2,-1))\nis_ds_can = shp_num >= 50\n\nds_can_is_shp = is_shp[is_ds_can]\nds_can_idx = cp.where(is_ds_can)\nds_can_cov, ds_can_coh = emperical_co_sp(rslc,ds_can_idx,ds_can_is_shp)\nds_can_ph = emi(ds_can_coh)[0]\n\n\n\nds_can_coh.shape,ds_can_ph.shape\n\n((740397, 17, 17), (740397, 17))\n\n\n\nds_can_temp_coh = temp_coh(ds_can_coh,ds_can_ph)\nds_can_temp_coh.shape\n\n(740397,)\n\n\n\nds_can_temp_coh_2d = cp.empty_like(is_ds_can,dtype=ds_can_temp_coh.dtype)\nds_can_temp_coh_2d[:] = cp.nan\nds_can_temp_coh_2d[is_ds_can] = ds_can_temp_coh\n\n\nfig, ax = plt.subplots(1,1,figsize=(10,10))\npcm = ax.imshow(cp.asnumpy(ds_can_temp_coh_2d),interpolation='nearest')\nax.set(title='DS Temporal Coherence',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()"
  },
  {
    "objectID": "Tutorials/work_with_dask.html",
    "href": "Tutorials/work_with_dask.html",
    "title": "Work With Dask",
    "section": "",
    "text": "import numpy as np\nimport zarr\nimport cupy as cp\nfrom itertools import product\n\nfrom matplotlib import pyplot as plt\nimport colorcet\n\nfrom decorrelation.shp import ks_test\nfrom decorrelation.co import emperical_co_sp\nfrom decorrelation.pl import emi\nIn this tutorial, we demostrate how to use Dask for distributed computing.\nTwo significant issues for InSAR big data processing are: 1) the memory of CPU/GPU does not fit the volume of very big data; 2) the processing speed is limited. For the first issue, one common solution is divide the data into independent chunks and process the chunks one by one. In many case, the processing of chunks are independent. Thus the processing can be speeded up by parallel processing.\nDask is a job scheduler that allows deploying process-level parallel processing. Through the Delayed feature, Dask operations only construct the computing workflow rather than do the computation immediately. All of the computations are done at the end to allow Dask better distributing computing resources for the task. Dask makes the parallel processing easier and enable the decoupling of codes for computation and codes for scheduling.\nIn this demo, we use Dask for multi-GPU KS test to select spatially homogenious pixels. This includes:\nThe KS test is one step of DS processing, the full DS processing precedure is in the DS_processing tutorial. However, that tutorial directly utilize arrays."
  },
  {
    "objectID": "Tutorials/work_with_dask.html#processing",
    "href": "Tutorials/work_with_dask.html#processing",
    "title": "Work With Dask",
    "section": "Processing",
    "text": "Processing\nLoad data into CPU, and set the chunk size:\n\nrslc_path = '../../data/rslc.zarr'\nrslc_zarr = zarr.open(rslc_path,mode='r')\ncpu_rslc = da.from_zarr(rslc_path,chunks=(2500,1000,17))\n\n\nrslc_zarr.chunks\n\n(1000, 1000, 17)\n\n\n\nrslc_zarr.shape\n\n(2500, 1834, 17)\n\n\nNote that SHP identification requires overlapping region to correctly select brothers of pixels around the chunk bound.\n\naz_half_win = 5\nr_half_win = 5\naz_win = 2*az_half_win+1\nr_win = 2*r_half_win+1\n\n\ndepth = {0:az_half_win, 1:r_half_win, 2:0}; boundary = {0:'none',1:'none',2:'none'}\ncpu_rslc_overlap = da.overlap.overlap(cpu_rslc,depth=depth, boundary=boundary)\n\n\nrslc_overlap = cpu_rslc_overlap.map_blocks(cp.asarray)\nrmli_overlap = da.abs(rslc_overlap)**2\nsorted_rmli_overlap = rmli_overlap.map_blocks(cp.sort,axis=-1)\n\nDask provide a convenient function map_blocks to apply function on every chunk. However, it only support function that have only one output. Here we manually do the mapping:\n\ndelayed_ks_test = delayed(ks_test,pure=True,nout=2)\nrmli_delayed = sorted_rmli_overlap.to_delayed()\np_delayed = np.empty_like(rmli_delayed,dtype=object)\ndist_delayed = np.empty_like(rmli_delayed,dtype=object)\n\n\nwith np.nditer(p_delayed,flags=['multi_index','refs_ok'], op_flags=['readwrite']) as p_it:\n    for p_block in p_it:\n        idx = p_it.multi_index\n        dist_delayed[idx],p_delayed[idx] = delayed_ks_test(rmli_delayed[idx],az_half_win=az_half_win,r_half_win=r_half_win)\n\n        chunk_shape = (*sorted_rmli_overlap.blocks[idx].shape[:-1],az_win,r_win)\n        dtype = sorted_rmli_overlap.dtype\n        dist_delayed[idx] = da.from_delayed(dist_delayed[idx],shape=chunk_shape,meta=cp.array((),dtype=dtype))\n        p_delayed[idx] = da.from_delayed(p_delayed[idx],shape=chunk_shape,meta=cp.array((),dtype=dtype))\n\n\np = da.block(p_delayed.reshape(*p_delayed.shape,1).tolist())\ndist = da.block(dist_delayed.reshape(*dist_delayed.shape,1).tolist())\n\nAfter we get the result, the overlapping region need to be trimed:\n\ndepth = {0:az_half_win, 1:r_half_win, 2:0, 3:0}; boundary = {0:'none',1:'none',2:'none',3:'none'}\ndist = da.overlap.trim_overlap(dist,depth=depth,boundary=boundary)\np = da.overlap.trim_overlap(p,depth=depth,boundary=boundary)\n\nSelect SHPs based on p-value threshold:\n\nis_shp = (p < 0.05) & (p >= 0.0)\n\n\nshp_num = da.count_nonzero(is_shp,axis=(-2,-1))\nis_ds_can = shp_num >= 50\n\n\ncpu_dist = da.map_blocks(cp.asnumpy,dist)\ncpu_p = da.map_blocks(cp.asnumpy,p)\ncpu_is_shp = da.map_blocks(cp.asnumpy,is_shp)\ncpu_shp_num = da.map_blocks(cp.asnumpy,shp_num)\ncpu_is_ds_can = da.map_blocks(cp.asnumpy,is_ds_can)\n\nSave the data to disk:\n\n_cpu_dist = cpu_dist.to_zarr('dist.zarr',overwrite=True,compute=False)\n_cpu_p = cpu_p.to_zarr('p.zarr',overwrite=True,compute=False)\n\nDo the computation:\n\nshp_num_result, is_ds_can_result = da.compute(_cpu_dist,_cpu_p,cpu_shp_num,cpu_is_ds_can)[2:]\ncluster.close()\n\nCPU times: user 795 ms, sys: 326 ms, total: 1.12 s\nWall time: 10.6 s\n\n\n\nfig, ax = plt.subplots(1,1,figsize=(10,10))\npcm = ax.imshow(shp_num_result,cmap=colorcet.cm.fire)\nax.set(title='Number of SHPs',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()\n\n\n\n\n\nfig, ax = plt.subplots(1,1,figsize=(10,10))\npcm = ax.imshow(is_ds_can_result,cmap=colorcet.cm.fire)\nax.set(title='DS Candidate distribution',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()\n\n\n\n\n\nimport numpy as np\nimport zarr\nimport cupy as cp\nfrom decorrelation.shp import ks_test\nrslc_zarr = zarr.open('../../data/rslc.zarr',mode='r')\nrslc_cpu = rslc_zarr[:]\nrslc = cp.asarray(rslc_cpu)\nrmli = cp.abs(rslc)**2\nsorted_rmli = cp.sort(rmli,axis=-1)\naz_half_win = 5\nr_half_win = 5\naz_win = 2*az_half_win+1\nr_win = 2*r_half_win+1\ndist,p = ks_test(sorted_rmli,az_half_win=az_half_win,r_half_win=r_half_win)\ndist_cpu = cp.asnumpy(dist)\np_cpu = cp.asnumpy(p)\nzarr.save_array('dist_ks.zarr', dist_cpu,chunks=(1000,1000,az_win,r_win),compressor=None)\nzarr.save_array('p_ks.zarr', p_cpu,chunks=(1000,1000,az_win,r_win),compressor=None)\n\nCPU times: user 2.32 s, sys: 7.71 s, total: 10 s\nWall time: 11.1 s"
  },
  {
    "objectID": "Tutorials/adaptive_multilook.html",
    "href": "Tutorials/adaptive_multilook.html",
    "title": "Adaptive Multilook",
    "section": "",
    "text": "In this tutorial, we demostrate how to use decorrelation package to identify spatially homogeneous pixels, extimate the coherence matrix and compare the original interferogram, multilook intergerogram and the adaptive multilook interferogram."
  },
  {
    "objectID": "Tutorials/adaptive_multilook.html#load-rslc-stack",
    "href": "Tutorials/adaptive_multilook.html#load-rslc-stack",
    "title": "Adaptive Multilook",
    "section": "Load rslc stack",
    "text": "Load rslc stack\n\ncp.cuda.Device(1).use()\n\n<CUDA Device 1>\n\n\n\nrslc = cp.load('../../data/rslc.npy')\nrslc.shape\n\n(2500, 1834, 17)"
  },
  {
    "objectID": "Tutorials/adaptive_multilook.html#apply-ks-test",
    "href": "Tutorials/adaptive_multilook.html#apply-ks-test",
    "title": "Adaptive Multilook",
    "section": "Apply ks test",
    "text": "Apply ks test\n\nrmli = cp.abs(rslc)**2\n\n\naz_half_win = 5\nr_half_win = 5\naz_win = 2*az_half_win+1\nr_win = 2*r_half_win+1\n\n\np = ks_test(rmli,az_half_win=az_half_win,r_half_win=r_half_win)[1]\n\nCPU times: user 45.7 ms, sys: 28.6 ms, total: 74.3 ms\nWall time: 74.8 ms\n\n\nks_test in decorrelation package is extremely fast!"
  },
  {
    "objectID": "Tutorials/adaptive_multilook.html#select-shps",
    "href": "Tutorials/adaptive_multilook.html#select-shps",
    "title": "Adaptive Multilook",
    "section": "Select SHPs",
    "text": "Select SHPs\n\nis_shp = (p < 0.05) & (p >= 0.0)\n\n\nshp_num = cp.count_nonzero(is_shp,axis=(-2,-1))\nshp_num_np = cp.asnumpy(shp_num)\n\n\nfig, ax = plt.subplots(1,1,figsize=(10,10))\npcm = ax.imshow(shp_num_np)\nax.set(title='Number of SHPs',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()"
  },
  {
    "objectID": "Tutorials/adaptive_multilook.html#estimate-coherence-matrix",
    "href": "Tutorials/adaptive_multilook.html#estimate-coherence-matrix",
    "title": "Adaptive Multilook",
    "section": "Estimate coherence matrix",
    "text": "Estimate coherence matrix\n\ncoh = emperical_co(rslc,is_shp)[1]\n\nCPU times: user 226 ms, sys: 18.8 ms, total: 245 ms\nWall time: 253 ms"
  },
  {
    "objectID": "Tutorials/adaptive_multilook.html#compare",
    "href": "Tutorials/adaptive_multilook.html#compare",
    "title": "Adaptive Multilook",
    "section": "Compare",
    "text": "Compare\nHere we compare 1-look interferogram, multilook interferogram and adaptive multilook interferogram\n\nref_image = 15\nsec_image = 16\n\n1 look interferogram:\n\ndiff = rslc[:,:,ref_image]*rslc[:,:,sec_image].conj()\n\nMultilook interferogram:\n\nml_diff = median_filter(diff,size=(az_win,r_win))\n\nAdaptive multilook interferogram:\n\nad_ml_diff = coh[:,:,ref_image,sec_image]\n\nThe plot background:\n\nplot_bg = rmli[:,:,0]\nplot_bg = cp.asnumpy(plot_bg)\nalpha = bg_alpha(plot_bg)\n\nPlot:\n\nfig,axes = plt.subplots(1,3,figsize=(24/2,7/2))\nxlabel = 'Range Index'\nylabel = 'Azimuth Index'\npcm0 = axes[0].imshow(cp.asnumpy(cp.angle(diff)),alpha=alpha,interpolation='nearest',cmap='hsv')\npcm1 = axes[1].imshow(cp.asnumpy(cp.angle(ml_diff)),alpha=alpha,interpolation='nearest',cmap='hsv')\npcm2 = axes[2].imshow(cp.asnumpy(cp.angle(ad_ml_diff)),alpha=alpha,interpolation='nearest',cmap='hsv')\nfor ax in axes:\n    ax.set(facecolor = \"black\")\naxes[0].set(title='Orignal Interferogram',xlabel=xlabel,ylabel=ylabel)\naxes[1].set(title=f'Multilook {az_win} by {r_win}',xlabel=xlabel,ylabel=ylabel)\naxes[2].set(title=f'Adaptively multilook {az_win} by {r_win}',xlabel=xlabel,ylabel=ylabel)\nfig.colorbar(pcm0,ax=axes[0])\nfig.colorbar(pcm1,ax=axes[1])\nfig.colorbar(pcm1,ax=axes[2])\nfig.show()"
  },
  {
    "objectID": "Tutorials/adaptive_multilook.html#conclusion",
    "href": "Tutorials/adaptive_multilook.html#conclusion",
    "title": "Adaptive Multilook",
    "section": "Conclusion",
    "text": "Conclusion\n\nAdaptive multilooking based on SHPs selection performs better than non-adaptive one;\nks_test and emperical_co implemented in decorrelation package are fast."
  },
  {
    "objectID": "Tutorials/ds_processing.html",
    "href": "Tutorials/ds_processing.html",
    "title": "DS Processing",
    "section": "",
    "text": "In this tutorial, we demostrate how to do standard DS processing with the decorrelation package."
  },
  {
    "objectID": "Tutorials/ds_processing.html#load-rslc-stack",
    "href": "Tutorials/ds_processing.html#load-rslc-stack",
    "title": "DS Processing",
    "section": "Load rslc stack",
    "text": "Load rslc stack\n\nrslc = cp.load('../../data/rslc.npy')\nrslc.shape\n\n(2500, 1834, 17)"
  },
  {
    "objectID": "Tutorials/ds_processing.html#apply-ks-test",
    "href": "Tutorials/ds_processing.html#apply-ks-test",
    "title": "DS Processing",
    "section": "Apply ks test",
    "text": "Apply ks test\n\nrmli = cp.abs(rslc)**2\nsorted_rmli = cp.sort(rmli,axis=-1)\n\n\naz_half_win = 5\nr_half_win = 5\naz_win = 2*az_half_win+1\nr_win = 2*r_half_win+1\n\n\np = ks_test(sorted_rmli,az_half_win=az_half_win,r_half_win=r_half_win)[1]"
  },
  {
    "objectID": "Tutorials/ds_processing.html#select-shps",
    "href": "Tutorials/ds_processing.html#select-shps",
    "title": "DS Processing",
    "section": "Select SHPs",
    "text": "Select SHPs\n\nis_shp = (p < 0.05) & (p >= 0.0)\n\n\nshp_num = cp.count_nonzero(is_shp,axis=(-2,-1))\n\n\nfig, ax = plt.subplots(1,1,figsize=(10,10))\npcm = ax.imshow(cp.asnumpy(shp_num),cmap=colorcet.cm.fire)\nax.set(title='Number of SHPs',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()"
  },
  {
    "objectID": "Tutorials/ds_processing.html#select-dss",
    "href": "Tutorials/ds_processing.html#select-dss",
    "title": "DS Processing",
    "section": "Select DSs",
    "text": "Select DSs\nHere we select DSs candidate as pixels have more than 50 brothers.\n\nis_ds_can = shp_num >= 50\n\nThe number of DSs:\n\ncp.count_nonzero(is_ds_can)\n\narray(740397)\n\n\nThe DSs distribution:\n\nfig, ax = plt.subplots(1,1,figsize=(10,10))\npcm = ax.imshow(cp.asnumpy(is_ds_can),cmap=colorcet.cm.fire)\nax.set(title='DS Candidate distribution',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()"
  },
  {
    "objectID": "Tutorials/ds_processing.html#estimate-coherence-matrix",
    "href": "Tutorials/ds_processing.html#estimate-coherence-matrix",
    "title": "DS Processing",
    "section": "Estimate coherence matrix",
    "text": "Estimate coherence matrix\nIn order to save memory, here we only estimate coherence matrix on selected DSs:\n\nds_can_is_shp = is_shp[is_ds_can]\nds_can_idx = cp.where(is_ds_can)\nds_can_cov, ds_can_coh = emperical_co_sp(rslc,ds_can_idx,ds_can_is_shp)\n\nPlot the average coherence matrix:\n\nds_can_ave_coh = abs(ds_can_coh).mean(axis=0)\n\n\nds_can_ave_coh.shape\n\n(17, 17)\n\n\n\nfig, ax = plt.subplots(1,1,figsize=(15,10))\npcm = ax.imshow(cp.asnumpy(ds_can_ave_coh),cmap=colorcet.cm.fire)\nax.set(title='Average Coherence Matrix',xlabel='Image Index',ylabel='Image Index')\nfig.colorbar(pcm)\nfig.show()\n\n\n\n\nThe coherence between the 5-th SLC and other SLC are bad. We may consider removing this image."
  },
  {
    "objectID": "Tutorials/ds_processing.html#phase-linking",
    "href": "Tutorials/ds_processing.html#phase-linking",
    "title": "DS Processing",
    "section": "Phase linking",
    "text": "Phase linking\nHere we apply the EMI method:\n\nds_can_ph, ds_can_emi_quality = emi(ds_can_coh)\nds_can_ph.shape, ds_can_emi_quality.shape\n\n((740397, 17), (740397,))\n\n\n\nds_can_emi_quality_2d = cp.empty_like(is_ds_can,dtype=ds_can_emi_quality.dtype)\nds_can_emi_quality_2d[:] = cp.nan\nds_can_emi_quality_2d[is_ds_can] = ds_can_emi_quality\n\n\nfig, ax = plt.subplots(1,1,figsize=(10,10))\npcm = ax.imshow(cp.asnumpy(ds_can_emi_quality_2d),interpolation='nearest',vmin=1,vmax=1.3)\nax.set(title='DS EMI quality factor',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()\n\n\n\n\n\nds_can_temp_coh = temp_coh(ds_can_coh,ds_can_ph)\nds_can_temp_coh.shape\n\n(740397,)\n\n\n\nds_can_temp_coh_2d = cp.empty_like(is_ds_can,dtype=ds_can_temp_coh.dtype)\nds_can_temp_coh_2d[:] = cp.nan\nds_can_temp_coh_2d[is_ds_can] = ds_can_temp_coh\nfig, ax = plt.subplots(1,1,figsize=(10,10))\npcm = ax.imshow(cp.asnumpy(ds_can_temp_coh_2d),interpolation='nearest')\nax.set(title='DS Temporal Coherence',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()"
  },
  {
    "objectID": "Tutorials/ds_processing.html#refine-ds-candidate",
    "href": "Tutorials/ds_processing.html#refine-ds-candidate",
    "title": "DS Processing",
    "section": "Refine DS candidate",
    "text": "Refine DS candidate\nHere we select DS candidate based on EMI quality factor and temporal coherence:\n\n_is_ds_can_refined = (ds_can_emi_quality>=1.0) & (ds_can_emi_quality <1.2) & (ds_can_temp_coh > 0.7) & (ds_can_temp_coh <= 1.0)\n\n\nds_can_refined_idx = tuple(idx[_is_ds_can_refined] for idx in ds_can_idx)\nis_ds_can_refined = cp.zeros_like(is_ds_can)\nis_ds_can_refined[ds_can_refined_idx] = True\n\n\nds_can_refined_coh = ds_can_coh[_is_ds_can_refined]\nds_can_refined_ph = ds_can_ph[_is_ds_can_refined]\n\n\nds_can_refined_coh.shape\n\n(460076, 17, 17)\n\n\nPlot the average coherence matrix and refined DS candiate distribution:\n\nds_can_refined_ave_coh = abs(ds_can_refined_coh).mean(axis=0)\nfig, ax = plt.subplots(1,1,figsize=(15,10))\npcm = ax.imshow(cp.asnumpy(ds_can_refined_ave_coh),cmap=colorcet.cm.fire)\nax.set(title='Average Coherence Matrix',xlabel='Image Index',ylabel='Image Index')\nfig.colorbar(pcm)\nfig.show()\n\n\n\n\n\nfig, ax = plt.subplots(1,1,figsize=(10,10))\npcm = ax.imshow(cp.asnumpy(is_ds_can_refined),cmap=colorcet.cm.fire)\nax.set(title='DS Candidate Refined distribution',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()\n\n\n\n\nWe find the coherence matrix gets better and noisy pixels are moved."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "decorrelation",
    "section": "",
    "text": "Documentation"
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "decorrelation",
    "section": "Install",
    "text": "Install\nInstall CuPy first, then:\nWith conda:\nconda install -c conda-forge decorrelation\nWith pip:\npip install decorrelation\nIn development mode:\ngit clone git@github.com:kanglcn/decorrelation.git ./decorrelation\ncd ./decorrelation\npip install -e '.[dev]'"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "decorrelation",
    "section": "How to use",
    "text": "How to use\n\nimport decorrelation as dc\n\nThis package provide functions for InSAR post-processing which refers as processing after SAR images co-registration and geocoding. The functions include PS/DS identification, coherence matrix estimation, phase linking etc.\nMost of the python functions in this package provide 2 kind of API, the array-based API and the file-based API. The inputs of array-based functions generally are numpy or cupy arrays. The inputs of file-based functions are path to the array stored in disk. The file-based functions make use of dask package to decrease the memory usage and parallelize the job. However, their is performance cost for using dask, if no parallelization is needed and the memory fits the data, the array-based API is recommended.\nPlease refer to the Documentation for detailed usage.\nWarning!!! This package is under intensive development. API is subjected to change without any noticement."
  },
  {
    "objectID": "index.html#contact-us",
    "href": "index.html#contact-us",
    "title": "decorrelation",
    "section": "Contact us",
    "text": "Contact us\n\nMost discussion happens on GitHub. Feel free to open an issue or comment on any open issue or pull request.\nuse github discussions to ask questions or leave comments."
  },
  {
    "objectID": "index.html#contribution",
    "href": "index.html#contribution",
    "title": "decorrelation",
    "section": "Contribution",
    "text": "Contribution\n\nPull requests are welcomed! Before making a pull request, please open an issue to talk about it.\nWe have notice many excellent open-source packages are rarely paid attention to due to lack of documentation. The package is developed with the nbdev, a notebook-driven development platform. Developers only need to simply write notebooks with lightweight markup and get high-quality documentation, tests, continuous integration, and packaging automatically."
  },
  {
    "objectID": "CLI/shp.html",
    "href": "CLI/shp.html",
    "title": "shp",
    "section": "",
    "text": "source\n\nde_shp_test\n\n de_shp_test (rslc:str, pvalue:str, az_half_win:int, r_half_win:int,\n              method:str=None, az_chunk_size:int=None, log:str=None)\n\nSHP identification through hypothetic test.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nrslc\nstr\n\ninput: rslc stack\n\n\npvalue\nstr\n\noutput: the p value of the test\n\n\naz_half_win\nint\n\nazimuth half window size\n\n\nr_half_win\nint\n\nrange half window size\n\n\nmethod\nstr\nNone\nSHP identification method,optional. Default: ks\n\n\naz_chunk_size\nint\nNone\nazimuth chunk size, optional. Default: the azimuth chunk size in rslc stack\n\n\nlog\nstr\nNone\nlog file, optional. Default: no log file\n\n\n\nThis function is a wrapper of functions in decorrelation.shp that provides file interface. Please refer it for the usage. It utilizes dask for parallel and distributed computation. Compared with the functions in decorrelation.shp, this function splits the dataset into several chunks and the computation in these chunks can run in parallel on multi-GPUs.\nThe r_chunk_size and az_chunk_size is used to determine how many pixels in range and azimuth in one chunk. The chunk size of the output pvalue is also setted according to them.\n\nrslc = '../../data/rslc.zarr'\npvalue = './pvalue.zarr'\naz_half_win = 5\nr_half_win = 5\nmethod = None\nr_chunk_size = 1000\naz_chunk_size = 1000\nlog='de_shp_test.log'\n\n\nde_shp_test(rslc,pvalue,az_half_win=5,r_half_win=5, method=None,az_chunk_size=1000,log='de_shp_test.log')\n\n2023-05-10 00:56:30 - de_shp_test - INFO - hypothetic test method: ks\n2023-05-10 00:56:30 - de_shp_test - INFO - rslc dateset shape: (2500, 1834, 17)\n2023-05-10 00:56:30 - de_shp_test - INFO - rslc dataset chunks: (1000, 1000, 17)\n2023-05-10 00:56:30 - de_shp_test - INFO - parallel processing azimuth chunk size: 1000\n2023-05-10 00:56:30 - de_shp_test - INFO - starting dask CUDA local cluster.\n\n\n2023-05-10 00:56:34,882 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n2023-05-10 00:56:34,882 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n2023-05-10 00:56:34,935 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n2023-05-10 00:56:34,935 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n2023-05-10 00:56:35,004 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n2023-05-10 00:56:35,004 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n2023-05-10 00:56:35,022 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n2023-05-10 00:56:35,023 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n2023-05-10 00:56:35,044 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n2023-05-10 00:56:35,045 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n2023-05-10 00:56:35,081 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n2023-05-10 00:56:35,081 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n2023-05-10 00:56:35,108 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n2023-05-10 00:56:35,108 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n2023-05-10 00:56:35,108 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n2023-05-10 00:56:35,108 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n\n\n2023-05-10 00:56:39 - de_shp_test - INFO - dask local CUDA cluster started.\n2023-05-10 00:56:39 - de_shp_test - INFO - rslc dask array shape: (2500, 1834, 17)\n2023-05-10 00:56:39 - de_shp_test - INFO - rslc dask array chunks: ((1000, 1000, 500), (1834,), (17,))\n2023-05-10 00:56:39 - de_shp_test - INFO - azimuth half window size: 5; azimuth window size: 11\n2023-05-10 00:56:39 - de_shp_test - INFO - range half window size: 5; range window size: 11\n2023-05-10 00:56:39 - de_shp_test - INFO - setting shared boundaries between rlsc chunks.\n2023-05-10 00:56:39 - de_shp_test - INFO - rslc dask array with overlap shape: (2520, 1834, 17)\n2023-05-10 00:56:39 - de_shp_test - INFO - rslc dask array with overlap chunks: ((1005, 1010, 505), (1834,), (17,))\n2023-05-10 00:56:39 - de_shp_test - INFO - rmli dask array with overlap shape: (2520, 1834, 17)\n2023-05-10 00:56:39 - de_shp_test - INFO - rmli dask array with overlap chunks: ((1005, 1010, 505), (1834,), (17,))\n2023-05-10 00:56:39 - de_shp_test - INFO - applying test on sorted rmli stack.\n2023-05-10 00:56:39 - de_shp_test - INFO - p value generated\n2023-05-10 00:56:39 - de_shp_test - INFO - p value shape: (2520, 1834, 11, 11)\n2023-05-10 00:56:39 - de_shp_test - INFO - p value chunks: ((1005, 1010, 505), (1834,), (11,), (11,))\n2023-05-10 00:56:39 - de_shp_test - INFO - trim shared boundaries between p value chunks\n2023-05-10 00:56:39 - de_shp_test - INFO - trimmed p value shape: (2500, 1834, 11, 11)\n2023-05-10 00:56:39 - de_shp_test - INFO - trimmed p value chunks: ((1000, 1000, 500), (1834,), (11,), (11,))\n2023-05-10 00:56:40 - de_shp_test - INFO - saving p value.\n2023-05-10 00:56:40 - de_shp_test - INFO - computing graph setted. doing all the computing.\n2023-05-10 00:56:46 - de_shp_test - INFO - computing finished.\n2023-05-10 00:56:47 - de_shp_test - INFO - dask cluster closed.\nCPU times: user 1.28 s, sys: 873 ms, total: 2.16 s\nWall time: 17.3 s\n\n\nThis function can also be called from command line directly:\n\n!de_shp_test -h\n\nusage: de_shp_test [-h] [--method METHOD] [--r_chunk_size R_CHUNK_SIZE]\n                   [--az_chunk_size AZ_CHUNK_SIZE] [--log LOG]\n                   rslc pvalue az_half_win r_half_win\n\nSHP identification through hypothetic test.\n\npositional arguments:\n  rslc                           input: rslc stack\n  pvalue                         output: the p value of the test\n  az_half_win                    azimuth half window size\n  r_half_win                     range half window size\n\noptions:\n  -h, --help                     show this help message and exit\n  --method METHOD                SHP identification method,optional. Default: ks\n  --r_chunk_size R_CHUNK_SIZE    range chunk size, Optional. Default: the range\n                                 chunk size in rslc stack\n  --az_chunk_size AZ_CHUNK_SIZE  azimuth chunk size, optional. Default: the\n                                 azimuth chunk size in rslc stack\n  --log LOG                      log file, optional. Default: no log file\n\n\n\nsource\n\n\nde_select_ds_can\n\n de_select_ds_can (pvalue:str, is_shp:str, is_ds_can:str,\n                   p_max:float=0.05, shp_num_min:int=50,\n                   az_chunk_size:int=None, shp_num_fig:str=None,\n                   is_ds_can_fig:str=None, log=None)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npvalue\nstr\n\ninput: pvalue of hypothetic test\n\n\nis_shp\nstr\n\noutput: bool array indicating the SHPs of every pixel\n\n\nis_ds_can\nstr\n\noutput: bool array indicating DS candidate\n\n\np_max\nfloat\n0.05\nthreshold of p value to select SHP,optional. Default: 0.05\n\n\nshp_num_min\nint\n50\nthreshold of number of SHPs to select DS candidate,optional. Default: 50\n\n\naz_chunk_size\nint\nNone\nazimuth chunk size, optional. Default: the azimuth chunk size in pvalue\n\n\nshp_num_fig\nstr\nNone\npath to the plot of number of SHPs, optional. Default: no plot\n\n\nis_ds_can_fig\nstr\nNone\npath to the plot of DSs candidate distribution, optional. Default: no plot\n\n\nlog\nNoneType\nNone\nlog file. Default: no log file\n\n\n\n\npvalue = './pvalue.zarr'\nis_shp = './is_shp.zarr'\nis_ds_can = './is_ds_can.zarr'\nshp_num_fig = './shp_num_fig.png'\nis_ds_can_fig = './is_ds_can.png'\naz_chunk_size = 1000\np_max = 0.05\nshp_num_min=50\nds_can_chunk_size = 100000\n\n\n#de_select_ds_can(pvalue,is_shp,is_ds_can,ds_can_is_shp,p_max=p_max)\nde_select_ds_can(pvalue,is_shp,is_ds_can,p_max=p_max,az_chunk_size=az_chunk_size,shp_num_fig=shp_num_fig,is_ds_can_fig=is_ds_can_fig)\n\n2023-05-11 11:36:47 - de_select_ds_can - INFO - pvalue dateset shape: (2500, 1834, 11, 11)\n2023-05-11 11:36:47 - de_select_ds_can - INFO - pvalue dataset chunks: (1000, 1834, 11, 11)\n2023-05-11 11:36:47 - de_select_ds_can - INFO - parallel processing azimuth chunk size: 1000\n2023-05-11 11:36:47 - de_select_ds_can - INFO - starting dask local cluster.\n2023-05-11 11:36:49 - de_select_ds_can - INFO - dask local cluster started.\n2023-05-11 11:36:49 - de_select_ds_can - INFO - pvalue dask array shape: (2500, 1834, 11, 11)\n2023-05-11 11:36:49 - de_select_ds_can - INFO - pvalue dask array chunks: ((1000, 1000, 500), (1834,), (11,), (11,))\n2023-05-11 11:36:49 - de_select_ds_can - INFO - selecting SHPs based on pvalue threshold: 0.05\n2023-05-11 11:36:49 - de_select_ds_can - INFO - is_shp shape: (2500, 1834, 11, 11)\n2023-05-11 11:36:49 - de_select_ds_can - INFO - is_shp chunks: ((1000, 1000, 500), (1834,), (11,), (11,))\n2023-05-11 11:36:49 - de_select_ds_can - INFO - selecting DS candidates based on minimum of number of SHPs: 50\n2023-05-11 11:36:49 - de_select_ds_can - INFO - is_ds_can shape: (2500, 1834)\n2023-05-11 11:36:49 - de_select_ds_can - INFO - is_ds_can chunks: ((1000, 1000, 500), (1834,))\n2023-05-11 11:36:49 - de_select_ds_can - INFO - saving is_shp.\n2023-05-11 11:36:49 - de_select_ds_can - INFO - saving is_ds_can.\n2023-05-11 11:36:49 - de_select_ds_can - INFO - computing graph setted. doing all the computing.\n2023-05-11 11:36:53 - de_select_ds_can - INFO - computing finished.\n2023-05-11 11:36:53 - de_select_ds_can - INFO - number of ds can in each chunk: (346329, 274921, 119147)\n2023-05-11 11:36:53 - de_select_ds_can - INFO - dask cluster closed.\n2023-05-11 11:36:53 - de_select_ds_can - INFO - plotting number of SHPs.\n2023-05-11 11:36:53 - de_select_ds_can - INFO - plotting DS candidate distribution.\nCPU times: user 1.4 s, sys: 394 ms, total: 1.79 s\nWall time: 6.61 s\n\n\n\n\n\n\n\n\n\n!de_select_ds_can -h\n\nusage: de_select_ds_can [-h] [--p_max P_MAX] [--shp_num_min SHP_NUM_MIN]\n                        [--r_chunk_size R_CHUNK_SIZE]\n                        [--az_chunk_size AZ_CHUNK_SIZE]\n                        [--ds_can_chunk_size DS_CAN_CHUNK_SIZE]\n                        [--shp_num_fig SHP_NUM_FIG]\n                        [--is_ds_can_fig IS_DS_CAN_FIG] [--log LOG]\n                        pvalue is_shp is_ds_can ds_can_is_shp\n\npositional arguments:\n  pvalue                                input: pvalue of hypothetic test\n  is_shp                                output: bool array indicating the SHPs\n                                        of every pixel\n  is_ds_can                             output: bool array indicating DS\n                                        candidate\n  ds_can_is_shp                         output: bool array indicating the SHPs\n                                        of DS candidate\n\noptions:\n  -h, --help                            show this help message and exit\n  --p_max P_MAX                         threshold of p value to select\n                                        SHP,optional. Default: 0.05 (default:\n                                        0.05)\n  --shp_num_min SHP_NUM_MIN             threshold of number of SHPs to select DS\n                                        candidate,optional. Default: 50\n                                        (default: 50)\n  --r_chunk_size R_CHUNK_SIZE           range chunk size, optional. Default: the\n                                        range chunk size in pvalue\n  --az_chunk_size AZ_CHUNK_SIZE         azimuth chunk size, optional. Default:\n                                        the azimuth chunk size in pvalue\n  --ds_can_chunk_size DS_CAN_CHUNK_SIZE\n                                        DS candidate chunk size, optional.\n  --shp_num_fig SHP_NUM_FIG             path to the plot of number of SHPs,\n                                        optional. Default: no plot\n  --is_ds_can_fig IS_DS_CAN_FIG         path to the plot of DSs candidate\n                                        distribution, optional. Default: no plot\n  --log LOG                             log file. Default: no log file"
  },
  {
    "objectID": "CLI/co.html",
    "href": "CLI/co.html",
    "title": "co",
    "section": "",
    "text": "source\n\nde_emperical_co_sp\n\n de_emperical_co_sp (rslc:str, is_shp:str, is_ds_can:str, ds_can_coh:str,\n                     az_chunk_size:int=None,\n                     ds_can_coh_chunk_size:int=None,\n                     ds_can_coh_ave_fig:str=None, log=None)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nrslc\nstr\n\ninput: rslc stack\n\n\nis_shp\nstr\n\ninput: bool array indicating the SHPs of every pixel\n\n\nis_ds_can\nstr\n\ninput: bool array indicating DS candidate\n\n\nds_can_coh\nstr\n\noutput: complex coherence matrix for DS candidate\n\n\naz_chunk_size\nint\nNone\nazimuth chunk size, optional. Default: the azimuth chunk size in rslc stack\n\n\nds_can_coh_chunk_size\nint\nNone\nchunk size of output zarr dataset, optional. Default: automatically determined\n\n\nds_can_coh_ave_fig\nstr\nNone\npath to the plot of average coherence matrix of DS candidate, optional. Default: no plot\n\n\nlog\nNoneType\nNone\nlog file. Default: no log file\n\n\n\n\nrslc = '../../data/rslc.zarr'\nis_shp = './is_shp.zarr'\nis_ds_can = './is_ds_can.zarr'\nds_can_coh = './ds_can_coh.zarr'\naz_chunk_size = 1000\nds_can_coh_chunk_size = None\nlog = 'co.log'\nds_can_coh_ave_fig = './ds_can_coh_ave.png'\n\n\nde_emperical_co_sp(rslc,is_shp,is_ds_can,ds_can_coh,az_chunk_size=az_chunk_size,ds_can_coh_ave_fig=ds_can_coh_ave_fig,log=log)\n\n2023-05-11 11:18:58 - de_emperical_co_sp - INFO - rslc dataset shape: (2500, 1834, 17)\n2023-05-11 11:18:58 - de_emperical_co_sp - INFO - rslc dataset chunks: (1000, 1000, 17)\n2023-05-11 11:18:58 - de_emperical_co_sp - INFO - is_shp dataset shape: (2500, 1834, 11, 11)\n2023-05-11 11:18:58 - de_emperical_co_sp - INFO - is_shp dataset chunks: (1000, 1834, 11, 11)\n2023-05-11 11:18:58 - de_emperical_co_sp - INFO - is_ds_can dataset shape: (2500, 1834)\n2023-05-11 11:18:58 - de_emperical_co_sp - INFO - is_ds_can dataset chunks: (1000, 1834)\n2023-05-11 11:18:58 - de_emperical_co_sp - INFO - got azimuth window size and half azimuth window size from is_shp shape: 11, 5\n2023-05-11 11:18:58 - de_emperical_co_sp - INFO - got range window size and half range window size from is_shp shape: 11, 5\n2023-05-11 11:18:58 - de_emperical_co_sp - INFO - parallel processing azimuth chunk size: 1000\n2023-05-11 11:18:58 - de_emperical_co_sp - INFO - starting dask CUDA local cluster.\n\n\n2023-05-11 11:19:03,022 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n2023-05-11 11:19:03,022 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n2023-05-11 11:19:03,059 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n2023-05-11 11:19:03,059 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n2023-05-11 11:19:03,094 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n2023-05-11 11:19:03,094 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n2023-05-11 11:19:03,099 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n2023-05-11 11:19:03,099 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n2023-05-11 11:19:03,176 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n2023-05-11 11:19:03,176 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n2023-05-11 11:19:03,177 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n2023-05-11 11:19:03,177 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n2023-05-11 11:19:03,199 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n2023-05-11 11:19:03,199 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n2023-05-11 11:19:03,203 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n2023-05-11 11:19:03,203 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n\n\n2023-05-11 11:19:07 - de_emperical_co_sp - INFO - dask local CUDA cluster started.\n2023-05-11 11:19:07 - de_emperical_co_sp - INFO - rslc dask array shape: (2500, 1834, 17)\n2023-05-11 11:19:07 - de_emperical_co_sp - INFO - rslc dask array chunks: ((1000, 1000, 500), (1834,), (17,))\n2023-05-11 11:19:07 - de_emperical_co_sp - INFO - is_shp dask array shape: (2500, 1834, 11, 11)\n2023-05-11 11:19:07 - de_emperical_co_sp - INFO - is_shp dask array chunks: ((1000, 1000, 500), (1834,), (11,), (11,))\n2023-05-11 11:19:07 - de_emperical_co_sp - INFO - is_ds_can dask array shape: (2500, 1834)\n2023-05-11 11:19:07 - de_emperical_co_sp - INFO - is_ds_can dask array chunks: ((1000, 1000, 500), (1834,))\n2023-05-11 11:19:07 - de_emperical_co_sp - INFO - setting shared boundaries between rlsc chunks.\n2023-05-11 11:19:07 - de_emperical_co_sp - INFO - rslc dask array with overlap shape: (2520, 1834, 17)\n2023-05-11 11:19:07 - de_emperical_co_sp - INFO - rslc dask array with overlap chunks: ((1005, 1010, 505), (1834,), (17,))\n2023-05-11 11:19:07 - de_emperical_co_sp - INFO - padding zero between is_ds_can chunks.\n2023-05-11 11:19:07 - de_emperical_co_sp - INFO - is_ds_can dask array with padding shape: (2520, 1834)\n2023-05-11 11:19:07 - de_emperical_co_sp - INFO - is_ds_can dask array with padding chunks: ((1005, 1010, 505), (1834,))\n2023-05-11 11:19:07 - de_emperical_co_sp - INFO - slicing is_shp on ds candidate.\n2023-05-11 11:19:07 - de_emperical_co_sp - INFO - ds_can_is_shp dask array shape: (740397, 11, 11)\n2023-05-11 11:19:07 - de_emperical_co_sp - INFO - ds_can_is_shp dask array chunks: ((346329, 274921, 119147), (11,), (11,))\n2023-05-11 11:19:07 - de_emperical_co_sp - INFO - estimating coherence matrix.\n2023-05-11 11:19:08 - de_emperical_co_sp - INFO - got coherence matrix.\n2023-05-11 11:19:08 - de_emperical_co_sp - INFO - rechunking ds_can_coh to chunk size (for saving with zarr): ((246799, 246799, 246799), (17,), (17,))\n2023-05-11 11:19:08 - de_emperical_co_sp - INFO - saving ds_can_coh.\n2023-05-11 11:19:08 - de_emperical_co_sp - INFO - computing graph setted. doing all the computing.\n2023-05-11 11:19:21 - de_emperical_co_sp - INFO - computing finished.\n2023-05-11 11:19:23 - de_emperical_co_sp - INFO - dask cluster closed.\n2023-05-11 11:19:23 - de_emperical_co_sp - INFO - plotting average coherence matrix.\nCPU times: user 2.25 s, sys: 1.11 s, total: 3.35 s\nWall time: 25 s\n\n\n\n\n\nAfter finishing it, remove computing the ds_can_is_shp from de_select_ds_can\nThis function is a wrapper of decorrelation.shp.emperical_co_sp that provides file interface.\n\n!de_emperical_co_sp -h\n\nusage: de_emperical_co_sp [-h] [--az_chunk_size AZ_CHUNK_SIZE]\n                          [--ds_can_coh_chunk_size DS_CAN_COH_CHUNK_SIZE]\n                          [--ds_can_coh_ave_fig DS_CAN_COH_AVE_FIG] [--log LOG]\n                          rslc is_shp is_ds_can ds_can_coh\n\npositional arguments:\n  rslc                                  input: rslc stack\n  is_shp                                input: bool array indicating the SHPs of\n                                        every pixel\n  is_ds_can                             input: bool array indicating DS\n                                        candidate\n  ds_can_coh                            output: complex coherence matrix for DS\n                                        candidate\n\noptions:\n  -h, --help                            show this help message and exit\n  --az_chunk_size AZ_CHUNK_SIZE         azimuth chunk size, optional. Default:\n                                        the azimuth chunk size in rslc stack\n  --ds_can_coh_chunk_size DS_CAN_COH_CHUNK_SIZE\n                                        chunk size of output zarr dataset,\n                                        optional. Default: automatically\n                                        determined\n  --ds_can_coh_ave_fig DS_CAN_COH_AVE_FIG\n                                        path to the plot of average coherence\n                                        matrix of DS candidate, optional.\n                                        Default: no plot\n  --log LOG                             log file. Default: no log file"
  },
  {
    "objectID": "CLI/utils/dask.html",
    "href": "CLI/utils/dask.html",
    "title": "dask",
    "section": "",
    "text": "source\n\npad_internal\n\n pad_internal (arr:<function array>, depth:dict=None)\n\nPad zero between block boundaries, currently one pad zero are supported"
  },
  {
    "objectID": "CLI/utils/logging.html",
    "href": "CLI/utils/logging.html",
    "title": "logging",
    "section": "",
    "text": "source\n\nget_logger\n\n get_logger (name:str=None, logfile:str=None, level:str=None)\n\nget logger for decorrelation cli application\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nname\nstr\nNone\nname of the application, optional. default: the function name that call this function\n\n\nlogfile\nstr\nNone\nlogfile, optional. default: no logfile\n\n\nlevel\nstr\nNone\nlog level, debug or info, optional. default: info\n\n\n\n\ndef log_test():\n    logger = get_logger(logfile='test.log')\n    logger.debug(\"This is a debug log.\")\n    logger.info(\"This is a info log.\")\n    logger.warning(\"This is a warning log.\")\n    logger.error(\"This is a error log.\")\n    logger.critical(\"This is a critical log.\")\n\n\nlog_test()\n\n2023-05-09 23:18:14 - log_test - INFO - This is a info log.\n2023-05-09 23:18:14 - log_test - WARNING - This is a warning log.\n2023-05-09 23:18:14 - log_test - ERROR - This is a error log.\n2023-05-09 23:18:14 - log_test - CRITICAL - This is a critical log."
  }
]