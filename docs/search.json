[
  {
    "objectID": "api/shp.html",
    "href": "api/shp.html",
    "title": "SHP",
    "section": "",
    "text": "source\n\n\n\n searchsorted (ref:cupy.ndarray, sec:cupy.ndarray)\n\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nref\nndarray\nmulti dimentional array\n\n\nsec\nndarray\nmulti dimentional array\n\n\nReturns\nndarray\nmulti dimentional index array, dtype: cp.int\n\n\n\nFind the indices from the innermost dimension of ref such that, if the corresponding values in sec were inserted before the indices. ref.shape must equals to sec.shape. For example:\n\nref = cp.arange(20, dtype=cp.float32)\nsec = cp.arange(5.5,25.5, dtype=cp.float32)\nout = searchsorted2d(ref,sec)\n\n\nref = cp.arange(20, dtype=cp.float32).reshape(2,2,5)\nsec = cp.arange(5.5,15.5, dtype=cp.float32).reshape(2,1,5)\nsec = cp.tile(sec,(1,2,2))\n\n\nref\n\narray([[[ 0.,  1.,  2.,  3.,  4.],\n        [ 5.,  6.,  7.,  8.,  9.]],\n\n       [[10., 11., 12., 13., 14.],\n        [15., 16., 17., 18., 19.]]], dtype=float32)\n\n\n\nsec\n\narray([[[ 5.5,  6.5,  7.5,  8.5,  9.5,  5.5,  6.5,  7.5,  8.5,  9.5],\n        [ 5.5,  6.5,  7.5,  8.5,  9.5,  5.5,  6.5,  7.5,  8.5,  9.5]],\n\n       [[10.5, 11.5, 12.5, 13.5, 14.5, 10.5, 11.5, 12.5, 13.5, 14.5],\n        [10.5, 11.5, 12.5, 13.5, 14.5, 10.5, 11.5, 12.5, 13.5, 14.5]]],\n      dtype=float32)\n\n\n\nout = searchsorted2d(ref,sec)\nout\n\narray([[[5, 5, 5, 5, 5, 5, 5, 5, 5, 5],\n        [1, 2, 3, 4, 5, 1, 2, 3, 4, 5]],\n\n       [[1, 2, 3, 4, 5, 1, 2, 3, 4, 5],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]])\n\n\n\n# test\nassert (out[0,1,:5] == cp.array([1, 2, 3, 4, 5],dtype=cp.int64)).all()\n\n\n# test the speed of cp.max()\nref = cp.arange(20000, dtype=cp.float32).reshape(200,100)\nprint(benchmark(cp.max,(ref,), n_repeat=1000))\nprint(benchmark(cp.max,(ref[:,-1],), n_repeat=1000))\n\namax                :    CPU:   18.950 us   +/- 1.750 (min:   18.280 / max:   71.205) us     GPU-0:   23.514 us   +/- 1.772 (min:   22.528 / max:   74.752) us\namax                :    CPU:   17.984 us   +/- 0.606 (min:   17.390 / max:   26.476) us     GPU-0:   21.877 us   +/- 0.895 (min:   20.480 / max:   36.864) us\n\n\n\n# test the speed between cupy and torch\n# def torch_searchsorted(ref,sec):\n#     _ref = torch.as_tensor(ref)\n#     _sec = torch.as_tensor(sec)\n#     indices = torch.searchsorted(_ref,_sec,side='right')\n#     indices = cp.asarray(indices)\n#     return indices\n# width = 100\n# nlines = 10000\n# ref = cp.arange(-1.1,-1.1+width*nlines, dtype=cp.float32).reshape(nlines,width)\n# sec = cp.arange(-1.5,-1.5+width*nlines, dtype=cp.float32).reshape(nlines,width)\n# print(benchmark(torch_searchsorted,(ref, sec), n_repeat=100))\n# print(benchmark(searchsorted,(ref, sec), n_repeat=100))\n\n\nsource\n\n\n\n\n ecdf_distance (data1:cupy.ndarray, data2, n:int=0)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata1\nndarray\n\ndata set 1\n\n\ndata2\n\n\ndata set 2\n\n\nn\nint\n0\nnumber of dimensions to compare\n\n\n\n\nref = cp.arange(20, dtype=cp.float32).reshape(2,2,5)\nsec = cp.arange(-1,19, dtype=cp.float32).reshape(2,2,5)\n\n\nref\n\narray([[[ 0.,  1.,  2.,  3.,  4.],\n        [ 5.,  6.,  7.,  8.,  9.]],\n\n       [[10., 11., 12., 13., 14.],\n        [15., 16., 17., 18., 19.]]], dtype=float32)\n\n\n\nsec\n\narray([[[-1.,  0.,  1.,  2.,  3.],\n        [ 4.,  5.,  6.,  7.,  8.]],\n\n       [[ 9., 10., 11., 12., 13.],\n        [14., 15., 16., 17., 18.]]], dtype=float32)\n\n\n\necdf_distance(ref,sec)\n\narray([[0.2, 0.2],\n       [0.2, 0.2]])\n\n\n\nsource\n\n\n\n\n ks_2sam (data1:cupy.ndarray, data2:cupy.ndarray, alpha:float=0.9)\n\nGPU version of ks 2 sample test\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata1\nndarray\n\nsamples to be test, each innermost vector is samples from one distribution\n\n\ndata2\nndarray\n\nthe seconds stack of samples,\n\n\nalpha\nfloat\n0.9\nsignificant value, the bigger the stricter in selecting SHP, between 0 and 1\n\n\nReturns\narray\n\nstack of bool, if SHP or not\n\n\n\n\n# a test is needed here"
  },
  {
    "objectID": "api/test_searchsorted.html",
    "href": "api/test_searchsorted.html",
    "title": "speed test for searchsorted",
    "section": "",
    "text": "import cupy as cp\nimport torch\nfrom cupyx.profiler import benchmark\nimport torchsearchsorted\n\n\ndef torch_searchsorted(ref:cp.ndarray, # N-D cupy array, containing monotonically increasing sequence on the innermost dimension\n                  sec:cp.ndarray, # N-D cupy array, containing the search value(s)\n                 ) -> cp.ndarray: # Array of insertion points with the same shape as `secs`\n    '''a simple `torch.searchsorted` wrapper for cupy array'''\n    _ref = torch.as_tensor(ref)\n    _sec = torch.as_tensor(sec)\n    indices = torch.searchsorted(_ref,_sec,side='right')\n    indices = cp.asarray(indices)\n    return indices\n\n\ndef cupy_searchsorted(a,b):\n    m,n = a.shape\n    max_num = cp.maximum(a.max() - a.min(), b.max() - b.min()) + 1\n    r = max_num*cp.arange(a.shape[0])[:,None]\n    p = cp.searchsorted( (a+r).ravel(), (b+r).ravel(), side='right' ).reshape(m,-1)\n    return p - n*(cp.arange(m)[:,None])\n\n\ndef stream_searchsorted(a,b):\n    m,n = a.shape\n    out = cp.empty_like(b,dtype=cp.int64)\n    map_streams = []\n    for i in range(m):\n        map_streams.append(cp.cuda.stream.Stream(non_blocking=True))\n    device = cp.cuda.Device()\n    for i, stream in enumerate(map_streams):\n        with stream:\n            out[i,:] = cp.searchsorted(a[i,:],b[i,:],side='right')\n    device.synchronize()\n    return out\n\n\nref = cp.arange(20, dtype=cp.float32).reshape(4,5)\nsec = cp.arange(-1,19, dtype=cp.float32).reshape(4,5)\n\n\ntorch_out = torch_searchsorted(ref,sec)\ncupy_out = cupy_searchsorted(ref,sec)\nstream_out = stream_searchsorted(ref,sec)\n\n\ntorch_out\n\narray([[0, 1, 2, 3, 4],\n       [0, 1, 2, 3, 4],\n       [0, 1, 2, 3, 4],\n       [0, 1, 2, 3, 4]])\n\n\n\ncupy_out\n\narray([[0, 1, 2, 3, 4],\n       [0, 1, 2, 3, 4],\n       [0, 1, 2, 3, 4],\n       [0, 1, 2, 3, 4]])\n\n\n\nstream_out\n\narray([[0, 1, 2, 3, 4],\n       [0, 1, 2, 3, 4],\n       [0, 1, 2, 3, 4],\n       [0, 1, 2, 3, 4]])\n\n\n\nwidth = 100\nnlines = 10000\nref = cp.arange(-1.1,-1.1+width*nlines, dtype=cp.float32).reshape(nlines,width)\nsec = cp.arange(-1.5,-1.5+width*nlines, dtype=cp.float32).reshape(nlines,width)\nprint(benchmark(torch_searchsorted,(ref, sec), n_repeat=100))\nprint(benchmark(cupy_searchsorted,(ref, sec), n_repeat=100))\n#print(benchmark(stream_searchsorted,(ref, sec), n_repeat=100))\n\ntorch_searchsorted  :    CPU: 8254.008 us   +/-373.205 (min: 8081.082 / max:10619.253) us     GPU-0: 8885.001 us   +/-372.529 (min: 8713.888 / max:11242.240) us\ncupy_searchsorted   :    CPU:  359.469 us   +/- 6.071 (min:  348.583 / max:  375.733) us     GPU-0:  380.876 us   +/- 5.246 (min:  372.736 / max:  397.312) us\n\n\n\n_ref = torch.as_tensor(ref)\n_sec = torch.as_tensor(sec)\nprint(benchmark(torch.searchsorted,(_ref, _sec), n_repeat=100))\nprint(benchmark(torchsearchsorted.searchsorted,(_ref, _sec), n_repeat=100))\n\nsearchsorted        :    CPU: 5718.757 us   +/-322.460 (min: 5644.038 / max: 8415.207) us     GPU-0: 5726.684 us   +/-322.698 (min: 5651.424 / max: 8422.784) us\nsearchsorted        :    CPU:13999.385 us   +/-88.953 (min:13972.137 / max:14832.605) us     GPU-0:14007.932 us   +/-89.373 (min:13980.384 / max:14843.904) us\n\n\nThe best way is to write a new cuda kernel for it."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "decorrelation",
    "section": "",
    "text": "Documentation"
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "decorrelation",
    "section": "Install",
    "text": "Install\nWith conda:\nconda install -c conda-forge decorrelation\nWith pip:\npip install decorrelation\nIn development mode:\ngit clone git@github.com:kanglcn/decorrelation.git ./decorrelation\ncd ./decorrelation\npip install -e '.[dev]'"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "decorrelation",
    "section": "How to use",
    "text": "How to use\n\nimport decorrelation as dc\n\nPlease refer to the Documentation for detailed usage."
  },
  {
    "objectID": "index.html#contact-us",
    "href": "index.html#contact-us",
    "title": "decorrelation",
    "section": "Contact us",
    "text": "Contact us\n\nMost discussion happens on GitHub. Feel free to open an issue or comment on any open issue or pull request.\nuse github discussions to ask questions or leave comments."
  },
  {
    "objectID": "index.html#contribution",
    "href": "index.html#contribution",
    "title": "decorrelation",
    "section": "Contribution",
    "text": "Contribution\n\nPull requests are welcomed! Before making a pull request, please open an issue to talk about it.\nWe have notice many excellent open-source packages are rarely paid attention to due to lake of documentation. The package is developed with the nbdev, a notebook-driven development platform. Developers only needs to simply write notebooks with lightweight markup and get high-quality documentation, tests, continuous integration, and packaging automatically."
  },
  {
    "objectID": "tutorials/data_transform.html",
    "href": "tutorials/data_transform.html",
    "title": "decorrelation",
    "section": "",
    "text": "import cupy as cp\nimport numpy as np\nfrom decorrelation.shp import ks_2sam\nfrom matplotlib import pyplot as plt\n\n\n\nrslc = cp.load('./rslc.npy')\nrslc = rslc[700:800,0:100,:]\n\n\n# here rslc is nlines*width*nimage\n\n\nrslc.shape\n\n(100, 100, 17)\n\n\n\nrmli = cp.abs(rslc)**2\n\n\naz_half_win = 5\nr_half_win = 5\naz_index = np.arange(az_half_win,rslc.shape[0]-az_half_win,dtype=int)\nr_index = np.arange(r_half_win,rslc.shape[1]-az_half_win,dtype=int)\naz_win_index = np.arange(-az_half_win,az_half_win+1,dtype=int)\nr_win_index = np.arange(-r_half_win,r_half_win+1,dtype=int)\n\n\nr_win_index\n\narray([-5, -4, -3, -2, -1,  0,  1,  2,  3,  4,  5])\n\n\n\n# az_index, range_index, az_shift, range_shift\na = np.meshgrid(az_index,r_index,az_win_index,r_win_index)\na = np.stack(a)\n\n\na.shape\n\n(4, 90, 90, 11, 11)\n\n\n\n# first 0 means return az_index, index of az_index, index of range_index,\nshp_table_shape = a[0,:,:,:,:].shape\na[0,:,:,:,:].reshape(-1)\n\narray([ 5,  5,  5, ..., 94, 94, 94])\n\n\n\nsorted_rmli = cp.sort(rmli,axis=-1)\nref_shp_stack = sorted_rmli[a[0,:,:,:,:].reshape(-1),a[1,:,:,:,:].reshape(-1)]\nsec_shp_stack = sorted_rmli[(a[0,:,:,:,:]+a[2,:,:,:,:]).reshape(-1),(a[1,:,:,:,:]+a[3,:,:,:,:]).reshape(-1)]\n\n\nref_shp_stack.shape\n\n(980100, 17)\n\n\n\nsec_shp_stack.shape\n\n(980100, 17)\n\n\n\nis_shp_stack = ks_2sam(ref_shp_stack,sec_shp_stack,0.5)\n\n\nis_shp_stack\n\narray([False, False, False, ..., False, False, False])\n\n\n\nis_shp_dense = is_shp_stack.reshape(shp_table_shape)\n\n\nis_shp_dense.shape\n\n(90, 90, 11, 11)\n\n\n\nis_shp_dense.reshape(*is_shp_dense.shape[0:-2],-1).shape\n\n(90, 90, 121)\n\n\n\nshp_number_thres = 2\nnum_shp = is_shp_dense.reshape(*is_shp_dense.shape[0:-2],-1).sum(axis=-1)\nnum_shp.shape\n# select base on number of num_shp\n\n(90, 90)\n\n\n\nnum_shp\n\narray([[ 6,  1,  1, ..., 33, 54, 12],\n       [ 7,  3,  3, ..., 45, 37, 46],\n       [ 3, 19, 20, ..., 46, 29, 51],\n       ...,\n       [ 5, 31, 14, ..., 55, 27, 34],\n       [17, 21, 34, ..., 25, 17, 35],\n       [ 2,  8,  5, ..., 44, 35,  5]])\n\n\n\nrslc_0 = rslc[a[0,:,:,:,:].reshape(-1),a[1,:,:,:,:].reshape(-1),0].reshape(*shp_table_shape[0:-2],-1)\nrslc_1 = rslc[(a[0,:,:,:,:]+a[2,:,:,:,:]).reshape(-1),(a[1,:,:,:,:]+a[3,:,:,:,:]).reshape(-1),1].reshape(*shp_table_shape[0:-2],-1)\nrslc_1 = rslc_1*is_shp_dense.reshape(*is_shp_dense.shape[0:-2],-1) # set non-shp as zero\ndiff = cp.sum(rslc_0*rslc_1.conj(),axis=-1)\n\n\ndiff.shape\n\n(90, 90)\n\n\n\ndef bg_alpha(pwr):\n    _pwr = np.power(pwr,0.35)\n    cv = _pwr.mean()*2.5\n    v = (_pwr.clip(0., cv))/cv\n    return v\n\n\nplot_bg = rmli[a[0,:,:,0,0].reshape(-1),a[1,:,:,0,0].reshape(-1),0].reshape(*shp_table_shape[0:-2])\nplot_bg = cp.asnumpy(plot_bg)\nplot_data = cp.asnumpy(cp.angle(diff))\n\nextent = (np.min(r_index), np.max(r_index), np.max(az_index), np.min(az_index))\n\nalpha = bg_alpha(plot_bg)\n\nfig,ax = plt.subplots(1,1,figsize=(16,9))\nxlabel = 'Range Index'\nylabel = 'Azimuth Index'\npcm0 = ax.imshow(plot_data,alpha=alpha,interpolation='nearest',cmap='hsv',extent=extent)\n# the real image showed is alpha*rgb + (1-alpha)*facecolor\nax.set(facecolor = \"black\")\nax.set(title='Interferogram',xlabel=xlabel,ylabel=ylabel)\nfig.colorbar(pcm0,ax=ax)\n\n<matplotlib.colorbar.Colorbar>"
  },
  {
    "objectID": "tutorials/loaddata.html",
    "href": "tutorials/loaddata.html",
    "title": "decorrelation",
    "section": "",
    "text": "import py_gamma as pg\nimport cupy as cp\nimport numpy as np\nfrom pathlib import Path\nfrom path import read_Path\nfrom geocode import rdc_width_nlines\nimport tempfile\nfrom matplotlib import pyplot as plt\nimport colorcet\nimport pandas as pd\nThe method behind the flattenSLC:\nLet the value of i-th rslc be \\(s_i\\), the simulated phase due to DEM and position difference be \\(u_{ij}\\). D-InSAR basically is: \\[d_{ij}=s_i \\times s_j^* \\times e^{-ju_{ij}}.\\] Let the distance between satellite and ground target for th i-th observation be \\(l_i\\). Then, the simulated phase for DInSAR \\[u_{ij} = l_i-l_j.\\] So, a simple conclusion is \\[u_{ij}-u_{ik}=-u_{jk}.\\] If we define \\[s_i^{\\prime} = s_i \\times e^{ju_{xi}},\\] where \\(X\\) can be any arbitrary interger less than \\(N\\)- the total number of the RSLCs. Then we can find that \\[int_{ij}^{\\prime} =  s_i^{\\prime} \\times s_j^{\\prime*} = s_i \\times s_j^* \\times e^{j(u_{xi}-u_{xj})} = s_i \\times s_j^* \\times e^{j(u_{xi}-u_{xj})} = s_i \\times s_j^* \\times e^{-ju_{ij}} = d_{ij}.\\]\nWe call \\(s_i^{\\prime}\\) as flattened RSLC. The advantage of flattened RSLC is DInSAR can be easily calculated by simple conjugate multiplication.\nThe angle difference between this diff and diff generated with mk_diff_2d can reach to 0.1 (only test on multilooked images), who can explain it? test done: - even the same reference is selected, the difference can also reach 0.1."
  },
  {
    "objectID": "tutorials/loaddata.html#image_show",
    "href": "tutorials/loaddata.html#image_show",
    "title": "decorrelation",
    "section": "image_show",
    "text": "image_show\n\ndef bg_alpha(pwr):\n    _pwr = np.power(pwr,0.35)\n    cv = _pwr.mean()*2.5\n    v = (_pwr.clip(0., cv))/cv\n    return v\n\n\noriginal_diff = pg.read_image('/home/kangl/scratch/BarryArm/ALOS2/diff_2_4/20220829_20221024.diff',width=917,dtype='fcomplex')\npwr = pg.read_image('/home/kangl/scratch/BarryArm/ALOS2/rmli_2_4/20220829.rmli',width=917,dtype='float')\n\nimage:\n  width: 917  number of lines: 625\ndata read from image:\n  column offset (x0): 0  row offset (y0): 0  \n  width: 917  number of lines: 625\nimage:\n  width: 917  number of lines: 625\ndata read from image:\n  column offset (x0): 0  row offset (y0): 0  \n  width: 917  number of lines: 625\n\n\n\nalpha = bg_alpha(pwr)\nfig,ax = plt.subplots(1,1,figsize=(16,9))\nxlabel = 'Range Index'\nylabel = 'Azimuth Index'\n# 对于存在噪声的数据，不要使用matplotlib默认的插值方式\npcm0 = ax.imshow(np.angle(original_diff),alpha=alpha,interpolation='nearest',cmap=cm)\n# the real image showed is alpha*rgb + (1-alpha)*facecolor\nax.set(facecolor = \"black\")\nax.set(title='Interferogram',xlabel=xlabel,ylabel=ylabel)\nfig.colorbar(pcm0,ax=ax)\n\n<matplotlib.colorbar.Colorbar>"
  },
  {
    "objectID": "tutorials/data_transform_loop.html",
    "href": "tutorials/data_transform_loop.html",
    "title": "decorrelation",
    "section": "",
    "text": "import cupy as cp\nimport numpy as np\nfrom decorrelation.shp import ks_2sam\nfrom matplotlib import pyplot as plt\nfrom tqdm import tqdm\n\n\n\nrslc = cp.load('./rslc.npy')\nrmli = cp.abs(rslc)**2\nsorted_rmli = cp.sort(rmli,axis=-1)\n\n\nref_image = 15\nsec_image = 16\ndiff = rslc[:,:,ref_image]*rslc[:,:,sec_image].conj()\nds_diff = cp.copy(diff)\nml_diff = cp.copy(diff)\n\n\n# here rslc is nlines*width*nimage\n\n\nrslc.shape\n\n(2500, 1834, 17)\n\n\n\nrmli = cp.abs(rslc)**2\naz_half_win = 10\nr_half_win = 10\n\n\npatch_size = 50\n\n\ndef patch_slice(data_shape,patch_size,boundary_size):\n    max_az = data_shape[0]-boundary_size[0]-1\n    min_az = boundary_size[0]\n    max_r = data_shape[1]-boundary_size[1]-1 # notice right slice is open for python [min_az,max_az)\n    min_r = boundary_size[1]\n    \n    n_az_patch = (max_az-min_az)//patch_size[0] # the finall small patch not included\n    n_r_patch = (max_r-min_r)//patch_size[1]\n    az_slices = [slice(min_az+i*patch_size[0],min_az+(i+1)*patch_size[0]) for i in range(n_az_patch)]\n    az_slices.append(slice(min_az+n_az_patch*patch_size[0],max_az))\n    r_slices = [slice(min_r+i*patch_size[1],min_r+(i+1)*patch_size[1]) for i in range(n_r_patch)]\n    r_slices.append(slice(min_r+n_r_patch*patch_size[1],max_r))\n    return az_slices, r_slices\n\n\naz_slices, r_slices = patch_slice(rslc.shape[:2],(patch_size,patch_size),(az_half_win,r_half_win))\n\n\nfrom itertools import product\nfor az_slice,r_slice in tqdm(product(az_slices,r_slices),total=len(az_slices)*len(r_slices)):\n    az_index = np.arange(az_slice.start,az_slice.stop,dtype=int)\n    r_index = np.arange(r_slice.start,r_slice.stop,dtype=int)\n    az_win_index = np.arange(-az_half_win,az_half_win+1,dtype=int)\n    r_win_index = np.arange(-r_half_win,r_half_win+1,dtype=int)\n\n    # az_index, range_index, az_shift, range_shift\n    a = np.meshgrid(az_index,r_index,az_win_index,r_win_index,indexing='ij')\n    a = np.stack(a)\n\n    # first 0 means return az_index, index of az_index, index of range_index,\n    shp_table_shape = a[0,:,:,:,:].shape\n\n    ref_shp_stack = sorted_rmli[a[0,:,:,:,:].reshape(-1),a[1,:,:,:,:].reshape(-1)]\n    sec_shp_stack = sorted_rmli[(a[0,:,:,:,:]+a[2,:,:,:,:]).reshape(-1),(a[1,:,:,:,:]+a[3,:,:,:,:]).reshape(-1)]\n\n    is_shp_stack = ks_2sam(ref_shp_stack,sec_shp_stack,0)\n    is_shp_dense = is_shp_stack.reshape(shp_table_shape)\n\n    shp_number_thres = 2\n    num_shp = is_shp_dense.reshape(*is_shp_dense.shape[0:-2],-1).sum(axis=-1)\n    num_shp.shape\n    #TODO select base on number of num_shp\n\n    rslc_0 = rslc[(a[0,:,:,:,:]+a[2,:,:,:,:]).reshape(-1),(a[1,:,:,:,:]+a[3,:,:,:,:]).reshape(-1),ref_image].reshape(*shp_table_shape[0:-2],-1)\n    rslc_1 = rslc[(a[0,:,:,:,:]+a[2,:,:,:,:]).reshape(-1),(a[1,:,:,:,:]+a[3,:,:,:,:]).reshape(-1),sec_image].reshape(*shp_table_shape[0:-2],-1)\n    rslc_1 = rslc_1*is_shp_dense.reshape(*is_shp_dense.shape[0:-2],-1) # set non-shp as zero\n    ml_diff[az_slice,r_slice] = cp.sum(rslc_0*rslc_1.conj(),axis=-1)\n\n100%|██████████| 1850/1850 [04:47<00:00,  6.44it/s]\n\n\n\nref_image = 15\nsec_image = 16\n\n\n# here rslc is nlines*width*nimage\n\n\nrslc.shape\n\n(2500, 1834, 17)\n\n\n\nrmli = cp.abs(rslc)**2\naz_half_win = 1\nr_half_win = 1\n\n\npatch_size = 200\n\n\ndef patch_slice(data_shape,patch_size,boundary_size):\n    max_az = data_shape[0]-boundary_size[0]-1\n    min_az = boundary_size[0]\n    max_r = data_shape[1]-boundary_size[1]-1 # notice right slice is open for python [min_az,max_az)\n    min_r = boundary_size[1]\n    \n    n_az_patch = (max_az-min_az)//patch_size[0] # the finall small patch not included\n    n_r_patch = (max_r-min_r)//patch_size[1]\n    az_slices = [slice(min_az+i*patch_size[0],min_az+(i+1)*patch_size[0]) for i in range(n_az_patch)]\n    az_slices.append(slice(min_az+n_az_patch*patch_size[0],max_az))\n    r_slices = [slice(min_r+i*patch_size[1],min_r+(i+1)*patch_size[1]) for i in range(n_r_patch)]\n    r_slices.append(slice(min_r+n_r_patch*patch_size[1],max_r))\n    return az_slices, r_slices\n\n\naz_slices, r_slices = patch_slice(rslc.shape[:2],(patch_size,patch_size),(az_half_win,r_half_win))\n\n\nfrom itertools import product\nfor az_slice,r_slice in tqdm(product(az_slices,r_slices),total=len(az_slices)*len(r_slices)):\n    az_index = np.arange(az_slice.start,az_slice.stop,dtype=int)\n    r_index = np.arange(r_slice.start,r_slice.stop,dtype=int)\n    az_win_index = np.arange(-az_half_win,az_half_win+1,dtype=int)\n    r_win_index = np.arange(-r_half_win,r_half_win+1,dtype=int)\n\n    # az_index, range_index, az_shift, range_shift\n    a = np.meshgrid(az_index,r_index,az_win_index,r_win_index,indexing='ij')\n    a = np.stack(a)\n\n    # first 0 means return az_index, index of az_index, index of range_index,\n    shp_table_shape = a[0,:,:,:,:].shape\n    a[0,:,:,:,:].reshape(-1)\n\n    ref_shp_stack = sorted_rmli[a[0,:,:,:,:].reshape(-1),a[1,:,:,:,:].reshape(-1)]\n    sec_shp_stack = sorted_rmli[(a[0,:,:,:,:]+a[2,:,:,:,:]).reshape(-1),(a[1,:,:,:,:]+a[3,:,:,:,:]).reshape(-1)]\n\n    is_shp_stack = ks_2sam(ref_shp_stack,sec_shp_stack,0.5)\n    is_shp_dense = is_shp_stack.reshape(shp_table_shape)\n\n    shp_number_thres = 2\n    num_shp = is_shp_dense.reshape(*is_shp_dense.shape[0:-2],-1).sum(axis=-1)\n    num_shp.shape\n    #TODO select base on number of num_shp\n\n    rslc_0 = rslc[(a[0,:,:,:,:]+a[2,:,:,:,:]).reshape(-1),(a[1,:,:,:,:]+a[3,:,:,:,:]).reshape(-1),ref_image].reshape(*shp_table_shape[0:-2],-1)\n    rslc_1 = rslc[(a[0,:,:,:,:]+a[2,:,:,:,:]).reshape(-1),(a[1,:,:,:,:]+a[3,:,:,:,:]).reshape(-1),sec_image].reshape(*shp_table_shape[0:-2],-1)\n    rslc_1 = rslc_1*is_shp_dense.reshape(*is_shp_dense.shape[0:-2],-1) # set non-shp as zero\n    ds_diff[az_slice,r_slice] = cp.sum(rslc_0*rslc_1.conj(),axis=-1)\n\n100%|██████████| 1850/1850 [04:35<00:00,  6.71it/s]\n\n\n\nplot_bg = rmli[:,:,0]\nplot_bg = cp.asnumpy(plot_bg)\nalpha = bg_alpha(plot_bg)\n\n\nfig,axes = plt.subplots(1,3,figsize=(23,7))\nxlabel = 'Range Index'\nylabel = 'Azimuth Index'\npcm0 = axes[0].imshow(cp.asnumpy(cp.angle(diff)),alpha=alpha,interpolation='nearest',cmap='hsv')\npcm1 = axes[1].imshow(cp.asnumpy(cp.angle(ml_diff)),alpha=alpha,interpolation='nearest',cmap='hsv')\npcm2 = axes[2].imshow(cp.asnumpy(cp.angle(ds_diff)),alpha=alpha,interpolation='nearest',cmap='hsv')\n# the real image showed is alpha*rgb + (1-alpha)*facecolor\nfor ax in axes:\n    ax.set(facecolor = \"black\")\naxes[0].set(title='Orignal Interferogram',xlabel=xlabel,ylabel=ylabel)\naxes[1].set(title='Multilook Interferogram',xlabel=xlabel,ylabel=ylabel)\naxes[2].set(title='DS Interferogram',xlabel=xlabel,ylabel=ylabel)\nfig.colorbar(pcm0,ax=axes[0])\nfig.colorbar(pcm1,ax=axes[1])\nfig.colorbar(pcm1,ax=axes[2])\n\n<matplotlib.colorbar.Colorbar>\n\n\n\n\n\n\ndef bg_alpha(pwr):\n    _pwr = np.power(pwr,0.35)\n    cv = _pwr.mean()*2.5\n    v = (_pwr.clip(0., cv))/cv\n    return v\n\n\nplot_bg = rmli[a[0,:,:,0,0].reshape(-1),a[1,:,:,0,0].reshape(-1),0].reshape(*shp_table_shape[0:-2])\nplot_bg = cp.asnumpy(plot_bg)\nplot_data = cp.asnumpy(cp.angle(diff))\n\n#extent = (np.min(r_index), np.max(r_index), np.max(az_index), np.min(az_index))\n\nalpha = bg_alpha(plot_bg)\n\nfig,ax = plt.subplots(1,1,figsize=(16,9))\nxlabel = 'Range Index'\nylabel = 'Azimuth Index'\npcm0 = ax.imshow(plot_data,alpha=alpha,interpolation='nearest',cmap='hsv')\n# the real image showed is alpha*rgb + (1-alpha)*facecolor\nax.set(facecolor = \"black\")\nax.set(title='Interferogram',xlabel=xlabel,ylabel=ylabel)\nfig.colorbar(pcm0,ax=ax)\n\n<matplotlib.colorbar.Colorbar>"
  }
]