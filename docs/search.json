[
  {
    "objectID": "CLI/utils/logging.html",
    "href": "CLI/utils/logging.html",
    "title": "logging",
    "section": "",
    "text": "source\n\nget_logger\n\n get_logger (name:str=None, logfile:str=None)\n\nget logger for decorrelation cli application\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nname\nstr\nNone\nname of the application, optional. default: the function name that call this function\n\n\nlogfile\nstr\nNone\nlogfile, optional. default: no logfile\n\n\n\n\ndef log_test():\n    logger = get_logger(logfile='test.log')\n    logger.debug(\"This is a debug log.\")\n    logger.info(\"This is a info log.\")\n    logger.warning(\"This is a warning log.\")\n    logger.error(\"This is a error log.\")\n    logger.critical(\"This is a critical log.\")\n\n\nlog_test()\n\n2023-04-30 20:47:05 - log_test - INFO - This is a info log.\n2023-04-30 20:47:05 - log_test - WARNING - This is a warning log.\n2023-04-30 20:47:05 - log_test - ERROR - This is a error log.\n2023-04-30 20:47:05 - log_test - CRITICAL - This is a critical log."
  },
  {
    "objectID": "CLI/shp.html",
    "href": "CLI/shp.html",
    "title": "shp",
    "section": "",
    "text": "source\n\nde_shp_test\n\n de_shp_test (rslc:str, pvalue:str, az_half_win:int, r_half_win:int,\n              method:str=None, r_chunk_size:int=None,\n              az_chunk_size:int=None, log:str=None)\n\nSHP identification through hypothetic test.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nrslc\nstr\n\ninput: rslc stack\n\n\npvalue\nstr\n\noutput: the p value of the test\n\n\naz_half_win\nint\n\nazimuth half window size\n\n\nr_half_win\nint\n\nrange half window size\n\n\nmethod\nstr\nNone\nSHP identification method,optional. Default: ks\n\n\nr_chunk_size\nint\nNone\nrange chunk size, Optional. Default: the range chunk size in rslc stack\n\n\naz_chunk_size\nint\nNone\nazimuth chunk size, optional. Default: the azimuth chunk size in rslc stack\n\n\nlog\nstr\nNone\nlog file, optional. Default: no log file\n\n\n\nThis function is a wrapper of functions in decorrelation.shp that provides file interface. Please refer it for the usage. It utilizes dask for parallel and distributed computation. Compared with the functions in decorrelation.shp, this function splits the dataset into several chunks and the computation in these chunks can run in parallel on multi-GPUs.\nThe r_chunk_size and az_chunk_size is used to determine how many pixels in range and azimuth in one chunk. The chunk size of the output pvalue is also setted according to them.\n\nrslcs = '../../data/rslc.zarr'\npvalue = './pvalue.zarr'\naz_half_win = 5\nr_half_win = 5\nmethod = None\nr_chunk_size = 1000\naz_chunk_size = 1000\n\n\nde_shp_test(rslcs,pvalue,az_half_win=5,r_half_win=5, method=None, r_chunk_size=1000,az_chunk_size=1000,log='de_shp_test.log')\n\n2023-05-01 03:40:26 - de_shp_test - INFO - hypothetic test method: ks\n2023-05-01 03:40:26 - de_shp_test - INFO - rslc dateset shape: (2500, 1834, 17)\n2023-05-01 03:40:26 - de_shp_test - INFO - rslc dataset chunks: (1000, 1000, 17)\n2023-05-01 03:40:26 - de_shp_test - INFO - parallel processing azimuth chunk size: 1000\n2023-05-01 03:40:26 - de_shp_test - INFO - parallel processing range chunk size: 1000\n2023-05-01 03:40:26 - de_shp_test - INFO - starting dask CUDA local cluster.\n\n\n2023-05-01 03:40:31,716 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n2023-05-01 03:40:31,716 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n2023-05-01 03:40:31,748 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n2023-05-01 03:40:31,748 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n2023-05-01 03:40:31,800 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n2023-05-01 03:40:31,800 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n2023-05-01 03:40:31,807 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n2023-05-01 03:40:31,807 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n2023-05-01 03:40:31,817 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n2023-05-01 03:40:31,817 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n2023-05-01 03:40:31,821 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n2023-05-01 03:40:31,821 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n2023-05-01 03:40:31,838 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n2023-05-01 03:40:31,838 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n2023-05-01 03:40:31,840 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n2023-05-01 03:40:31,840 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n\n\n2023-05-01 03:40:36 - de_shp_test - INFO - dask local CUDA cluster started.\n2023-05-01 03:40:36 - de_shp_test - INFO - rslc dask array shape: (2500, 1834, 17)\n2023-05-01 03:40:36 - de_shp_test - INFO - rslc dask array chunks: ((1000, 1000, 500), (1000, 834), (17,))\n2023-05-01 03:40:36 - de_shp_test - INFO - azimuth half window size: 5; azimuth window size: 11\n2023-05-01 03:40:36 - de_shp_test - INFO - range half window size: 5; range window size: 11\n2023-05-01 03:40:36 - de_shp_test - INFO - setting shared boundaries between rlsc chunks.\n2023-05-01 03:40:36 - de_shp_test - INFO - rslc dask array with overlap shape: (2520, 1844, 17)\n2023-05-01 03:40:36 - de_shp_test - INFO - rslc dask array with overlap chunks: ((1005, 1010, 505), (1005, 839), (17,))\n2023-05-01 03:40:37 - de_shp_test - INFO - rmli dask array with overlap shape: (2520, 1844, 17)\n2023-05-01 03:40:37 - de_shp_test - INFO - rmli dask array with overlap chunks: ((1005, 1010, 505), (1005, 839), (17,))\n2023-05-01 03:40:37 - de_shp_test - INFO - applying test on sorted rmli stack.\n2023-05-01 03:40:37 - de_shp_test - INFO - p value generated\n2023-05-01 03:40:37 - de_shp_test - INFO - p value shape: (2520, 1844, 11, 11)\n2023-05-01 03:40:37 - de_shp_test - INFO - p value chunks: ((1005, 1010, 505), (1005, 839), (11,), (11,))\n2023-05-01 03:40:37 - de_shp_test - INFO - trim shared boundaries between p value chunks\n2023-05-01 03:40:37 - de_shp_test - INFO - trimmed p value shape: (2500, 1834, 11, 11)\n2023-05-01 03:40:37 - de_shp_test - INFO - trimmed p value chunks: ((1000, 1000, 500), (1000, 834), (11,), (11,))\n2023-05-01 03:40:37 - de_shp_test - INFO - saving p value.\n2023-05-01 03:40:37 - de_shp_test - INFO - computing graph setted. doing all the computing.\n2023-05-01 03:40:41 - de_shp_test - INFO - computing finished.\n2023-05-01 03:40:43 - de_shp_test - INFO - dask cluster closed.\n\n\nThis function can also be called from command line directly:\n\n!de_shp_test -h\n\nusage: de_shp_test [-h] [--method METHOD] [--r_chunk_size R_CHUNK_SIZE]\n                   [--az_chunk_size AZ_CHUNK_SIZE] [--log LOG]\n                   rslc pvalue az_half_win r_half_win\n\nSHP identification through hypothetic test.\n\npositional arguments:\n  rslc                           input: rslc stack\n  pvalue                         output: the p value of the test\n  az_half_win                    azimuth half window size\n  r_half_win                     range half window size\n\noptions:\n  -h, --help                     show this help message and exit\n  --method METHOD                SHP identification method,optional. Default: ks\n  --r_chunk_size R_CHUNK_SIZE    range chunk size, Optional. Default: the range\n                                 chunk size in rslc stack\n  --az_chunk_size AZ_CHUNK_SIZE  azimuth chunk size, optional. Default: the\n                                 azimuth chunk size in rslc stack\n  --log LOG                      log file, optional. Default: no log file\n\n\n\nsource\n\n\nde_select_ds_can\n\n de_select_ds_can (pvalue:str, is_shp:str, is_ds_can:str,\n                   ds_can_is_shp:str, p_max:float=0.05,\n                   shp_num_min:int=50, r_chunk_size=None,\n                   az_chunk_size=None, ds_can_chunk_size=None,\n                   shp_num_fig=None, is_ds_can_fig=None, log=None)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npvalue\nstr\n\ninput: pvalue of hypothetic test\n\n\nis_shp\nstr\n\noutput: bool array indicating the SHPs of every pixel\n\n\nis_ds_can\nstr\n\noutput: bool array indicating DS candidate\n\n\nds_can_is_shp\nstr\n\noutput: bool array indicating the SHPs of DS candidate\n\n\np_max\nfloat\n0.05\nthreshold of p value to select SHP,optional. Default: 0.05\n\n\nshp_num_min\nint\n50\nthreshold of number of SHPs to select DS candidate,optional. Default: 50\n\n\nr_chunk_size\nNoneType\nNone\nrange chunk size, optional. Default: the range chunk size in pvalue\n\n\naz_chunk_size\nNoneType\nNone\nazimuth chunk size, optional. Default: the azimuth chunk size in pvalue\n\n\nds_can_chunk_size\nNoneType\nNone\nDS candidate chunk size, optional.\n\n\nshp_num_fig\nNoneType\nNone\npath to the plot of number of SHPs, optional. Default: no plot\n\n\nis_ds_can_fig\nNoneType\nNone\npath to the plot of DSs candidate distribution, optional. Default: no plot\n\n\nlog\nNoneType\nNone\nlog file. Default: no log file\n\n\n\n\npvalue = './pvalue.zarr'\nis_shp = './is_shp.zarr'\nis_ds_can = './is_ds_can.zarr'\nds_can_is_shp = './ds_can_is_shp.zarr'\nshp_num_fig = './shp_num_fig.png'\nis_ds_can_fig = './is_ds_can.png'\nr_chunk_size = 1000\naz_chunk_size = 1000\np_max = 0.05\nds_can_chunk_size = 100000\n\n\n#de_select_ds_can(pvalue,is_shp,is_ds_can,ds_can_is_shp,p_max=p_max)\nde_select_ds_can(pvalue,is_shp,is_ds_can,ds_can_is_shp,p_max=p_max,r_chunk_size=r_chunk_size,az_chunk_size=az_chunk_size,ds_can_chunk_size=ds_can_chunk_size,shp_num_fig=shp_num_fig,is_ds_can_fig=is_ds_can_fig)\n\n2023-05-01 03:40:46 - de_select_ds_can - INFO - pvalue dateset shape: (2500, 1834, 11, 11)\n2023-05-01 03:40:46 - de_select_ds_can - INFO - pvalue dataset chunks: (1000, 1000, 11, 11)\n2023-05-01 03:40:46 - de_select_ds_can - INFO - parallel processing azimuth chunk size: 1000\n2023-05-01 03:40:46 - de_select_ds_can - INFO - parallel processing range chunk size: 1000\n2023-05-01 03:40:46 - de_select_ds_can - INFO - starting dask local cluster.\n2023-05-01 03:40:48 - de_select_ds_can - INFO - dask local cluster started.\n2023-05-01 03:40:48 - de_select_ds_can - INFO - pvalue dask array shape: (2500, 1834, 11, 11)\n2023-05-01 03:40:48 - de_select_ds_can - INFO - pvalue dask array chunks: ((1000, 1000, 500), (1000, 834), (11,), (11,))\n2023-05-01 03:40:48 - de_select_ds_can - INFO - selecting SHPs based on pvalue threshold: 0.05\n2023-05-01 03:40:48 - de_select_ds_can - INFO - is_shp shape: (2500, 1834, 11, 11)\n2023-05-01 03:40:48 - de_select_ds_can - INFO - is_shp chunks: ((1000, 1000, 500), (1000, 834), (11,), (11,))\n2023-05-01 03:40:48 - de_select_ds_can - INFO - selecting DS candidates based on minimum of number of SHPs: 50\n2023-05-01 03:40:48 - de_select_ds_can - INFO - is_ds_can shape: (2500, 1834)\n2023-05-01 03:40:48 - de_select_ds_can - INFO - is_ds_can chunks: ((1000, 1000, 500), (1000, 834))\n2023-05-01 03:40:48 - de_select_ds_can - INFO - slicing is_shp on DS candidate.\n2023-05-01 03:40:51 - de_select_ds_can - INFO - is_ds_can shape: (740397, 11, 11)\n2023-05-01 03:40:51 - de_select_ds_can - INFO - is_ds_can chunks: ((168899, 177430, 146914, 128007, 62892, 56255), (11,), (11,))\n2023-05-01 03:40:51 - de_select_ds_can - INFO - rechunking ds_can_is_shp to chunk size: ((100000, 100000, 100000, 100000, 100000, 100000, 100000, 40397), (11,), (11,))\n2023-05-01 03:40:51 - de_select_ds_can - INFO - saving is_shp.\n2023-05-01 03:40:51 - de_select_ds_can - INFO - saving is_ds_can.\n2023-05-01 03:40:51 - de_select_ds_can - INFO - saving ds_can_is_shp.\n2023-05-01 03:40:51 - de_select_ds_can - INFO - computing graph setted. doing all the computing.\n2023-05-01 03:40:55 - de_select_ds_can - INFO - computing finished.\n2023-05-01 03:40:55 - de_select_ds_can - INFO - dask cluster closed.\n2023-05-01 03:40:55 - de_select_ds_can - INFO - plotting number of SHPs.\n2023-05-01 03:40:56 - de_select_ds_can - INFO - plotting DS candidate distribution.\nCPU times: user 2.93 s, sys: 2.21 s, total: 5.14 s\nWall time: 9.76 s"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "decorrelation",
    "section": "",
    "text": "Documentation"
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "decorrelation",
    "section": "Install",
    "text": "Install\nInstall CuPy first, then:\nWith conda:\nconda install -c conda-forge decorrelation\nWith pip:\npip install decorrelation\nIn development mode:\ngit clone git@github.com:kanglcn/decorrelation.git ./decorrelation\ncd ./decorrelation\npip install -e '.[dev]'"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "decorrelation",
    "section": "How to use",
    "text": "How to use\n\nimport decorrelation as dc\n\nThis package provide functions for InSAR post-processing which refers as processing after SAR images co-registration and geocoding. The functions include PS/DS identification, coherence matrix estimation, phase linking etc.\nMost of the python functions in this package provide 2 kind of API, the array-based API and the file-based API. The inputs of array-based functions generally are numpy or cupy arrays. The inputs of file-based functions are path to the array stored in disk. The file-based functions make use of dask package to decrease the memory usage and parallelize the job. However, their is performance cost for using dask, if no parallelization is needed and the memory fits the data, the array-based API is recommended.\nPlease refer to the Documentation for detailed usage.\nWarning!!! This package is under intensive development. API is subjected to change without any noticement."
  },
  {
    "objectID": "index.html#contact-us",
    "href": "index.html#contact-us",
    "title": "decorrelation",
    "section": "Contact us",
    "text": "Contact us\n\nMost discussion happens on GitHub. Feel free to open an issue or comment on any open issue or pull request.\nuse github discussions to ask questions or leave comments."
  },
  {
    "objectID": "index.html#contribution",
    "href": "index.html#contribution",
    "title": "decorrelation",
    "section": "Contribution",
    "text": "Contribution\n\nPull requests are welcomed! Before making a pull request, please open an issue to talk about it.\nWe have notice many excellent open-source packages are rarely paid attention to due to lake of documentation. The package is developed with the nbdev, a notebook-driven development platform. Developers only needs to simply write notebooks with lightweight markup and get high-quality documentation, tests, continuous integration, and packaging automatically."
  },
  {
    "objectID": "API/pl.html",
    "href": "API/pl.html",
    "title": "pl",
    "section": "",
    "text": "Code for generating data for test and doc\nimport cupy as cp\nimport numpy as np\nimport zarr\nimport h5py\nfrom decorrelation.shp import ks_test\nfrom decorrelation.co import emperical_co,emperical_co_sp, regularize_spectral\n\nfrom matplotlib import pyplot as plt"
  },
  {
    "objectID": "API/pl.html#emi",
    "href": "API/pl.html#emi",
    "title": "pl",
    "section": "EMI",
    "text": "EMI\n\nsource\n\nemi\n\n emi (coh:cupy.ndarray)\n\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ncoh\nndarray\ncomplex coherence metrix,dtype cupy.complex\n\n\nReturns\ntuple\nestimated phase history ph, dtype complex; quality (minimum eigvalue, dtype float)\n\n\n\nemi is a phase estimator base on Eigendecomposition-based Maximum-likelihood-estimator of Interferometric phase (EMI) [@ansariEfficientPhaseEstimation2018] phase linking method.\nThe amplitude of coh should range between 0 and 1 and the phase of coh should be the interferometric phase. The returned phase is also complex but the amplitude is setted to 1. The quality factor is a measure for the inadequacy of EMI’s model that adding real-valued dyadic for calibration of real coherence matrix which is generally poorly estimated. It is supposed to larger than 1 and smaller means better.\nExample: Complex coherence matrix from a stack of 17 SLC images:\n\n\nCode for generating data for test and doc\nrslc = zarr.open('../../data/rslc.zarr/','r')\nrslc = cp.asarray(rslc[:])\n\n# SHP selection\naz_half_win = 5; r_half_win = 5\naz_win = 2*az_half_win+1; r_win = 2*r_half_win+1\n\nrmli = cp.abs(rslc)**2\nsorted_rmli = cp.sort(rmli,axis=-1)\ndel rmli\ndist,p = ks_test(sorted_rmli,az_half_win=az_half_win,r_half_win=r_half_win)\nis_shp = (p < 0.05) & (p >= 0.0)\ndel p\n\n# Select DS candidate\nshp_num = cp.count_nonzero(is_shp,axis=(-2,-1))\nis_ds_can = shp_num >= 50\n\nds_can_is_shp = is_shp[is_ds_can]\nds_can_idx = cp.where(is_ds_can)\nds_can_cov, ds_can_coh = emperical_co_sp(rslc,ds_can_idx,ds_can_is_shp)\n\n\n\nds_can_coh.shape\n\n(740397, 17, 17)\n\n\n\nds_can_ph, ds_can_emi_quality = emi(ds_can_coh)\nds_can_ph.shape, ds_can_emi_quality.shape\n\n((740397, 17), (740397,))\n\n\n\nds_can_emi_quality_2d = cp.empty_like(is_ds_can,dtype=ds_can_emi_quality.dtype)\nds_can_emi_quality_2d[:] = cp.nan\nds_can_emi_quality_2d[is_ds_can] = ds_can_emi_quality\n\n\nfig, ax = plt.subplots(1,1,figsize=(10,10))\npcm = ax.imshow(cp.asnumpy(ds_can_emi_quality_2d),interpolation='nearest',vmin=1,vmax=1.3)\nax.set(title='DS EMI quality factor',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()"
  },
  {
    "objectID": "API/pl.html#temporal-coherence-for-distributed-scatterer",
    "href": "API/pl.html#temporal-coherence-for-distributed-scatterer",
    "title": "pl",
    "section": "Temporal Coherence for Distributed Scatterer",
    "text": "Temporal Coherence for Distributed Scatterer\n\nsource\n\ntemp_coh\n\n temp_coh (coh:cupy.ndarray, ds_ph=<class 'cupy.ndarray'>)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncoh\nndarray\n\ncomplex coherence metrix, dtype cupy.complex\n\n\nds_ph\ntype\nndarray\ncomplex phase history, dtype cupy.complex\n\n\n\nThis function estimate the temporal coherence of DSs which is defined as [@ferrettiNewAlgorithmProcessing2011]:\n\\[\\gamma = \\frac{1}{N^2-N} \\sum_{n=1}^{N} \\sum_{k \\neq n}^{N} e^{i\\phi_{nk}} e^{-i(\\theta_n-\\theta_k)}\\]\nWhere \\(\\phi_{nk}\\) is the phase of complex coherence matrix and \\(\\theta_{n}\\) is the phase after phase linking.\n\n\nCode for generating data for test and doc\nrslc = zarr.open('../../data/rslc.zarr/','r')\nrslc = cp.asarray(rslc[:])\n\n# SHP selection\naz_half_win = 5; r_half_win = 5\naz_win = 2*az_half_win+1; r_win = 2*r_half_win+1\n\nrmli = cp.abs(rslc)**2\nsorted_rmli = cp.sort(rmli,axis=-1)\ndel rmli\ndist,p = ks_test(sorted_rmli,az_half_win=az_half_win,r_half_win=r_half_win)\nis_shp = (p < 0.05) & (p >= 0.0)\n\n# Select DS candidate\nshp_num = cp.count_nonzero(is_shp,axis=(-2,-1))\nis_ds_can = shp_num >= 50\n\nds_can_is_shp = is_shp[is_ds_can]\nds_can_idx = cp.where(is_ds_can)\nds_can_cov, ds_can_coh = emperical_co_sp(rslc,ds_can_idx,ds_can_is_shp)\nds_can_ph = emi(ds_can_coh)[0]\n\n\n\nds_can_coh.shape,ds_can_ph.shape\n\n((740397, 17, 17), (740397, 17))\n\n\n\nds_can_temp_coh = temp_coh(ds_can_coh,ds_can_ph)\nds_can_temp_coh.shape\n\n(740397,)\n\n\n\nds_can_temp_coh_2d = cp.empty_like(is_ds_can,dtype=ds_can_temp_coh.dtype)\nds_can_temp_coh_2d[:] = cp.nan\nds_can_temp_coh_2d[is_ds_can] = ds_can_temp_coh\n\n\nfig, ax = plt.subplots(1,1,figsize=(10,10))\npcm = ax.imshow(cp.asnumpy(ds_can_temp_coh_2d),interpolation='nearest')\nax.set(title='DS Temporal Coherence',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()"
  },
  {
    "objectID": "API/co.html",
    "href": "API/co.html",
    "title": "co",
    "section": "",
    "text": "For generating data for doc and test\nimport cupy as cp\nimport zarr\nfrom decorrelation.shp import ks_test\nimport math\nimport itertools\nfrom cupy.testing import assert_array_almost_equal"
  },
  {
    "objectID": "API/co.html#covariance-and-coherence-matrix-estimator",
    "href": "API/co.html#covariance-and-coherence-matrix-estimator",
    "title": "co",
    "section": "Covariance and Coherence Matrix Estimator",
    "text": "Covariance and Coherence Matrix Estimator\n\nsource\n\nemperical_co\n\n emperical_co (rslc:cupy.ndarray, is_shp:cupy.ndarray, block_size:int=128)\n\nMaximum likelihood covariance estimator.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nrslc\nndarray\n\nrslc stack, dtype: cupy.complexfloating\n\n\nis_shp\nndarray\n\nshp bool, dtype: cupy.bool\n\n\nblock_size\nint\n128\nthe CUDA block size, it only affects the calculation speed\n\n\nReturns\ntuple\n\nthe covariance and coherence matrix cov and coh\n\n\n\nThe cov and coh is defined as:\n\\[\ncov = E(z_1z_2^*) \\quad coh=\\frac{E(z_1z_2^*)}{\\sqrt{E(|z_1|^2)E(|z_2|^2)}}\n\\]\nand estimated as:\n\\[\ncov = \\frac{\\sum_{i=1}^{L}z_1^{i}z_2^{i*}}{L} \\quad coh = \\frac{\\sum_{i=1}^{L}z_1^{i}z_2^{i*}}{\\sqrt(\\sum_{i=1}^{L}|z_1^{i}|^2)(\\sum_{i=1}^{L}|z_2^{i}|^2)}\n\\]\nusing all selected SHPs. Their shapes are [nlines,width,nimages,nimages].\nThe rslc is a three dimentional cupy ndarray. The dtype should be cupy.complex64. From outerest to innerest, the three dimentions are azimuth, range and image. is_shp is a four dimentional cupy ndarray. It describes if pixels in the search window are SHP to the central pixel. From outerest ot innerest, they are azimuth, range, secondary pixel relative azimuth, secondary pixel relative range.\nHere is an example:\n\n\nFor generating data for doc and test\nrslc = zarr.open('../../data/rslc.zarr/','r')[600:605,600:610]\nrslc = cp.asarray(rslc)\n\n# SHP selection\naz_half_win = 1; r_half_win = 2\naz_win = 2*az_half_win+1; r_win = 2*r_half_win+1\n\nrmli = cp.abs(rslc)**2\nsorted_rmli = cp.sort(rmli,axis=-1)\ndist,p = ks_test(sorted_rmli,az_half_win=az_half_win,r_half_win=r_half_win)\nis_shp = (p < 0.05) & (p >= 0.0)\n\n# Select DS candidate\nshp_num = cp.count_nonzero(is_shp,axis=(-2,-1))\nis_ds_can = shp_num >= 3\nds_can_is_shp = is_shp[is_ds_can]\nds_can_idx = cp.where(is_ds_can)\n\n\n\nrslc.shape, is_shp.shape, is_shp[2,3]\n\n((5, 10, 17),\n (5, 10, 3, 5),\n array([[False, False, False, False,  True],\n        [False, False,  True, False, False],\n        [False, False,  True, False, False]]))\n\n\nrslc is a stack of 17 rslc images. Each of the image has 5 pixel in azimuth dimention and 10 pixels in range dimention. It shows for pixel (2,3), the (3*5) window around it has 2 SHPs to it (the central one is itself).\n\ncov,coh = emperical_co(rslc,is_shp)\ncov.shape, coh.shape\n\n((5, 10, 17, 17), (5, 10, 17, 17))\n\n\nBoth cov and coh are complex data. The shape shows each covarience or coherence matrix is 17 by 17 since there are 17 images. And cov and coh are matrix for all 5*10 pixels.\n\nsource\n\n\nemperical_co_sp\n\n emperical_co_sp (rslc:cupy.ndarray, sp_idx:cupy.ndarray,\n                  is_shp_sp:cupy.ndarray, block_size:int=128)\n\nMaximum likelihood covariance estimator for sparse data.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nrslc\nndarray\n\nrslc stack, dtype: cupy.complexfloating\n\n\nsp_idx\nndarray\n\nindex of sparse data [azimuth_index, range_index], dtype: cupy.int, shape: (n_sp,2)\n\n\nis_shp_sp\nndarray\n\nshp bool, dtype: cupy.bool\n\n\nblock_size\nint\n128\nthe CUDA block size, it only affects the calculation speed\n\n\nReturns\ntuple\n\nthe covariance and coherence matrix cov and coh\n\n\n\nemperical_co_sp is the emperical_co on sparse data, e.g., DSs. rslc is same as emperical_co. sp_idx is the index, i.e., a tuple of (azimuth_idx, range_idx). Each index is 1D array. is_shp_sp is similar to is_shp in emperical_co but it only contains information about the sparse data. It is a 3D array with shape [number_of_point,az_win,r_win].\nCompared with emperical_co, emperical_co_sp only estimate coherence/covariance at specific position so the memory usage is much small.\nExample:\n\n\nCode for generating data for doc\nrslc = zarr.open('../../data/rslc.zarr/','r')[600:605,600:610]\nrslc = cp.asarray(rslc)\n\n# SHP selection\naz_half_win = 1; r_half_win = 2\naz_win = 2*az_half_win+1; r_win = 2*r_half_win+1\n\nrmli = cp.abs(rslc)**2\nsorted_rmli = cp.sort(rmli,axis=-1)\ndist,p = ks_test(sorted_rmli,az_half_win=az_half_win,r_half_win=r_half_win)\nis_shp = (p < 0.05) & (p >= 0.0)\n\n# Select DS candidate\nshp_num = cp.count_nonzero(is_shp,axis=(-2,-1))\nis_ds_can = shp_num >= 3\nds_can_is_shp = is_shp[is_ds_can]\nds_can_idx = cp.where(is_ds_can)\n\n\n\nrslc.shape,ds_can_idx,ds_can_is_shp\n\n((5, 10, 17),\n (array([2, 3, 3, 4, 4]), array([3, 3, 5, 1, 4])),\n array([[[False, False, False, False,  True],\n         [False, False,  True, False, False],\n         [False, False,  True, False, False]],\n \n        [[False, False,  True, False, False],\n         [False, False,  True, False, False],\n         [False, False, False,  True, False]],\n \n        [[False, False, False, False, False],\n         [False, False,  True, False, False],\n         [ True,  True, False, False, False]],\n \n        [[False, False,  True, False, False],\n         [False,  True,  True, False, False],\n         [False, False, False, False, False]],\n \n        [[False,  True,  True,  True, False],\n         [False, False,  True, False,  True],\n         [False, False, False, False, False]]]))\n\n\nrslc is a stack of 17 rslc images. Each of the image has 5 pixel in azimuth dimention and 10 pixels in range dimention. ds_can_idx shows the index of the DS candidates and ds_can_is_shp shows the corrosponding SHPs.\n\nds_can_cov, ds_can_coh = emperical_co_sp(rslc,ds_can_idx,ds_can_is_shp)"
  },
  {
    "objectID": "API/co.html#covariance-and-coherence-matrix-regularizer",
    "href": "API/co.html#covariance-and-coherence-matrix-regularizer",
    "title": "co",
    "section": "Covariance and Coherence Matrix Regularizer",
    "text": "Covariance and Coherence Matrix Regularizer\n\nsource\n\nisPD\n\n isPD (co:cupy.ndarray)\n\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nco\nndarray\nabsolute value of complex coherence/covariance stack\n\n\nReturns\nndarray\nbool array indicating wheather coherence/covariance is positive define\n\n\n\nThis function tells if the matrix is positive defined or not.\n\n\nCode for generating data for doc\nrslc = zarr.open('../../data/rslc.zarr/','r')[600:650,600:650]\nrslc = cp.asarray(rslc)\n\n# SHP selection\naz_half_win = 5; r_half_win = 5\naz_win = 2*az_half_win+1; r_win = 2*r_half_win+1\n\nrmli = cp.abs(rslc)**2\nsorted_rmli = cp.sort(rmli,axis=-1)\ndist,p = ks_test(sorted_rmli,az_half_win=az_half_win,r_half_win=r_half_win)\nis_shp = (p < 0.05) & (p >= 0.0)\n\n# Select DS candidate\nshp_num = cp.count_nonzero(is_shp,axis=(-2,-1))\nis_ds_can = shp_num >= 50\nds_can_is_shp = is_shp[is_ds_can]\nds_can_idx = cp.where(is_ds_can)\n\nds_can_coh = emperical_co_sp(rslc,ds_can_idx,ds_can_is_shp)[1]\n\n\n\nds_can_coh.shape\n\n(149, 17, 17)\n\n\n\nisPD_ds_can = isPD(ds_can_coh)\n\n\nisPD_ds_can\n\narray([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True])\n\n\nAll coherence matrix are positive defined.\n\nsource\n\n\nnearestPD\n\n nearestPD (co:cupy.ndarray)\n\nFind the nearest positive-definite matrix to input matrix.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nco\nndarray\nstack of matrix with shape […,N,N]\n\n\nReturns\nndarray\nnearest positive definite matrix of input, shape […,N,N]\n\n\n\nnearest means the Frobenius norm of the difference is minimized.\n\nsource\n\n\nregularize_spectral\n\n regularize_spectral (coh:cupy.ndarray, beta:Union[float,cupy.ndarray])\n\nSpectral regularizer for coherence matrix.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ncoh\nndarray\nstack of matrix with shape […,N,N]\n\n\nbeta\nUnion\nthe regularization parameter, a float number or cupy ndarray with shape […]\n\n\nReturns\nndarray\nregularized matrix, shape […,N,N]\n\n\n\nregularize_spectral can regularize the absolute value of coherence matrix for better phase linking. It is first presented in [@zwiebackCheapValidRegularizers2022a].\nExamples:\n\n\nCode for generating data for doc\nrslc = zarr.open('../../data/rslc.zarr/','r')[600:605,600:610]\nrslc = cp.asarray(rslc)\n\n# SHP selection\naz_half_win = 1; r_half_win = 2\naz_win = 2*az_half_win+1; r_win = 2*r_half_win+1\n\nrmli = cp.abs(rslc)**2\nsorted_rmli = cp.sort(rmli,axis=-1)\ndist,p = ks_test(sorted_rmli,az_half_win=az_half_win,r_half_win=r_half_win)\nis_shp = (p < 0.05) & (p >= 0.0)\n\ncov,coh = emperical_co(rslc,is_shp)\n\n\n\ncoh.shape\n\n(5, 10, 17, 17)\n\n\n\nregularized_coh1 = regularize_spectral(coh,0.1)\n\nMore general, bata can be a cp.ndarray:\n\nbeta = cp.ones(coh.shape[:-2])/10\nregularized_coh2 = regularize_spectral(coh,beta)"
  },
  {
    "objectID": "API/plot.html",
    "href": "API/plot.html",
    "title": "Plot",
    "section": "",
    "text": "source\n\nbg_alpha\n\n bg_alpha (pwr)"
  },
  {
    "objectID": "API/shp.html",
    "href": "API/shp.html",
    "title": "shp",
    "section": "",
    "text": "from scipy import stats\nimport numpy as np\nimport itertools"
  },
  {
    "objectID": "API/shp.html#kolmogorov-smirnov-ks-two-sample-test",
    "href": "API/shp.html#kolmogorov-smirnov-ks-two-sample-test",
    "title": "shp",
    "section": "Kolmogorov-Smirnov (KS) two-sample test",
    "text": "Kolmogorov-Smirnov (KS) two-sample test\n\nsource\n\nks_test\n\n ks_test (rmli:cupy.ndarray, az_half_win:int, r_half_win:int,\n          block_size:int=128)\n\nSHP identification based on Two-Sample Kolmogorov-Smirnov Test.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nrmli\nndarray\n\nthe rmli stack, dtype: cupy.floating\n\n\naz_half_win\nint\n\nSHP identification half search window size in azimuth direction\n\n\nr_half_win\nint\n\nSHP identification half search window size in range direction\n\n\nblock_size\nint\n128\nthe CUDA block size, it only affects the calculation speed\n\n\nReturns\ntuple\n\nthe KS test statistics dist and p value p\n\n\n\nThe ks_test function apply the Two-Sample Kolmogorov-Smirnov Test on a stack of rmli images to identify SHPs candidate for further processing. This method is originally published in [@ferrettiNewAlgorithmProcessing2011]. This function is designed to run on GPU for high speed.\nThe rmli is a three dimentional cupy ndarray. The dtype should be float. From outerest to innerest, the three dimentions are azimuth, range and image. For each pixel P, a search window centered at P is defined by az_half_win and r_half_win. All pixels in this search window is compared with P by KS test. They are refered here as secondary pixels. The total number of secondary pixels (including P) is (2*az_half_win+1)*(2*r_half_win+1).\nThe returns are the ks test statistic which is the maximum value of the absolute difference between the emperical cumulative distribution functions of the two samples, and p value. Both of them are 4 dimentional cupy ndarrays. From outerest ot innerest, they are azimuth, range, secondary pixel relative azimuth, secondary pixel relative range. For P at the corner of the image where part of the search window is out of the image, the result is -1.\nHere is a simplest example. First simulate rmli time series of two pixels from two correlated normal distributions:\n\nsample_size = 20\nrng = np.random.default_rng()\nsample1 = stats.uniform.rvs(size=sample_size, random_state=rng).astype(cp.float32)\nsample2 = stats.norm.rvs(size=sample_size, random_state=rng).astype(cp.float32)\n\nConvert the data to cupy ndarray and make sure the dtype is cp.float32 and the data are sorted:\n\nrmli_stack = cp.stack((cp.asarray(sample1), cp.asarray(sample2))).reshape(1,2,sample_size)\nrmli_stack = rmli_stack.astype(cp.float32)\nrmli_stack.shape\n\n(1, 2, 20)\n\n\nThe shape of rmli_stack shows it contains 20 images. Each of the image has 1 pixel in azimuth dimention and 2 pixels in range dimention. Set the az_half_win and r_half_win to 1 and apply the ks_test function:\n\ndist,p = ks_test(rmli_stack,1,1)\nprint(dist.shape)\nprint(dist)\n\n(1, 2, 3, 3)\n[[[[-1.  -1.  -1. ]\n   [-1.   0.   0.6]\n   [-1.  -1.  -1. ]]\n\n  [[-1.  -1.  -1. ]\n   [ 0.6  0.  -1. ]\n   [-1.  -1.  -1. ]]]]\n\n\ndist is the ks test statistic. The shape of it shows for each pixel P in this 1*2 image, a 3*3 search window is defined and all pixels in this search window is test with P. The value 0 in dist is the ks test result of pixel P and pixel P itself. The value -1 means the secondary pixel is out of the image and no ks test is applied.\n\nprint(p.shape)\nprint(p)\n\n(1, 2, 3, 3)\n[[[[-1.0000000e+00 -1.0000000e+00 -1.0000000e+00]\n   [-1.0000000e+00  0.0000000e+00  7.2528544e-04]\n   [-1.0000000e+00 -1.0000000e+00 -1.0000000e+00]]\n\n  [[-1.0000000e+00 -1.0000000e+00 -1.0000000e+00]\n   [ 7.2528544e-04  0.0000000e+00 -1.0000000e+00]\n   [-1.0000000e+00 -1.0000000e+00 -1.0000000e+00]]]]\n\n\np is the ks test p value with same shape of dist.\n\nprint(stats.ks_2samp(sample1, sample2,method='asymp'))\n\nKstestResult(statistic=0.6, pvalue=0.0005681672000000003, statistic_location=-0.12029845, statistic_sign=-1)\n\n\nBy comparing the result of ks_test and ks_2samp from scipy, the statistics are same which prove the correctness of ks_test. The difference in p value is because the approcimation method used are different but the orders of magnitudes are consistent."
  },
  {
    "objectID": "Tutorials/work_with_dask.html",
    "href": "Tutorials/work_with_dask.html",
    "title": "Work With Dask",
    "section": "",
    "text": "import numpy as np\nimport zarr\nimport cupy as cp\nfrom itertools import product\n\nfrom matplotlib import pyplot as plt\nimport colorcet\n\nfrom decorrelation.shp import ks_test\nfrom decorrelation.co import emperical_co_sp\nfrom decorrelation.pl import emi\nIn this tutorial, we demostrate how to use Dask for distributed computing.\nTwo significant issues for InSAR big data processing are: 1) the memory of CPU/GPU does not fit the volume of very big data; 2) the processing speed is limited. For the first issue, one common solution is divide the data into independent chunks and process the chunks one by one. In many case, the processing of chunks are independent. Thus the processing can be speeded up by parallel processing.\nDask is a job scheduler that allows deploying process-level parallel processing. Through the Delayed feature, Dask operations only construct the computing workflow rather than do the computation immediately. All of the computations are done at the end to allow Dask better distributing computing resources for the task. Dask makes the parallel processing easier and enable the decoupling of codes for computation and codes for scheduling.\nIn this demo, we use Dask for multi-GPU KS test to select spatially homogenious pixels. This includes:\nThe KS test is one step of DS processing, the full DS processing precedure is in the DS_processing tutorial. However, that tutorial directly utilize arrays."
  },
  {
    "objectID": "Tutorials/work_with_dask.html#processing",
    "href": "Tutorials/work_with_dask.html#processing",
    "title": "Work With Dask",
    "section": "Processing",
    "text": "Processing\nLoad data into CPU, and set the chunk size:\n\nrslc_path = '../../data/rslc.zarr'\nrslc_zarr = zarr.open(rslc_path,mode='r')\ncpu_rslc = da.from_zarr(rslc_path,chunks=(2500,1000,17))\n\n\nrslc_zarr.chunks\n\n(1000, 1000, 17)\n\n\n\nrslc_zarr.shape\n\n(2500, 1834, 17)\n\n\nNote that SHP identification requires overlapping region to correctly select brothers of pixels around the chunk bound.\n\naz_half_win = 5\nr_half_win = 5\naz_win = 2*az_half_win+1\nr_win = 2*r_half_win+1\n\n\ndepth = {0:az_half_win, 1:r_half_win, 2:0}; boundary = {0:'none',1:'none',2:'none'}\ncpu_rslc_overlap = da.overlap.overlap(cpu_rslc,depth=depth, boundary=boundary)\n\n\nrslc_overlap = cpu_rslc_overlap.map_blocks(cp.asarray)\nrmli_overlap = da.abs(rslc_overlap)**2\nsorted_rmli_overlap = rmli_overlap.map_blocks(cp.sort,axis=-1)\n\nDask provide a convenient function map_blocks to apply function on every chunk. However, it only support function that have only one output. Here we manually do the mapping:\n\n# the array of delayed object will lost some shape information so perserve them here\nchunks_size = sorted_rmli_overlap.chunks \nnchunks = tuple(len(nchunks_in_each_dim) for nchunks_in_each_dim in chunks_size)\nchunks_shape = list(product(*chunks_size))\n\n\nrmli_chunks = sorted_rmli_overlap.to_delayed()\nrmli_chunks\n\narray([[[Delayed(('sort-d8fa317bd477a77978ac39f6f309381a', 0, 0, 0))],\n        [Delayed(('sort-d8fa317bd477a77978ac39f6f309381a', 0, 1, 0))]]],\n      dtype=object)\n\n\n\ndelayed_ks_test = delayed(ks_test,pure=True,nout=2)\nresults = [delayed_ks_test(rmli_chunk,az_half_win=az_half_win,r_half_win=r_half_win) for rmli_chunk in rmli_chunks.ravel()]\ndist_chunks, p_chunks = zip(*results)\ndist_chunks, p_chunks = np.array(dist_chunks), np.array(p_chunks)\n\n\nfor i in range(len(chunks_shape)):\n    dist_chunks[i] = da.from_delayed(dist_chunks[i],shape=(*chunks_shape[i][:-1],az_win,r_win),meta=cp.array((),dtype=rmli_overlap.dtype))\n    p_chunks[i] = da.from_delayed(p_chunks[i],shape=(*chunks_shape[i][:-1],az_win,r_win),meta=cp.array((),dtype=rmli_overlap.dtype))\n\n\ndist_chunks, p_chunks = dist_chunks.reshape((*nchunks,1)).tolist(), p_chunks.reshape((*nchunks,1)).tolist()\n\n\ndist = da.block(dist_chunks)\np = da.block(p_chunks)\n\nAfter we get the result, the overlapping region need to be trimed:\n\ndepth = {0:az_half_win, 1:r_half_win, 2:0, 3:0}; boundary = {0:'none',1:'none',2:'none',3:'none'}\ndist = da.overlap.trim_overlap(dist,depth=depth,boundary=boundary)\np = da.overlap.trim_overlap(p,depth=depth,boundary=boundary)\n\nSelect SHPs based on p-value threshold:\n\nis_shp = (p < 0.05) & (p >= 0.0)\n\n\nshp_num = da.count_nonzero(is_shp,axis=(-2,-1))\nis_ds_can = shp_num >= 50\n\n\ncpu_dist = da.map_blocks(cp.asnumpy,dist)\ncpu_p = da.map_blocks(cp.asnumpy,p)\ncpu_is_shp = da.map_blocks(cp.asnumpy,is_shp)\ncpu_shp_num = da.map_blocks(cp.asnumpy,shp_num)\ncpu_is_ds_can = da.map_blocks(cp.asnumpy,is_ds_can)\n\nSave the data to disk:\n\n_cpu_dist = cpu_dist.to_zarr('dist.zarr',overwrite=True,compute=False)\n_cpu_p = cpu_p.to_zarr('p.zarr',overwrite=True,compute=False)\n\nDo the computation:\n\nshp_num_result, is_ds_can_result = da.compute(_cpu_dist,_cpu_p,cpu_shp_num,cpu_is_ds_can)[2:]\ncluster.close()\n\nCPU times: user 748 ms, sys: 353 ms, total: 1.1 s\nWall time: 10.4 s\n\n\n\nfig, ax = plt.subplots(1,1,figsize=(10,10))\npcm = ax.imshow(shp_num_result,cmap=colorcet.cm.fire)\nax.set(title='Number of SHPs',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()\n\n\n\n\n\nfig, ax = plt.subplots(1,1,figsize=(10,10))\npcm = ax.imshow(is_ds_can_result,cmap=colorcet.cm.fire)\nax.set(title='DS Candidate distribution',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()\n\n\n\n\n\nimport numpy as np\nimport zarr\nimport cupy as cp\nfrom decorrelation.shp import ks_test\nrslc_zarr = zarr.open('../../data/rslc.zarr',mode='r')\nrslc_cpu = rslc_zarr[:]\nrslc = cp.asarray(rslc_cpu)\nrmli = cp.abs(rslc)**2\nsorted_rmli = cp.sort(rmli,axis=-1)\naz_half_win = 5\nr_half_win = 5\naz_win = 2*az_half_win+1\nr_win = 2*r_half_win+1\ndist,p = ks_test(sorted_rmli,az_half_win=az_half_win,r_half_win=r_half_win)\ndist_cpu = cp.asnumpy(dist)\np_cpu = cp.asnumpy(p)\nzarr.save_array('dist_ks.zarr', dist_cpu,chunks=(1000,1000,az_win,r_win),compressor=None)\nzarr.save_array('p_ks.zarr', p_cpu,chunks=(1000,1000,az_win,r_win),compressor=None)\n\nCPU times: user 2.27 s, sys: 8.69 s, total: 11 s\nWall time: 12.3 s"
  },
  {
    "objectID": "Tutorials/ds_processing.html",
    "href": "Tutorials/ds_processing.html",
    "title": "DS Processing",
    "section": "",
    "text": "In this tutorial, we demostrate how to do standard DS processing with the decorrelation package."
  },
  {
    "objectID": "Tutorials/ds_processing.html#load-rslc-stack",
    "href": "Tutorials/ds_processing.html#load-rslc-stack",
    "title": "DS Processing",
    "section": "Load rslc stack",
    "text": "Load rslc stack\n\nrslc = cp.load('../../data/rslc.npy')\nrslc.shape\n\n(2500, 1834, 17)"
  },
  {
    "objectID": "Tutorials/ds_processing.html#apply-ks-test",
    "href": "Tutorials/ds_processing.html#apply-ks-test",
    "title": "DS Processing",
    "section": "Apply ks test",
    "text": "Apply ks test\n\nrmli = cp.abs(rslc)**2\nsorted_rmli = cp.sort(rmli,axis=-1)\n\n\naz_half_win = 5\nr_half_win = 5\naz_win = 2*az_half_win+1\nr_win = 2*r_half_win+1\n\n\np = ks_test(sorted_rmli,az_half_win=az_half_win,r_half_win=r_half_win)[1]"
  },
  {
    "objectID": "Tutorials/ds_processing.html#select-shps",
    "href": "Tutorials/ds_processing.html#select-shps",
    "title": "DS Processing",
    "section": "Select SHPs",
    "text": "Select SHPs\n\nis_shp = (p < 0.05) & (p >= 0.0)\n\n\nshp_num = cp.count_nonzero(is_shp,axis=(-2,-1))\n\n\nfig, ax = plt.subplots(1,1,figsize=(10,10))\npcm = ax.imshow(cp.asnumpy(shp_num),cmap=colorcet.cm.fire)\nax.set(title='Number of SHPs',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()"
  },
  {
    "objectID": "Tutorials/ds_processing.html#select-dss",
    "href": "Tutorials/ds_processing.html#select-dss",
    "title": "DS Processing",
    "section": "Select DSs",
    "text": "Select DSs\nHere we select DSs candidate as pixels have more than 50 brothers.\n\nis_ds_can = shp_num >= 50\n\nThe number of DSs:\n\ncp.count_nonzero(is_ds_can)\n\narray(740397)\n\n\nThe DSs distribution:\n\nfig, ax = plt.subplots(1,1,figsize=(10,10))\npcm = ax.imshow(cp.asnumpy(is_ds_can),cmap=colorcet.cm.fire)\nax.set(title='DS Candidate distribution',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()"
  },
  {
    "objectID": "Tutorials/ds_processing.html#estimate-coherence-matrix",
    "href": "Tutorials/ds_processing.html#estimate-coherence-matrix",
    "title": "DS Processing",
    "section": "Estimate coherence matrix",
    "text": "Estimate coherence matrix\nIn order to save memory, here we only estimate coherence matrix on selected DSs:\n\nds_can_is_shp = is_shp[is_ds_can]\nds_can_idx = cp.where(is_ds_can)\nds_can_cov, ds_can_coh = emperical_co_sp(rslc,ds_can_idx,ds_can_is_shp)\n\nPlot the average coherence matrix:\n\nds_can_ave_coh = abs(ds_can_coh).mean(axis=0)\n\n\nds_can_ave_coh.shape\n\n(17, 17)\n\n\n\nfig, ax = plt.subplots(1,1,figsize=(15,10))\npcm = ax.imshow(cp.asnumpy(ds_can_ave_coh),cmap=colorcet.cm.fire)\nax.set(title='Average Coherence Matrix',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()\n\n\n\n\nThe coherence between the 5-th SLC and other SLC are bad. We may consider removing this image."
  },
  {
    "objectID": "Tutorials/ds_processing.html#phase-linking",
    "href": "Tutorials/ds_processing.html#phase-linking",
    "title": "DS Processing",
    "section": "Phase linking",
    "text": "Phase linking\nHere we apply the EMI method:\n\nds_can_ph, ds_can_emi_quality = emi(ds_can_coh)\nds_can_ph.shape, ds_can_emi_quality.shape\n\n((740397, 17), (740397,))\n\n\n\nds_can_emi_quality_2d = cp.empty_like(is_ds_can,dtype=ds_can_emi_quality.dtype)\nds_can_emi_quality_2d[:] = cp.nan\nds_can_emi_quality_2d[is_ds_can] = ds_can_emi_quality\n\n\nfig, ax = plt.subplots(1,1,figsize=(10,10))\npcm = ax.imshow(cp.asnumpy(ds_can_emi_quality_2d),interpolation='nearest',vmin=1,vmax=1.3)\nax.set(title='DS EMI quality factor',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()\n\n\n\n\n\nds_can_temp_coh = temp_coh(ds_can_coh,ds_can_ph)\nds_can_temp_coh.shape\n\n(740397,)\n\n\n\nds_can_temp_coh_2d = cp.empty_like(is_ds_can,dtype=ds_can_temp_coh.dtype)\nds_can_temp_coh_2d[:] = cp.nan\nds_can_temp_coh_2d[is_ds_can] = ds_can_temp_coh\nfig, ax = plt.subplots(1,1,figsize=(10,10))\npcm = ax.imshow(cp.asnumpy(ds_can_temp_coh_2d),interpolation='nearest')\nax.set(title='DS Temporal Coherence',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()"
  },
  {
    "objectID": "Tutorials/ds_processing.html#refine-ds-candidate",
    "href": "Tutorials/ds_processing.html#refine-ds-candidate",
    "title": "DS Processing",
    "section": "Refine DS candidate",
    "text": "Refine DS candidate\nHere we select DS candidate based on EMI quality factor and temporal coherence:\n\n_is_ds_can_refined = (ds_can_emi_quality>=1.0) & (ds_can_emi_quality <1.2) & (ds_can_temp_coh > 0.7) & (ds_can_temp_coh <= 1.0)\n\n\nds_can_refined_idx = tuple(idx[_is_ds_can_refined] for idx in ds_can_idx)\nis_ds_can_refined = cp.zeros_like(is_ds_can)\nis_ds_can_refined[ds_can_refined_idx] = True\n\n\nds_can_refined_coh = ds_can_coh[_is_ds_can_refined]\nds_can_refined_ph = ds_can_ph[_is_ds_can_refined]\n\n\nds_can_refined_coh.shape\n\n(460076, 17, 17)\n\n\nPlot the average coherence matrix and refined DS candiate distribution:\n\nds_can_refined_ave_coh = abs(ds_can_refined_coh).mean(axis=0)\nfig, ax = plt.subplots(1,1,figsize=(15,10))\npcm = ax.imshow(cp.asnumpy(ds_can_refined_ave_coh),cmap=colorcet.cm.fire)\nax.set(title='Average Coherence Matrix',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()\n\n\n\n\n\nfig, ax = plt.subplots(1,1,figsize=(10,10))\npcm = ax.imshow(cp.asnumpy(is_ds_can_refined),cmap=colorcet.cm.fire)\nax.set(title='DS Candidate Refined distribution',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()\n\n\n\n\nWe find the coherence matrix gets better and noisy pixels are moved."
  },
  {
    "objectID": "Tutorials/adaptive_multilook.html",
    "href": "Tutorials/adaptive_multilook.html",
    "title": "Adaptive Multilook",
    "section": "",
    "text": "In this tutorial, we demostrate how to use decorrelation package to identify spatially homogeneous pixels, extimate the coherence matrix and compare the original interferogram, multilook intergerogram and the adaptive multilook interferogram."
  },
  {
    "objectID": "Tutorials/adaptive_multilook.html#load-rslc-stack",
    "href": "Tutorials/adaptive_multilook.html#load-rslc-stack",
    "title": "Adaptive Multilook",
    "section": "Load rslc stack",
    "text": "Load rslc stack\n\ncp.cuda.Device(1).use()\n\n<CUDA Device 1>\n\n\n\nrslc = cp.load('../../data/rslc.npy')\nrslc.shape\n\n(2500, 1834, 17)"
  },
  {
    "objectID": "Tutorials/adaptive_multilook.html#apply-ks-test",
    "href": "Tutorials/adaptive_multilook.html#apply-ks-test",
    "title": "Adaptive Multilook",
    "section": "Apply ks test",
    "text": "Apply ks test\n\nrmli = cp.abs(rslc)**2\n\n\naz_half_win = 5\nr_half_win = 5\naz_win = 2*az_half_win+1\nr_win = 2*r_half_win+1\n\n\np = ks_test(rmli,az_half_win=az_half_win,r_half_win=r_half_win)[1]\n\nCPU times: user 45.7 ms, sys: 28.6 ms, total: 74.3 ms\nWall time: 74.8 ms\n\n\nks_test in decorrelation package is extremely fast!"
  },
  {
    "objectID": "Tutorials/adaptive_multilook.html#select-shps",
    "href": "Tutorials/adaptive_multilook.html#select-shps",
    "title": "Adaptive Multilook",
    "section": "Select SHPs",
    "text": "Select SHPs\n\nis_shp = (p < 0.05) & (p >= 0.0)\n\n\nshp_num = cp.count_nonzero(is_shp,axis=(-2,-1))\nshp_num_np = cp.asnumpy(shp_num)\n\n\nfig, ax = plt.subplots(1,1,figsize=(10,10))\npcm = ax.imshow(shp_num_np)\nax.set(title='Number of SHPs',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()"
  },
  {
    "objectID": "Tutorials/adaptive_multilook.html#estimate-coherence-matrix",
    "href": "Tutorials/adaptive_multilook.html#estimate-coherence-matrix",
    "title": "Adaptive Multilook",
    "section": "Estimate coherence matrix",
    "text": "Estimate coherence matrix\n\ncoh = emperical_co(rslc,is_shp)[1]\n\nCPU times: user 226 ms, sys: 18.8 ms, total: 245 ms\nWall time: 253 ms"
  },
  {
    "objectID": "Tutorials/adaptive_multilook.html#compare",
    "href": "Tutorials/adaptive_multilook.html#compare",
    "title": "Adaptive Multilook",
    "section": "Compare",
    "text": "Compare\nHere we compare 1-look interferogram, multilook interferogram and adaptive multilook interferogram\n\nref_image = 15\nsec_image = 16\n\n1 look interferogram:\n\ndiff = rslc[:,:,ref_image]*rslc[:,:,sec_image].conj()\n\nMultilook interferogram:\n\nml_diff = median_filter(diff,size=(az_win,r_win))\n\nAdaptive multilook interferogram:\n\nad_ml_diff = coh[:,:,ref_image,sec_image]\n\nThe plot background:\n\nplot_bg = rmli[:,:,0]\nplot_bg = cp.asnumpy(plot_bg)\nalpha = bg_alpha(plot_bg)\n\nPlot:\n\nfig,axes = plt.subplots(1,3,figsize=(24/2,7/2))\nxlabel = 'Range Index'\nylabel = 'Azimuth Index'\npcm0 = axes[0].imshow(cp.asnumpy(cp.angle(diff)),alpha=alpha,interpolation='nearest',cmap='hsv')\npcm1 = axes[1].imshow(cp.asnumpy(cp.angle(ml_diff)),alpha=alpha,interpolation='nearest',cmap='hsv')\npcm2 = axes[2].imshow(cp.asnumpy(cp.angle(ad_ml_diff)),alpha=alpha,interpolation='nearest',cmap='hsv')\nfor ax in axes:\n    ax.set(facecolor = \"black\")\naxes[0].set(title='Orignal Interferogram',xlabel=xlabel,ylabel=ylabel)\naxes[1].set(title=f'Multilook {az_win} by {r_win}',xlabel=xlabel,ylabel=ylabel)\naxes[2].set(title=f'Adaptively multilook {az_win} by {r_win}',xlabel=xlabel,ylabel=ylabel)\nfig.colorbar(pcm0,ax=axes[0])\nfig.colorbar(pcm1,ax=axes[1])\nfig.colorbar(pcm1,ax=axes[2])\nfig.show()"
  },
  {
    "objectID": "Tutorials/adaptive_multilook.html#conclusion",
    "href": "Tutorials/adaptive_multilook.html#conclusion",
    "title": "Adaptive Multilook",
    "section": "Conclusion",
    "text": "Conclusion\n\nAdaptive multilooking based on SHPs selection performs better than non-adaptive one;\nks_test and emperical_co implemented in decorrelation package are fast."
  }
]